{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy-Generator Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from queue import PriorityQueue\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import tqdm\n",
    "from torchnlp.metrics import get_moses_multi_bleu\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
    "from io import BytesIO\n",
    "\n",
    "import linecache\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import operator\n",
    "import collections\n",
    "from pprint import pprint\n",
    "\n",
    "from models_and_trainers.base_transformer import TransformerModel, PositionalEncoding\n",
    "from models_and_trainers.copy_gen_transformer import Transformer, TransformerDecoderLayer, TransformerDecoder\n",
    "from models_and_trainers.retrieval import PyLuceneRetriever\n",
    "import beam_search\n",
    "from utils.edit_tagger import build_matrix, single_step_edits, perform_edits, get_tags\n",
    "\n",
    "from IPython.core.debugger import set_trace as tr\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def super_print(filename):\n",
    "    '''filename is the file where output will be written'''\n",
    "    def wrap(func):\n",
    "        '''func is the function you are \"overriding\", i.e. wrapping'''\n",
    "        def wrapped_func(*args,**kwargs):\n",
    "            '''*args and **kwargs are the arguments supplied \n",
    "            to the overridden function'''\n",
    "            #use with statement to open, write to, and close the file safely\n",
    "            with open(filename,'a') as outputfile:\n",
    "                now = datetime.now()\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                outputfile.write(\"[{}] \".format(dt_string))\n",
    "                outputfile.write(\" \".join(str(x) for x in args))\n",
    "                outputfile.write(\"\\n\")\n",
    "            #now original function executed with its arguments as normal\n",
    "            return func(*args,**kwargs)\n",
    "        return wrapped_func\n",
    "    return wrap\n",
    "\n",
    "print = super_print('logs-copy-gen.txt')(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.set_device(0) # choose GPU from nvidia-smi \n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['create', 'variable', 'student_names', 'with', 'string', \"'foo bar baz'\"]\n"
     ]
    }
   ],
   "source": [
    "text = \"create variable student_names with string 'foo bar baz'\"\n",
    "\n",
    "def string_split(s):\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(_|\\W)', s))) # this will chunk all code properly by plits strings with quotes\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|_|\\W)', s))) # this keeps the strings intact\n",
    "    return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|\\W)', s)))\n",
    "\n",
    "print(string_split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_array(src_fp, tgt_fp):\n",
    "    lines = []\n",
    "    with open(src_fp, \"r\") as src_file, open(tgt_fp, \"r\") as tgt_file:\n",
    "        for src, tgt in zip(src_file, tgt_file):\n",
    "            lines.append((src, tgt))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_corpus(data, max_seq_length=200, tokenizer=string_split):\n",
    "    return [(src, tgt) for src, tgt in data if len(string_split(src)) <= max_seq_length and len(string_split(tgt)) <= max_seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_dataset(samples):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samples: [(src_string),(tgt_string)]\n",
    "        src/tgt_tokenizer: a func that takes a string and returns an array of strings\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    TEXT_FIELD = Field(sequential=True, use_vocab=False, init_token='<sos>',eos_token='<eos>')\n",
    "    \n",
    "    for sample in samples:\n",
    "        src_string, tgt_string = sample\n",
    "        examples.append(torchtext.data.Example.fromdict({\"src\":src_string, \"tgt\":tgt_string}, \n",
    "                                        fields={\"src\":(\"src\",TEXT_FIELD), \"tgt\":(\"tgt\",TEXT_FIELD)}))\n",
    "        \n",
    "    dataset = torchtext.data.Dataset(examples,fields={\"src\":src_field, \"tgt\":tgt_field})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max src length: 557\n",
      "Max tgt length: 527\n",
      "Full dataset size: 18805\n",
      "Limited dataset size: 18794\n"
     ]
    }
   ],
   "source": [
    "data = corpus_to_array(\"datasets/all.desc\", \"datasets/all.code\")\n",
    "# data = corpus_to_array(\"datasets/all.desc\", \"datasets/all.code\")\n",
    "random.shuffle(data)\n",
    "print(\"Max src length:\", max([len(string_split(src)) for src, tgt in data]))\n",
    "print(\"Max tgt length:\", max([len(string_split(tgt)) for src, tgt in data]))\n",
    "\n",
    "print(\"Full dataset size:\", len(data))\n",
    "max_seq_length=200\n",
    "data = filter_corpus(data, max_seq_length=max_seq_length, tokenizer=string_split)\n",
    "data = [(\" \".join(string_split(src)),\" \".join(string_split(tgt))) for src, tgt in data]\n",
    "print(\"Limited dataset size:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {\"<unk>\":0, \"<sos>\":1, \"<eos>\":2, \"<pad>\":3, \"<gen>\":4}\n",
    "max_vocab = 10000 - len(stoi)\n",
    "\n",
    "all_toks = []\n",
    "for (src, tgt) in data:\n",
    "    all_toks += string_split(src)\n",
    "    all_toks += string_split(tgt)\n",
    "\n",
    "most_freq = collections.Counter(all_toks).most_common(max_vocab)\n",
    "\n",
    "for tok, count in most_freq:\n",
    "    stoi[tok] = len(stoi)\n",
    "    \n",
    "itos = [k for k,v in sorted(stoi.items(), key=lambda kv: kv[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9178\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size: {len(stoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(string, from_list=False):\n",
    "    OOVs = []\n",
    "    IDs = []\n",
    "    if not from_list:\n",
    "        words = string_split(string)\n",
    "    else:\n",
    "        words = string\n",
    "    for word in words:\n",
    "        try:\n",
    "            id = stoi[word]\n",
    "            IDs.append(id)\n",
    "        except KeyError as e:\n",
    "            # word is OOV\n",
    "            IDs.append(len(stoi) + len(OOVs))\n",
    "            OOVs.append(word)\n",
    "    return IDs, OOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(string, OOVs, from_list=False):\n",
    "    IDs = []\n",
    "    if from_list:\n",
    "        words = string\n",
    "    else:\n",
    "        words = string_split(string)\n",
    "    for word in words:\n",
    "        try:\n",
    "            id = stoi[word]\n",
    "            IDs.append(id)\n",
    "        except KeyError as e:\n",
    "            # word is OOV\n",
    "            try:\n",
    "                IDs.append(len(stoi) + OOVs.index(word))\n",
    "            except ValueError as e:\n",
    "                IDs.append(stoi[\"<unk>\"])\n",
    "    return IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids, OOVs):\n",
    "    extended_itos = itos.copy()\n",
    "    extended_itos += [OOV+\"(COPY)\" for OOV in OOVs]\n",
    "    return \" \".join([extended_itos[id] for id in ids if id<len(extended_itos)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval \n",
    "We want to find the most appropriate code to the input description. For this we use PyLucene to provide a BM25 search over the english descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"return value of the npath function with string '.mo' appended to the base_path as argument , and return value of the npath function with string '.po' appended to the base_path as argument , substitute it for args . call the popen_wrapper with args as the argument , assign the result to the output , errors and status , respectively .\",\n",
       " 'output , errors , status = popen_wrapper ( args )')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = PyLuceneRetriever()\n",
    "\n",
    "src_data = [src for src,tgt in data]\n",
    "retriever.add_multiple_docs(src_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 best matched samples\n",
      "Description: if age is greater than max_age ,\n",
      "Code       : if age > max_age :\n",
      "\n",
      "Description: if start is greater than upto ,\n",
      "Code       : if start > upto :\n",
      "\n",
      "Description: if doublecolon_len is greater than best_doublecolon_len ,\n",
      "Code       : if doublecolon_len > best_doublecolon_len :\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_ranking = retriever.BM25_search(\"is greater than\")\n",
    "doc_ids = [x.doc for x in doc_ranking]\n",
    "retrieved_samples = [data[i] for i in doc_ids]\n",
    "print(\"10 best matched samples\")\n",
    "for doc in retrieved_samples[:10]:\n",
    "    print(f\"Description: {doc[0]}\")\n",
    "    print(f\"Code       : {doc[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Edit steps\n",
    "While there is a vocabulary for the shared english and code. The editing tokens also need to be converted to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_stoi = {\"K\":0, \"D\":1, \"R\":2, \"<pad>\":3}\n",
    "edit_itos = {0:\"K\", 1:\"D\", 2:\"R\", 3:\"<pad>\"}\n",
    "max_insertions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_commands(commands):\n",
    "    return [edit_stoi[command] for command in commands]\n",
    "\n",
    "def decode_commands(commands):\n",
    "    return [edit_itos[command] for command in commands]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single edit example\n",
    "Let's make a complete sample from the dataset.\n",
    "![alt text](./images/edit_transformer_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', 'output', ',', 'errors', ',', 'status', '=', 'popen_wrapper', '(', 'args', ')'] ['<sos>', 'msgs', ',', 'errors', ',', 'status', '=', 'popen_wrapper', '(', 'args', ')']\n",
      "[{'code_target': ['<sos>',\n",
      "                  'output',\n",
      "                  ',',\n",
      "                  'errors',\n",
      "                  ',',\n",
      "                  'status',\n",
      "                  '=',\n",
      "                  'popen_wrapper',\n",
      "                  '(',\n",
      "                  'args',\n",
      "                  ')'],\n",
      "  'decoder_input': ['<sos>',\n",
      "                    'msgs',\n",
      "                    ',',\n",
      "                    'errors',\n",
      "                    ',',\n",
      "                    'status',\n",
      "                    '=',\n",
      "                    'popen_wrapper',\n",
      "                    '(',\n",
      "                    'args',\n",
      "                    ')'],\n",
      "  'encoder_input': ['return',\n",
      "                    'value',\n",
      "                    'of',\n",
      "                    'the',\n",
      "                    'npath',\n",
      "                    'function',\n",
      "                    'with',\n",
      "                    'string',\n",
      "                    \"'.mo'\",\n",
      "                    'appended',\n",
      "                    'to',\n",
      "                    'the',\n",
      "                    'base_path',\n",
      "                    'as',\n",
      "                    'argument',\n",
      "                    ',',\n",
      "                    'and',\n",
      "                    'return',\n",
      "                    'value',\n",
      "                    'of',\n",
      "                    'the',\n",
      "                    'npath',\n",
      "                    'function',\n",
      "                    'with',\n",
      "                    'string',\n",
      "                    \"'.po'\",\n",
      "                    'appended',\n",
      "                    'to',\n",
      "                    'the',\n",
      "                    'base_path',\n",
      "                    'as',\n",
      "                    'argument',\n",
      "                    ',',\n",
      "                    'substitute',\n",
      "                    'it',\n",
      "                    'for',\n",
      "                    'args',\n",
      "                    '.',\n",
      "                    'call',\n",
      "                    'the',\n",
      "                    'popen_wrapper',\n",
      "                    'with',\n",
      "                    'args',\n",
      "                    'as',\n",
      "                    'the',\n",
      "                    'argument',\n",
      "                    ',',\n",
      "                    'assign',\n",
      "                    'the',\n",
      "                    'result',\n",
      "                    'to',\n",
      "                    'the',\n",
      "                    'output',\n",
      "                    ',',\n",
      "                    'errors',\n",
      "                    'and',\n",
      "                    'status',\n",
      "                    ',',\n",
      "                    'respectively',\n",
      "                    '.'],\n",
      "  'target_commands': ['K', 'R', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K'],\n",
      "  'target_insertions': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "  'target_replacements': ['<pad>',\n",
      "                          'output',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>']}]\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0]\n",
    "doc_ranking = retriever.BM25_search(x)\n",
    "top_2_doc = data[doc_ranking[2].doc] # get the second best document since the best doc is the same from the description\n",
    "x_, y_ = top_2_doc\n",
    "\n",
    "# convert to token array\n",
    "x = string_split(x)\n",
    "y = [\"<sos>\"] + string_split(y)\n",
    "x_ = string_split(x_)\n",
    "y_ = [\"<sos>\"] + string_split(y_)\n",
    "\n",
    "print(y, y_)\n",
    "\n",
    "dataset_edit_samples = []\n",
    "while y_ != y:\n",
    "    edit_steps = single_step_edits(y_, y)\n",
    "    commands, insertions, replacements = edit_steps\n",
    "    sample = {\n",
    "        \"encoder_input\": x,\n",
    "        \"decoder_input\": y_.copy(),\n",
    "        \"target_commands\": commands,\n",
    "        \"target_insertions\": insertions,\n",
    "        \"target_replacements\": replacements,\n",
    "        \"code_target\": y\n",
    "    }\n",
    "    dataset_edit_samples.append(sample)\n",
    "    y_ = perform_edits(y_, edit_steps, gen_tok_id=\"<gen>\")\n",
    "\n",
    "pprint(dataset_edit_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the dataset\n",
    "The trick to modularizing models effectively is to make important functions that are necessary to them. `data2dataset()` is one suuch example. Taking in the dataset provided from the paper and converting it into the format needed to train our edit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = Field(sequential=True, use_vocab=False, unk_token=0, pad_token=3)\n",
    "OOV_TEXT_FIELD = Field(sequential=True, use_vocab=False, pad_token=3)\n",
    "\n",
    "def data2dataset(data, desc_rank=1):\n",
    "    TEXT_FIELD = Field(sequential=True, use_vocab=False, unk_token=0, pad_token=3)\n",
    "    OOV_TEXT_FIELD = Field(sequential=True, use_vocab=False, pad_token=3)\n",
    "    \n",
    "    OOV_stoi = {}\n",
    "    OOV_itos = {}\n",
    "    OOV_starter_count = 30000\n",
    "    OOV_count = OOV_starter_count\n",
    "    \n",
    "    examples = []\n",
    "\n",
    "    for (src, tgt) in data:\n",
    "        \n",
    "#         print(src)\n",
    "        doc_ranking = retriever.BM25_search(src)\n",
    "        if len(doc_ranking) > 1:\n",
    "            top_2_doc = data[doc_ranking[desc_rank].doc]\n",
    "            x_, y_ = top_2_doc\n",
    "        else:\n",
    "            x_, y_ = \"\", \"\"\n",
    "        src_ids, OOVs = encode_input(src)\n",
    "        decoder_input = encode_output(y_, OOVs)\n",
    "        ground_truth_code = encode_output(tgt, OOVs)\n",
    "        \n",
    "        decoder_input = [stoi[\"<sos>\"]] + decoder_input\n",
    "        ground_truth_code = [stoi[\"<sos>\"]] + ground_truth_code\n",
    "        \n",
    "        ran_once = False\n",
    "        \n",
    "        while decoder_input != ground_truth_code or not ran_once:\n",
    "            ran_once = True\n",
    "            edit_steps = single_step_edits(decoder_input, ground_truth_code, pad_token=stoi[\"<pad>\"], token_insertions=2)\n",
    "            commands, target_insertions, target_replacements = edit_steps\n",
    "            \n",
    "            target_commands = encode_commands(commands)\n",
    "#             target_replacements = encode_output(replacements, OOVs, from_list=True)\n",
    "            \n",
    "#             print(src_ids)\n",
    "#             print(decoder_input)\n",
    "#             print(decode(decoder_input, OOVs))\n",
    "#             print(ground_truth_code)\n",
    "#             print(decode(ground_truth_code, OOVs))\n",
    "#             print(target_commands)\n",
    "#             print(target_insertions)\n",
    "#             print(target_replacements)\n",
    "#             print()\n",
    "            \n",
    "#             print(len(decoder_input) == len(target_commands))\n",
    "\n",
    "            \n",
    "            OOV_ids = []\n",
    "\n",
    "            for OOV in OOVs:\n",
    "                try:\n",
    "                    idx = OOV_stoi[OOV]\n",
    "                    OOV_ids.append(idx)\n",
    "                except KeyError as e:\n",
    "                    OOV_count += 1\n",
    "                    OOV_stoi[OOV] = OOV_count\n",
    "                    OOV_itos[OOV_count] = OOV\n",
    "                    OOV_ids.append(OOV_count)\n",
    "                    \n",
    "            \n",
    "            if \"<DELETE_ME>\" in decoder_input:\n",
    "                print(decoder_input)\n",
    "\n",
    "            example = torchtext.data.Example.fromdict({\"encoder_input\":src_ids, \n",
    "                                                       \"ground_truth_code\":ground_truth_code, \n",
    "                                                       \"OOVs\":OOV_ids, \n",
    "                                                       \"decoder_input\":decoder_input,\n",
    "                                                       \"target_commands\":target_commands, \n",
    "                                                       \"target_insertions\": target_insertions,\n",
    "                                                       \"target_replacements\":target_replacements}, \n",
    "                                                    fields={\"encoder_input\":(\"encoder_input\",TEXT_FIELD), \n",
    "                                                            \"ground_truth_code\":(\"ground_truth_code\",TEXT_FIELD),\n",
    "                                                            \"OOVs\":(\"OOVs\", OOV_TEXT_FIELD), \n",
    "                                                            \"decoder_input\":(\"decoder_input\",TEXT_FIELD),\n",
    "                                                            \"target_commands\":(\"target_commands\",TEXT_FIELD), \n",
    "                                                            \"target_insertions\": (\"target_insertions\",TEXT_FIELD),\n",
    "                                                            \"target_replacements\":(\"target_replacements\",TEXT_FIELD)})\n",
    "            examples.append(example)\n",
    "            decoder_input = perform_edits(decoder_input, edit_steps, gen_tok_id=stoi[\"<gen>\"])\n",
    "    return examples\n",
    "\n",
    "examples = data2dataset(data, desc_rank=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['errd', 'foo', 'd']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [\"foo\",\"errd\",\"d\"]\n",
    "    \n",
    "sorted(p, key=lambda x: -len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchtext.data.Dataset(examples,fields={\"encoder_input\":TEXT_FIELD, \n",
    "                                                  \"ground_truth_code\":TEXT_FIELD, \n",
    "                                                  \"OOVs\":OOV_TEXT_FIELD, \n",
    "                                                  \"decoder_input\":TEXT_FIELD, \n",
    "                                                  \"target_commands\":TEXT_FIELD, \n",
    "                                                  \"target_insertions\":TEXT_FIELD, \n",
    "                                                  \"target_replacements\":TEXT_FIELD})\n",
    "\n",
    "train_dataset, val_dataset = dataset.split([0.9,0.1])\n",
    "# train_dataset = val_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input    : substitute http_cookies . Morsel for Morsel . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "decoder_input    : <sos> dict . __setitem__ ( self , key , http_cookies . Morsel ( ) )\n",
      "ground_truth_code: <sos> Morsel = http_cookies . Morsel <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "target_commands  : [0, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 1, 1, 1]\n",
      "15 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_iterator = BucketIterator(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    repeat=True,\n",
    "    shuffle=True,\n",
    "    sort_key = lambda x: len(x.encoder_input)+len(x.decoder_input), # this doesn't seem to work, check it out later\n",
    "    device = device)\n",
    "\n",
    "# The iterator generates batches with padded length for sequences with similar sizes, a batch is [seq_length, batch_size]\n",
    "\n",
    "for i, batch in enumerate(train_iterator):\n",
    "    idx = 2\n",
    "#     print([SRC_TEXT.vocab.itos[id] for id in batch.src.cpu().numpy()[:,idx]])\n",
    "    OOVs = [OOV_itos[OOV] for OOV in batch.OOVs.cpu()[:,idx].tolist() if OOV != 3] # 3 is the <pad> token\n",
    "    encoder_input = batch.encoder_input.cpu()[:,idx].tolist()\n",
    "    decoder_input = batch.decoder_input.cpu()[:,idx].tolist()\n",
    "    ground_truth_code = batch.ground_truth_code.cpu()[:,idx].tolist()\n",
    "    target_commands = batch.target_commands.cpu()[:,idx].tolist()\n",
    "    \n",
    "    print(\"encoder_input    :\",decode(encoder_input, OOVs))\n",
    "    print(\"decoder_input    :\",decode(decoder_input, OOVs))\n",
    "    print(\"ground_truth_code:\",decode(ground_truth_code, OOVs))\n",
    "    print(\"target_commands  :\", target_commands)\n",
    "    print(len(decoder_input), len(target_commands))\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size=512, dropout=0.5):\n",
    "        super(CopyModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.pos_encoder = PositionalEncoding(embedding_size, dropout)\n",
    "        self.src_encoder = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.tgt_encoder = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        self.transformer = Transformer(d_model=embedding_size, nhead=8, num_encoder_layers=4, num_decoder_layers=4, dim_feedforward=1024)\n",
    "        self.replacement_decoder = nn.Linear(embedding_size, vocab_size)\n",
    "        self.insertion_decoder = nn.Linear(embedding_size, max_insertions)\n",
    "        self.command_decoder = nn.Linear(embedding_size, len(edit_stoi))\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.p_generator = nn.Linear(embedding_size,1)\n",
    "\n",
    "        self.init_weights()\n",
    "        self.tgt_mask = None\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.src_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.tgt_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.replacement_decoder.bias.data.zero_()\n",
    "        self.replacement_decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.insertion_decoder.bias.data.zero_()\n",
    "        self.insertion_decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.command_decoder.bias.data.zero_()\n",
    "        self.command_decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "#         noise_e = 0.05 if self.training else 0.0 # this is code to add noise to the decoding process during training\n",
    "        noise_e = 0.0 if self.training else 0.0\n",
    "        noise_mask = (torch.rand(sz,sz) > noise_e).float()\n",
    "\n",
    "        mask = (torch.triu(torch.ones(sz,sz))).transpose(0, 1)\n",
    "        mask = torch.mul(mask, noise_mask)\n",
    "        v = (torch.sum(mask, dim=-1) == 0).float()\n",
    "\n",
    "        fix_mask = torch.zeros(sz,sz)\n",
    "        fix_mask[:,0] = 1.0\n",
    "        v = v.repeat(sz, 1).transpose(0,1)\n",
    "        fix_mask = torch.mul(fix_mask,v)\n",
    "\n",
    "        mask += fix_mask\n",
    "        \n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        self.tgt_mask = self._generate_square_subsequent_mask(len(tgt)).to(self.device)\n",
    "        \n",
    "\n",
    "        src_emb = self.src_encoder(src) * math.sqrt(self.embedding_size)\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "        \n",
    "        tgt_emb = self.tgt_encoder(tgt) * math.sqrt(self.embedding_size)\n",
    "        tgt_emb = self.pos_encoder(tgt_emb)\n",
    "        \n",
    "        output, atts = self.transformer(src_emb, tgt_emb, tgt_mask=self.tgt_mask)\n",
    "        \n",
    "        \n",
    "        src_scat = src.transpose(0,1)\n",
    "        src_scat = src_scat.unsqueeze(0)\n",
    "        src_scat = torch.repeat_interleave(src_scat, tgt.shape[0], dim=0)\n",
    "#         print(\"src_scat.shqape\", src_scat.shape)\n",
    "        \n",
    "        p_gens = self.p_generator(output).sigmoid()\n",
    "        atts = atts.transpose(0,1)\n",
    "#         print(\"att.shqape\", atts.shape)\n",
    "        atts = atts * (1 - p_gens)\n",
    "                \n",
    "        target_replacements = self.replacement_decoder(output)\n",
    "#         output[:,:,12:] = -np.inf\n",
    "        target_replacements = target_replacements.softmax(-1)\n",
    "        target_replacements = target_replacements * p_gens\n",
    "        \n",
    "        target_replacements = target_replacements.scatter_add_(2,src_scat,atts)\n",
    "        \n",
    "        target_insertions = self.insertion_decoder(output)\n",
    "        \n",
    "        target_commands = self.command_decoder(output)\n",
    "        \n",
    "        return target_commands, target_insertions, target_replacements.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi[\"','\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2, 4]), torch.Size([5, 2, 20]), torch.Size([5, 2, 9378]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos) + max_seq_length\n",
    "\n",
    "model = CopyModel(vocab_size).to(device) \n",
    "src = torch.randint(0, vocab_size, (3,2)).to(device)\n",
    "tgt = torch.randint(0, vocab_size, (5,2)).to(device)\n",
    "\n",
    "target_commands, target_insertions, target_replacements = model(src, tgt)\n",
    "target_commands.shape, target_insertions.shape, target_replacements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_bleu(refrence, prediction):\n",
    "    \"\"\"\n",
    "    Implementation from ReCode\n",
    "    and moses multi belu script sets BLEU to 0.0 if len(toks) < 4\n",
    "    \"\"\"\n",
    "    ngram_weights = [0.25] * min(4, len(refrence))\n",
    "    return sentence_bleu([refrence], prediction, weights=ngram_weights, \n",
    "                          smoothing_function=SmoothingFunction().method3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmpad(arr):\n",
    "    pad_id = stoi[\"<pad>\"]\n",
    "    return [x for x in arr if x != pad_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input      : help is a tuple containing a string \"Output the contents of the database as a fixture of the given \"\n",
      "ground_truth_code  : <sos> help = ( \"Output the contents of the database as a fixture of the given \" \"format (using each model's default manager unless --all is \" \"specified).\" )\n",
      "decoder_input      : <sos> missing_args_message = ( \"No database fixture specified. Please provide the \" \"path of at least one fixture in the command line.\" )\n",
      "gt_target_commands : [0, 2, 0, 0, 2, 2, 0]\n",
      "gt_target_insertions: [0, 0, 0, 2, 0, 0, 0]\n",
      "gt_target_replacements: help \"format (using each model's default manager unless --all is \" \"specified).\"\n",
      "gt_edited_code     : <sos> help = ( <gen> <gen> \"format (using each model's default manager unless --all is \" \"specified).\" )\n",
      "\n",
      "encoder_input      : define the function pbkdf2 with 5 arguments : password , salt , iterations , dklen set to integer 0 and digest set to None .\n",
      "ground_truth_code  : <sos> def pbkdf2 ( password , salt , iterations , dklen = 0 , digest = None ) :\n",
      "decoder_input      : <sos> def pbkdf2 ( password , salt , iterations , dklen = 0 , digest = None ) :\n",
      "gt_target_commands : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "gt_target_insertions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "gt_target_replacements: \n",
      "gt_edited_code     : <sos> def pbkdf2 ( password , salt , iterations , dklen = 0 , digest = None ) :\n",
      "\n",
      "encoder_input      : call the function import_string with an argument dotted_path , substitute the result for attr .\n",
      "ground_truth_code  : <sos> attr = import_string ( dotted_path )\n",
      "decoder_input      : <sos> def import_string ( dotted_path ) :\n",
      "gt_target_commands : [0, 2, 0, 0, 0, 0, 1]\n",
      "gt_target_insertions: [2, 0, 0, 0, 0, 0, 0]\n",
      "gt_target_replacements: =\n",
      "gt_edited_code     : <sos> <gen> <gen> = import_string ( dotted_path )\n",
      "\n",
      "encoder_input      : call the method qs . using with an argument form . instance . _state . db , substitute the result for qs .\n",
      "ground_truth_code  : <sos> qs = qs . using ( form . instance . _state . db )\n",
      "decoder_input      : <sos> qs = qs . using ( <gen> <gen> instance <gen> <gen> )\n",
      "gt_target_commands : [0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0]\n",
      "gt_target_insertions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0]\n",
      "gt_target_replacements: form . . db\n",
      "gt_edited_code     : <sos> qs = qs . using ( form . instance <gen> <gen> . db )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def outputs2code(target_commands, target_insertions, target_replacements, decoder_input):\n",
    "    batch_size = target_commands.shape[1]\n",
    "    \n",
    "    edited_code_samples = []\n",
    "    for i in range(batch_size):\n",
    "        code_to_edit = rmpad(decoder_input[:,i].tolist())\n",
    "        code_length = len(code_to_edit)\n",
    "        \n",
    "        sample_commands = target_commands[:code_length,i].view(-1).tolist()\n",
    "#         print(sample_commands)\n",
    "        sample_commands = decode_commands(sample_commands)\n",
    "        sample_insertions = target_insertions[:code_length,i].view(-1).tolist()\n",
    "        sample_replacements = target_replacements[:code_length,i].view(-1).tolist()\n",
    "        \n",
    "        \n",
    "        \n",
    "        edits = (sample_commands, sample_insertions, sample_replacements)\n",
    "        \n",
    "        edited_code = perform_edits(code_to_edit, edits, gen_tok_id=stoi[\"<gen>\"])\n",
    "        \n",
    "        edited_code_samples.append(edited_code)\n",
    "        \n",
    "    max_sample_len = max([len(sample) for sample in edited_code_samples])\n",
    "    edited_code_samples = [(sample + max_sample_len * [stoi[\"<pad>\"]])[:max_sample_len] for sample in edited_code_samples]\n",
    "    return torch.tensor(edited_code_samples).T.to(device)\n",
    "    \n",
    "        \n",
    "batch = next(iter(train_iterator))\n",
    "decoder_input = batch.decoder_input\n",
    "encoder_input = batch.encoder_input\n",
    "ground_truth_code = batch.ground_truth_code\n",
    "OOVss = batch.OOVs\n",
    "\n",
    "gt_target_commands = batch.target_commands\n",
    "gt_target_insertions = batch.target_insertions\n",
    "gt_target_replacements = batch.target_replacements\n",
    "\n",
    "gt_edited_code = outputs2code(gt_target_commands, gt_target_insertions, gt_target_replacements, decoder_input)\n",
    "\n",
    "target_commands, target_insertions, target_replacements = model(encoder_input, decoder_input)\n",
    "\n",
    "_, argmax_target_commands = target_commands.max(2)\n",
    "_, argmax_target_insertions = target_insertions.max(2)\n",
    "_, argmax_target_replacements = target_replacements.max(2)\n",
    "\n",
    "outputs2code(argmax_target_commands, argmax_target_insertions, argmax_target_replacements, decoder_input)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print(\"encoder_input      :\", decode(rmpad(encoder_input[:,i].tolist()), []))\n",
    "    print(\"ground_truth_code  :\",decode(rmpad(ground_truth_code[:,i].tolist()), []))\n",
    "    print(\"decoder_input      :\",decode(rmpad(decoder_input[:,i].tolist()), []))\n",
    "    print(\"gt_target_commands :\", rmpad(gt_target_commands[:,i].tolist()))\n",
    "    print(\"gt_target_insertions:\", rmpad(gt_target_insertions[:,i].tolist()))\n",
    "    print(\"gt_target_replacements:\", decode(rmpad(gt_target_replacements[:,i].tolist()), []))\n",
    "    print(\"gt_edited_code     :\",decode(rmpad(gt_edited_code[:,i].tolist()), []))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iterator = BucketIterator(val_dataset,\n",
    "    batch_size = 32,\n",
    "    sort_key = lambda x: len(x.src)+len(x.tgt),\n",
    "    device = device)\n",
    "\n",
    "def batch_filter_ids(batch_list):\n",
    "    return [[id for id in l if id not in [1,2,3]] for l in batch_list]\n",
    "\n",
    "def evaluate(beam_size=1, log=False):\n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    with torch.no_grad(), open(\"out.txt\", \"w\") as out_fp:\n",
    "        BLEU_scores = []\n",
    "        \n",
    "        for i, batch in enumerate(valid_iterator):\n",
    "            batch_size = batch.encoder_input.shape[1]\n",
    "            max_iter = 8\n",
    "            \n",
    "            code_edits_finished = [None] * batch_size\n",
    "            \n",
    "            decoder_input = batch.decoder_input\n",
    "            encoder_input = batch.encoder_input\n",
    "            OOVss = batch.OOVs\n",
    "            \n",
    "            while not all(code_edits_finished) and max_iter > 0:\n",
    "                max_iter -= 1\n",
    "                target_commands, target_insertions, target_replacements = model(encoder_input, decoder_input)\n",
    "                \n",
    "                _, argmax_target_commands = target_commands.max(2)\n",
    "                _, argmax_target_insertions = target_insertions.max(2)\n",
    "                _, argmax_target_replacements = target_replacements.max(2)\n",
    "                                \n",
    "                code_samples = outputs2code(argmax_target_commands, argmax_target_insertions, argmax_target_replacements, decoder_input)\n",
    "                                \n",
    "                for j in range(batch_size):\n",
    "                    if (stoi[\"<gen>\"] not in code_samples[:,j] and code_edits_finished[j] == None) or max_iter == 0:\n",
    "                        code_edits_finished[j] = rmpad(code_samples[:,j].cpu().tolist())\n",
    "                        tgt = rmpad(batch.ground_truth_code[:,j].cpu().tolist())\n",
    "                        pred = encode_output(\n",
    "                                code_edits_finished[j], \n",
    "                                OOVss[:,j].cpu().tolist(), \n",
    "                                from_list=True)\n",
    "                        BLEU = nltk_bleu(\n",
    "                            rmpad(batch.ground_truth_code[:,j].cpu().tolist()),\n",
    "                            code_edits_finished[j])\n",
    "                        BLEU_scores.append(BLEU)\n",
    "                        \n",
    "                        print(\"Target    :\"decode(rmpad(batch.ground_truth_code[:,j].cpu().tolist()), OOVss[:,j].cpu().tolist()))\n",
    "                        print(\"Prediction:\",decode(rmpad(code_samples[:,j].cpu().tolist()), OOVss[:,j].cpu().tolist()))\n",
    "                        print(\"BLEU      :\",BLEU)\n",
    "                        print()\n",
    "                \n",
    "                decoder_input = code_samples\n",
    "                \n",
    "            \n",
    "            ground_truth_code = batch.ground_truth_code\n",
    "                \n",
    "        out_fp.write(\"\\n\\n| EVALUATION | BLEU: {:5.2f} |\\n\".format(np.average(BLEU_scores)))\n",
    "        print(\"| EVALUATION | BLEU: {:5.3f} |\".format(np.average(BLEU_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> all_models = [ ( app_config . label , router . get_migratable_models ( app_config , connection . alias , include_auto_created = True ) ) for app_config in apps . get_app_configs ( ) if app_config . models_module is not None and app_config . label in app_labels ]\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> label in app_labels ]\n",
      "0.02202431506436006\n",
      "\n",
      "<sos> msg . attach ( attachment )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> msg <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> . attach ( body_msg )\n",
      "0.12874330508144838\n",
      "\n",
      "<sos> default_validators = [ validators . validate_ipv4_address ]\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> default_validators <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = [ validators . validate_slug ]\n",
      "0.1892240568795935\n",
      "\n",
      "<sos> for accessor_name , object_list in self . m2m_data . items ( ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> object_list in self . m2m_data . items ( ) :\n",
      "0.44323796909955787\n",
      "\n",
      "<sos> class AppRegistryNotReady ( Exception ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> class <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> ValidationError ( Exception ) :\n",
      "0.195647514979229\n",
      "\n",
      "<sos> if self . load_initial_data :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> if <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> size :\n",
      "0.07495553473355841\n",
      "\n",
      "<sos> except StandardError as e :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> except <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> StandardError as e :\n",
      "0.21142141714303078\n",
      "\n",
      "<sos> def __init__ ( self , data = None , files = None , auto_id = 'id_%s' , prefix = None , initial = None , error_class = ErrorList , label_suffix = None , empty_permitted = False , instance = None ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> def <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> __init__ ( self , data = None , files = None , auto_id = 'id_%s' , prefix = None , initial = None , <gen> <gen> False , instance = None ) :\n",
      "0.6891985314058643\n",
      "\n",
      "<sos> self . requires_system_checks = ( self . requires_system_checks if has_new_option else self . requires_model_validation if has_old_option else True )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> has_new_option <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = hasattr ( self , 'requires_system_checks' )\n",
      "0.05045777123948042\n",
      "\n",
      "<sos> if token = = \"not\" and i + 1 < l and tokens [ i + 1 ] = = \"in\" :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> if <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> i + 1 < len ( chunks ) :\n",
      "0.12690181599215222\n",
      "\n",
      "<sos> raise ValidationError ( ungettext ( \"Please submit %d or fewer forms.\" , \"Please submit %d or fewer forms.\" , self . max_num ) % self . max_num , code = 'too_many_forms' , )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> raise <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> ValidationError ( ungettext ( \"Please submit %d or fewer forms.\" , \"Please submit %d or fewer forms.\" , self . max_num ) % self . max_num , code = <gen> <gen> , )\n",
      "0.5974409230277014\n",
      "\n",
      "<sos> parser . add_argument ( '--liveserver' , action = 'store' , dest = 'liveserver' , default = None , help = 'Overrides the default address where the live server (used ' 'with LiveServerTestCase) is expected to run from. The ' 'default value is localhost:8081.' ) ,\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> parser <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> . add_argument ( '--testrunner' , action = 'store' , dest = 'testrunner' , help = 'Tells Django to use specified test runner class instead of ' 'the one specified by the TEST_RUNNER setting.' ) ,\n",
      "0.3163907400714565\n",
      "\n",
      "<sos> context_extras = { }\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> context_extras <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = { }\n",
      "0.14458924666162856\n",
      "\n",
      "<sos> from django . core . exceptions import ValidationError\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> from <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> django . core . exceptions import ValidationError\n",
      "0.38538569180303145\n",
      "\n",
      "<sos> raise TemplateSyntaxError ( \"'%s' did not receive value(s) for the argument(s): %s\" % ( name , \", \" . join ( \"'%s'\" % p for p in unhandled_params ) ) )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> raise <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> TemplateSyntaxError ( <gen> <gen> p in unhandled_params ) ) )\n",
      "0.25092815504374294\n",
      "\n",
      "<sos> def __init__ ( self , name ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> def <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> __init__ ( self , name ) :\n",
      "0.38538569180303145\n",
      "\n",
      "<sos> return self . __text_cast ( )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> . __text_cast ( )\n",
      "0.17395797375642233\n",
      "\n",
      "<sos> ext_list . extend ( ext . replace ( ' ' , '' ) . split ( ',' ) )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> colors <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = styles . pop ( ) . split ( '/' )\n",
      "0.13520459769143478\n",
      "\n",
      "<sos> super ( DebugParser , self ) . extend_nodelist ( nodelist , node , token )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> ( DebugParser , self <gen> <gen> ( nodelist , node , token )\n",
      "0.3489214645008508\n",
      "\n",
      "<sos> color_names = ( 'black' , 'red' , 'green' , 'yellow' , 'blue' , 'magenta' , 'cyan' , 'white' )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> color_names <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = ( 'black' , <gen> <gen> 'white' )\n",
      "0.16256774711563596\n",
      "\n",
      "<sos> resolved_path . append ( ns )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> resolved_path <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = [ ]\n",
      "0.06178110636313394\n",
      "\n",
      "<sos> def configure_filter ( self , config ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> def <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> __init__ ( self , config ) :\n",
      "0.3168900267453786\n",
      "\n",
      "<sos> for path in all_locale_paths ( ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> def <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> all_locale_paths ( ) :\n",
      "0.18798317647335086\n",
      "\n",
      "<sos> parser = subcommand_cls . create_parser ( '' , cwords [ 0 ] )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> subcommand_cls <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = self . fetch_command ( cwords [ 0 ] )\n",
      "0.21314568971111159\n",
      "\n",
      "<sos> url = url . replace ( '\\\\' , '/' )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> s <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = s . replace ( \"'\" , \"\\\\'\" )\n",
      "0.0931377532902409\n",
      "\n",
      "<sos> return getattr ( self . _caches , 'caches' , { } ) . values ( )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> return <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> getattr ( self . _caches , 'caches' , { } ) <gen> <gen> ( )\n",
      "0.4545438735095376\n",
      "\n",
      "<sos> class TranslatableFile ( object ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> class <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> ManagementUtility ( object ) :\n",
      "0.195647514979229\n",
      "\n",
      "<sos> regexes = self . regexes\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> regexes <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = <gen> <gen> . regexes\n",
      "0.078594386815106\n",
      "\n",
      "<sos> offset = ( len ( self . __starttag_text ) - self . __starttag_text . rfind ( \"\\n\" ) )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> offset <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = ( len ( self . __starttag_text ) <gen> <gen>\n",
      "0.37903259135181483\n",
      "\n",
      "<sos> klass . __new__ = staticmethod ( __new__ )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> obj <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> . _constructor_args = ( args , kwargs )\n",
      "0.03211547431691929\n",
      "\n",
      "<sos> yield line\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> yield <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> data\n",
      "0.17827531042796255\n",
      "\n",
      "<sos> if isinstance ( content , EmailMessage ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> elif <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> not isinstance ( content , Message ) :\n",
      "0.16617429299578945\n",
      "\n",
      "<sos> return cookiedict\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> cookiedict <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = { }\n",
      "0.1098640693749858\n",
      "\n",
      "<sos> except ( OSError , NotImplementedError , AttributeError ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> except <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> ( OSError , <gen> <gen> AttributeError ) :\n",
      "0.1527678022374703\n",
      "\n",
      "<sos> for cache in caches . all ( ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> cache <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = caches [ cache_alias ]\n",
      "0.034585921141027376\n",
      "\n",
      "<sos> project_name = settings . SETTINGS_MODULE . split ( '.' ) [ 0 ]\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> generic_lang_code <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = lang_code . split ( '-' ) [ 0 ]\n",
      "0.1845895819969781\n",
      "\n",
      "<sos> @ property\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> @ <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> property\n",
      "0.19729406277958836\n",
      "\n",
      "<sos> self . _load_post_and_files ( )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> self <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> . _load_post_and_files ( )\n",
      "0.21142141714303078\n",
      "\n",
      "<sos> self . render_value = render_value\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> self <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> . render_value <gen> <gen> render_value\n",
      "0.078594386815106\n",
      "\n",
      "<sos> else :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> else <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> :\n",
      "0.19729406277958836\n",
      "\n",
      "<sos> from threading import local\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> from <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> threading import local\n",
      "0.14458924666162856\n",
      "\n",
      "<sos> if isinstance ( stream_or_string , bytes ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> if <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> isinstance ( stream_or_string , bytes ) :\n",
      "0.38538569180303145\n",
      "\n",
      "<sos> for key , value in parse_qsl ( query_string or '' , keep_blank_values = True , encoding = encoding ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> for <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> key , value in parse_qsl ( query_string or '' , keep_blank_values = True ) :\n",
      "0.5418972770407012\n",
      "\n",
      "<sos> utc = pytz . utc if pytz else UTC ( )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> utc <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = <gen> <gen> utc <gen> <gen>\n",
      "0.05816635421147516\n",
      "\n",
      "<sos> models = set ( )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> self <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> . models = set ( )\n",
      "0.23961829057131984\n",
      "\n",
      "<sos> def ordered_forms ( self ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> raise <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> AttributeError ( \"'%s' object has no attribute 'ordered_forms'\" % self . __class__ . __name__ )\n",
      "0.027076576267554487\n",
      "\n",
      "<sos> kwargs [ \"required\" ] = False\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> kwargs <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> [ 'localize' ] = True\n",
      "0.078594386815106\n",
      "\n",
      "<sos> options + = [ ( s_opt . get_opt_string ( ) , s_opt . nargs ) for s_opt in parser . option_list ]\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> options <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> + = [ ( sorted ( s_opt . option_strings ) [ 0 ] , s_opt . nargs ! = 0 ) for s_opt in parser . _actions if s_opt . option_strings ]\n",
      "0.26491132489549474\n",
      "\n",
      "<sos> @ classmethod\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> @ <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> classmethod\n",
      "0.19729406277958836\n",
      "\n",
      "<sos> bits . append ( force_text ( bit ) )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> bits <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> . append ( <gen> <gen> bit ) <gen> <gen>\n",
      "0.11076007888812259\n",
      "\n",
      "<sos> return ( copyreg . _reconstructor , ( self . __class__ , object , None ) , self . __getstate__ ( ) )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> return <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> ( copyreg . _reconstructor , ( self . __class__ , <gen> <gen> ) , self . __getstate__ ( ) )\n",
      "0.5428586816526576\n",
      "\n",
      "<sos> elif self . _delegate_text :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> elif <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> self . _delegate_text :\n",
      "0.21142141714303078\n",
      "\n",
      "<sos> self . ignore = options . pop ( 'ignorenonexistent' , False )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> ignore <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = options . pop ( 'ignorenonexistent' , False )\n",
      "0.4464617303464354\n",
      "\n",
      "<sos> import io\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> import <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> io\n",
      "0.19729406277958836\n",
      "\n",
      "<sos> raise ImproperlyConfigured ( 'The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.' )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> raise <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> TypeError ( \"sep must be None or a string\" )\n",
      "0.06754312828675708\n",
      "\n",
      "<sos> if value is True :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> value <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = True\n",
      "0.044568827606990644\n",
      "\n",
      "<sos> parts = viewname . split ( ':' )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> new_ip <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> = ip_str . split ( ':' )\n",
      "0.23287896954139942\n",
      "\n",
      "<sos> if set ( kwargs . keys ( ) ) | set ( defaults . keys ( ) ) ! = set ( params ) | set ( defaults . keys ( ) ) | set ( prefix_args ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> ) | set ( <gen> <gen> prefix_args ) :\n",
      "0.06593630010264945\n",
      "\n",
      "<sos> def __init__ ( self , request , dict_ = None , processors = None , current_app = None , use_l10n = None , use_tz = None ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> def <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> __init__ ( self , dict_ = None , autoescape = True , current_app = None , use_l10n = None , use_tz = None ) :\n",
      "0.561540837289191\n",
      "\n",
      "<sos> if self . domain_regex . match ( domain_part ) :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> if <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> self . validate_domain_part ( domain_part ) :\n",
      "0.19345299022826185\n",
      "\n",
      "<sos> yield buf . read ( )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> yield <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> buf . read ( )\n",
      "0.2829559628326351\n",
      "\n",
      "<sos> cache_timeout = 0\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> if <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> cache_timeout < 0 :\n",
      "0.03737437943747671\n",
      "\n",
      "<sos> loop_dict [ 'first' ] = ( i = = 0 )\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> loop_dict <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> [ 'last' ] = ( i = = len_values - 1 )\n",
      "0.25306188056493334\n",
      "\n",
      "<sos> except Model . DoesNotExist :\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "<sos> if <gen> <gen> <gen> <gen> <gen> <gen> <gen> <gen> ( obj . pk is None and hasattr ( Model , 'natural_key' ) and hasattr ( Model . _default_manager , 'get_by_natural_key' ) ) :\n",
      "0.025889065173943994\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-ee948df27117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-249-4ef1a8c7e00f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(beam_size, log)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_edits_finished\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mmax_iter\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mtarget_commands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_insertions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_replacements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax_target_commands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-159382112ae6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mtgt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/my_shared/notebooks/models_and_trainers/copy_gen_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    357\u001b[0m         output, atts = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001b[1;32m    358\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                               memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/my_shared/notebooks/models_and_trainers/copy_gen_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    468\u001b[0m                                     \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                                     \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                                     memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/my_shared/notebooks/models_and_trainers/copy_gen_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \"\"\"\n\u001b[1;32m    594\u001b[0m         tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n\u001b[0;32m--> 595\u001b[0;31m                               key_padding_mask=tgt_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3345\u001b[0m                                                device=key_padding_mask.device)], dim=1)\n\u001b[1;32m   3346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3347\u001b[0;31m     \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3348\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi['<pad>'])\n",
    "lr = 0.005 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    vocab_size = len(itos) + max_seq_length\n",
    "    encoder_input = batch.encoder_input\n",
    "    decoder_input = batch.decoder_input\n",
    "    ground_truth_commands = batch.target_commands\n",
    "    ground_truth_insertions = batch.target_insertions\n",
    "    ground_truth_replacements = batch.target_replacements\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    target_commands, target_insertions, target_replacements = model(encoder_input, decoder_input)\n",
    "\n",
    "    \n",
    "    command_loss = criterion(target_commands.view(-1, len(edit_stoi)), ground_truth_commands.view(-1))\n",
    "    insertion_loss = criterion(target_insertions.view(-1, max_insertions), ground_truth_insertions.view(-1))\n",
    "    replacement_loss = criterion(target_replacements.view(-1, vocab_size), ground_truth_replacements.view(-1))\n",
    "    \n",
    "    loss = command_loss + insertion_loss + replacement_loss\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "    elapsed = time.time() - start_time\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     4/1000000 steps | lr 0.0050 | ms/batch 528.08 | loss 11.92 | ppl 150092.90\n",
      "|     8/1000000 steps | lr 0.0050 | ms/batch 588.28 | loss  9.20 | ppl  9873.35\n",
      "|    12/1000000 steps | lr 0.0050 | ms/batch 574.45 | loss  8.94 | ppl  7595.55\n",
      "|    16/1000000 steps | lr 0.0050 | ms/batch 568.42 | loss  9.91 | ppl 20176.67\n",
      "|    20/1000000 steps | lr 0.0050 | ms/batch 507.27 | loss  7.97 | ppl  2900.74\n",
      "|    24/1000000 steps | lr 0.0050 | ms/batch 524.54 | loss  7.79 | ppl  2427.73\n",
      "|    28/1000000 steps | lr 0.0050 | ms/batch 582.48 | loss  8.09 | ppl  3250.94\n",
      "|    32/1000000 steps | lr 0.0050 | ms/batch 561.84 | loss  8.66 | ppl  5759.95\n",
      "|    36/1000000 steps | lr 0.0050 | ms/batch 599.12 | loss  9.50 | ppl 13351.32\n",
      "|    40/1000000 steps | lr 0.0050 | ms/batch 631.95 | loss  8.60 | ppl  5448.22\n",
      "|    44/1000000 steps | lr 0.0050 | ms/batch 575.42 | loss  7.03 | ppl  1131.00\n",
      "|    48/1000000 steps | lr 0.0050 | ms/batch 498.92 | loss  7.27 | ppl  1434.77\n",
      "|    52/1000000 steps | lr 0.0050 | ms/batch 514.23 | loss  5.97 | ppl   391.14\n",
      "|    56/1000000 steps | lr 0.0050 | ms/batch 519.04 | loss  7.10 | ppl  1212.33\n",
      "|    60/1000000 steps | lr 0.0050 | ms/batch 470.65 | loss  5.00 | ppl   147.85\n",
      "|    64/1000000 steps | lr 0.0050 | ms/batch 538.28 | loss  7.59 | ppl  1978.54\n",
      "|    68/1000000 steps | lr 0.0050 | ms/batch 536.02 | loss  5.34 | ppl   207.67\n",
      "|    72/1000000 steps | lr 0.0050 | ms/batch 536.42 | loss  8.88 | ppl  7178.84\n",
      "|    76/1000000 steps | lr 0.0050 | ms/batch 499.84 | loss  7.25 | ppl  1410.65\n",
      "|    80/1000000 steps | lr 0.0050 | ms/batch 533.22 | loss  8.14 | ppl  3446.06\n",
      "|    84/1000000 steps | lr 0.0050 | ms/batch 509.92 | loss  6.99 | ppl  1086.07\n",
      "|    88/1000000 steps | lr 0.0050 | ms/batch 557.66 | loss  6.06 | ppl   426.86\n",
      "|    92/1000000 steps | lr 0.0050 | ms/batch 596.74 | loss  7.57 | ppl  1931.23\n",
      "|    96/1000000 steps | lr 0.0050 | ms/batch 550.33 | loss  5.93 | ppl   376.57\n",
      "|   100/1000000 steps | lr 0.0050 | ms/batch 514.23 | loss  6.17 | ppl   480.28\n",
      "|   104/1000000 steps | lr 0.0050 | ms/batch 636.70 | loss  7.50 | ppl  1808.49\n",
      "|   108/1000000 steps | lr 0.0050 | ms/batch 551.60 | loss  7.37 | ppl  1594.97\n",
      "|   112/1000000 steps | lr 0.0050 | ms/batch 599.58 | loss  6.19 | ppl   488.91\n",
      "|   116/1000000 steps | lr 0.0050 | ms/batch 612.94 | loss  8.00 | ppl  2978.75\n",
      "|   120/1000000 steps | lr 0.0050 | ms/batch 575.14 | loss  9.15 | ppl  9421.00\n",
      "|   124/1000000 steps | lr 0.0050 | ms/batch 549.78 | loss  6.26 | ppl   523.53\n",
      "|   128/1000000 steps | lr 0.0050 | ms/batch 586.15 | loss  6.68 | ppl   796.92\n",
      "|   132/1000000 steps | lr 0.0050 | ms/batch 591.16 | loss  7.80 | ppl  2436.58\n",
      "|   136/1000000 steps | lr 0.0050 | ms/batch 565.25 | loss  6.27 | ppl   525.87\n",
      "|   140/1000000 steps | lr 0.0050 | ms/batch 561.32 | loss  5.13 | ppl   169.49\n",
      "|   144/1000000 steps | lr 0.0050 | ms/batch 552.47 | loss  7.78 | ppl  2395.24\n",
      "|   148/1000000 steps | lr 0.0050 | ms/batch 568.27 | loss  6.52 | ppl   677.68\n",
      "|   152/1000000 steps | lr 0.0050 | ms/batch 499.84 | loss  5.05 | ppl   155.93\n",
      "|   156/1000000 steps | lr 0.0050 | ms/batch 522.05 | loss  6.26 | ppl   523.62\n",
      "|   160/1000000 steps | lr 0.0050 | ms/batch 536.53 | loss  3.92 | ppl    50.62\n",
      "|   164/1000000 steps | lr 0.0050 | ms/batch 540.55 | loss  6.78 | ppl   881.46\n",
      "|   168/1000000 steps | lr 0.0050 | ms/batch 561.97 | loss  7.87 | ppl  2605.47\n",
      "|   172/1000000 steps | lr 0.0050 | ms/batch 573.70 | loss  7.60 | ppl  1995.76\n",
      "|   176/1000000 steps | lr 0.0050 | ms/batch 530.68 | loss  7.65 | ppl  2095.76\n",
      "|   180/1000000 steps | lr 0.0050 | ms/batch 535.13 | loss  7.67 | ppl  2153.26\n",
      "|   184/1000000 steps | lr 0.0050 | ms/batch 546.80 | loss  5.58 | ppl   265.21\n",
      "|   188/1000000 steps | lr 0.0050 | ms/batch 578.68 | loss  8.40 | ppl  4462.28\n",
      "|   192/1000000 steps | lr 0.0050 | ms/batch 583.51 | loss  5.19 | ppl   178.76\n",
      "|   196/1000000 steps | lr 0.0050 | ms/batch 530.88 | loss  5.78 | ppl   323.99\n",
      "|   200/1000000 steps | lr 0.0050 | ms/batch 511.54 | loss  7.65 | ppl  2109.88\n",
      "|   204/1000000 steps | lr 0.0050 | ms/batch 561.05 | loss  7.52 | ppl  1838.54\n",
      "|   208/1000000 steps | lr 0.0050 | ms/batch 556.65 | loss  6.92 | ppl  1015.19\n",
      "|   212/1000000 steps | lr 0.0050 | ms/batch 579.15 | loss  6.29 | ppl   539.22\n",
      "|   216/1000000 steps | lr 0.0050 | ms/batch 586.35 | loss  6.60 | ppl   732.00\n",
      "|   220/1000000 steps | lr 0.0050 | ms/batch 582.23 | loss  6.88 | ppl   975.33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-ec4725d202fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-ec4725d202fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(steps, log_interval, learning_interval, eval_interval)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-219dd4a1cc54>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minsertion_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreplacement_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(steps=10000, log_interval=200, learning_interval=4000, eval_interval=1000):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    step = 1\n",
    "    for batch in train_iterator:\n",
    "        loss = train_step(batch)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if step % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| {:5d}/{:5d} steps | '\n",
    "                  'lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    step, steps, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "        if step % eval_interval == 0:\n",
    "            print(\"Evaluating model\")\n",
    "            evaluate()\n",
    "            model.train()\n",
    "        \n",
    "        if step % learning_interval == 0:\n",
    "            scheduler.step()\n",
    "        \n",
    "        step += 1\n",
    "        if step >= steps:\n",
    "            print(\"Finished training\")\n",
    "\n",
    "\n",
    "\n",
    "            return\n",
    "\n",
    "train(steps=1000000,eval_interval=10000,log_interval=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
