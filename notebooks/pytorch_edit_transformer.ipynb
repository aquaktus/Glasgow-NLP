{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy-Generator Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from queue import PriorityQueue\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import tqdm\n",
    "from torchnlp.metrics import get_moses_multi_bleu\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
    "from io import BytesIO\n",
    "\n",
    "import linecache\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import operator\n",
    "import collections\n",
    "from pprint import pprint\n",
    "\n",
    "from models_and_trainers.base_transformer import TransformerModel, PositionalEncoding\n",
    "from models_and_trainers.copy_gen_transformer import Transformer, TransformerDecoderLayer, TransformerDecoder\n",
    "from models_and_trainers.retrieval import PyLuceneRetriever\n",
    "import beam_search\n",
    "from utils.edit_tagger import build_matrix, single_step_edits, perform_edits, get_tags\n",
    "\n",
    "from IPython.core.debugger import set_trace as tr\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def super_print(filename):\n",
    "    '''filename is the file where output will be written'''\n",
    "    def wrap(func):\n",
    "        '''func is the function you are \"overriding\", i.e. wrapping'''\n",
    "        def wrapped_func(*args,**kwargs):\n",
    "            '''*args and **kwargs are the arguments supplied \n",
    "            to the overridden function'''\n",
    "            #use with statement to open, write to, and close the file safely\n",
    "            with open(filename,'a') as outputfile:\n",
    "                now = datetime.now()\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                outputfile.write(\"[{}] \".format(dt_string))\n",
    "                outputfile.write(\" \".join(str(x) for x in args))\n",
    "                outputfile.write(\"\\n\")\n",
    "            #now original function executed with its arguments as normal\n",
    "            return func(*args,**kwargs)\n",
    "        return wrapped_func\n",
    "    return wrap\n",
    "\n",
    "print = super_print('logs-copy-gen.txt')(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.set_device(0) # choose GPU from nvidia-smi \n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['create', 'variable', 'student_names', 'with', 'string', \"'foo bar baz'\"]\n"
     ]
    }
   ],
   "source": [
    "text = \"create variable student_names with string 'foo bar baz'\"\n",
    "\n",
    "def string_split(s):\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(_|\\W)', s))) # this will chunk all code properly by plits strings with quotes\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|_|\\W)', s))) # this keeps the strings intact\n",
    "    return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|\\W)', s)))\n",
    "\n",
    "print(string_split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_array(src_fp, tgt_fp):\n",
    "    lines = []\n",
    "    with open(src_fp, \"r\") as src_file, open(tgt_fp, \"r\") as tgt_file:\n",
    "        for src, tgt in zip(src_file, tgt_file):\n",
    "            lines.append((src, tgt))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_corpus(data, max_seq_length=200, tokenizer=string_split):\n",
    "    return [(src, tgt) for src, tgt in data if len(string_split(src)) <= max_seq_length and len(string_split(tgt)) <= max_seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_dataset(samples):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samples: [(src_string),(tgt_string)]\n",
    "        src/tgt_tokenizer: a func that takes a string and returns an array of strings\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    TEXT_FIELD = Field(sequential=True, use_vocab=False, init_token='<sos>',eos_token='<eos>')\n",
    "    \n",
    "    for sample in samples:\n",
    "        src_string, tgt_string = sample\n",
    "        examples.append(torchtext.data.Example.fromdict({\"src\":src_string, \"tgt\":tgt_string}, \n",
    "                                        fields={\"src\":(\"src\",TEXT_FIELD), \"tgt\":(\"tgt\",TEXT_FIELD)}))\n",
    "        \n",
    "    dataset = torchtext.data.Dataset(examples,fields={\"src\":src_field, \"tgt\":tgt_field})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max src length: 557\n",
      "Max tgt length: 527\n",
      "Full dataset size: 18805\n",
      "Limited dataset size: 18794\n"
     ]
    }
   ],
   "source": [
    "data = corpus_to_array(\"datasets/all.desc\", \"datasets/all.code\")\n",
    "# data = corpus_to_array(\"datasets/all.desc\", \"datasets/all.code\")\n",
    "random.shuffle(data)\n",
    "print(\"Max src length:\", max([len(string_split(src)) for src, tgt in data]))\n",
    "print(\"Max tgt length:\", max([len(string_split(tgt)) for src, tgt in data]))\n",
    "\n",
    "print(\"Full dataset size:\", len(data))\n",
    "max_seq_length=200\n",
    "data = filter_corpus(data, max_seq_length=max_seq_length, tokenizer=string_split)\n",
    "data = [(\" \".join(string_split(src)),\" \".join(string_split(tgt))) for src, tgt in data]\n",
    "print(\"Limited dataset size:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {\"<unk>\":0, \"<sos>\":1, \"<eos>\":2, \"<pad>\":3, \"<gen>\":4}\n",
    "max_vocab = 10000 - len(stoi)\n",
    "\n",
    "all_toks = []\n",
    "for (src, tgt) in data:\n",
    "    all_toks += string_split(src)\n",
    "    all_toks += string_split(tgt)\n",
    "\n",
    "most_freq = collections.Counter(all_toks).most_common(max_vocab)\n",
    "\n",
    "for tok, count in most_freq:\n",
    "    stoi[tok] = len(stoi)\n",
    "    \n",
    "itos = [k for k,v in sorted(stoi.items(), key=lambda kv: kv[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9178\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size: {len(stoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(string, from_list=False):\n",
    "    OOVs = []\n",
    "    IDs = []\n",
    "    if not from_list:\n",
    "        words = string_split(string)\n",
    "    else:\n",
    "        words = string\n",
    "    for word in words:\n",
    "        try:\n",
    "            id = stoi[word]\n",
    "            IDs.append(id)\n",
    "        except KeyError as e:\n",
    "            # word is OOV\n",
    "            IDs.append(len(stoi) + len(OOVs))\n",
    "            OOVs.append(word)\n",
    "    return IDs, OOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(string, OOVs, from_list=False):\n",
    "    IDs = []\n",
    "    if not from_list:\n",
    "        words = string_split(string)\n",
    "    else:\n",
    "        words = string\n",
    "    for word in words:\n",
    "        try:\n",
    "            id = stoi[word]\n",
    "            IDs.append(id)\n",
    "        except KeyError as e:\n",
    "            # word is OOV\n",
    "            try:\n",
    "                IDs.append(len(stoi) + OOVs.index(word))\n",
    "            except ValueError as e:\n",
    "                IDs.append(stoi[\"<unk>\"])\n",
    "    return IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids, OOVs):\n",
    "    extended_itos = itos.copy()\n",
    "    extended_itos += [OOV+\"(COPY)\" for OOV in OOVs]\n",
    "    return \" \".join([extended_itos[id] for id in ids if id<len(extended_itos)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval \n",
    "We want to find the most appropriate code to the input description. For this we use PyLucene to provide a BM25 search over the english descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"return value of the npath function with string '.mo' appended to the base_path as argument , and return value of the npath function with string '.po' appended to the base_path as argument , substitute it for args . call the popen_wrapper with args as the argument , assign the result to the output , errors and status , respectively .\",\n",
       " 'output , errors , status = popen_wrapper ( args )')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = PyLuceneRetriever()\n",
    "\n",
    "src_data = [src for src,tgt in data]\n",
    "retriever.add_multiple_docs(src_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 best matched samples\n",
      "Description: if age is greater than max_age ,\n",
      "Code       : if age > max_age :\n",
      "\n",
      "Description: if start is greater than upto ,\n",
      "Code       : if start > upto :\n",
      "\n",
      "Description: if doublecolon_len is greater than best_doublecolon_len ,\n",
      "Code       : if doublecolon_len > best_doublecolon_len :\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_ranking = retriever.BM25_search(\"is greater than\")\n",
    "doc_ids = [x.doc for x in doc_ranking]\n",
    "retrieved_samples = [data[i] for i in doc_ids]\n",
    "print(\"10 best matched samples\")\n",
    "for doc in retrieved_samples[:10]:\n",
    "    print(f\"Description: {doc[0]}\")\n",
    "    print(f\"Code       : {doc[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Edit steps\n",
    "While there is a vocabulary for the shared english and code. The editing tokens also need to be converted to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_stoi = {\"K\":0, \"D\":1, \"R\":2, \"<pad>\":3}\n",
    "edit_itos = {0:\"K\", 1:\"D\", 2:\"R\", 3:\"<pad>\"}\n",
    "max_insertions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_commands(commands):\n",
    "    return [edit_stoi[command] for command in commands]\n",
    "\n",
    "def decode_commands(commands):\n",
    "    return [edit_itos[command] for command in commands]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single edit example\n",
    "Let's make a complete sample from the dataset.\n",
    "![alt text](./images/edit_transformer_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', 'output', ',', 'errors', ',', 'status', '=', 'popen_wrapper', '(', 'args', ')'] ['<sos>', 'msgs', ',', 'errors', ',', 'status', '=', 'popen_wrapper', '(', 'args', ')']\n",
      "[{'code_target': ['<sos>',\n",
      "                  'output',\n",
      "                  ',',\n",
      "                  'errors',\n",
      "                  ',',\n",
      "                  'status',\n",
      "                  '=',\n",
      "                  'popen_wrapper',\n",
      "                  '(',\n",
      "                  'args',\n",
      "                  ')'],\n",
      "  'decoder_input': ['<sos>',\n",
      "                    'msgs',\n",
      "                    ',',\n",
      "                    'errors',\n",
      "                    ',',\n",
      "                    'status',\n",
      "                    '=',\n",
      "                    'popen_wrapper',\n",
      "                    '(',\n",
      "                    'args',\n",
      "                    ')'],\n",
      "  'encoder_input': ['return',\n",
      "                    'value',\n",
      "                    'of',\n",
      "                    'the',\n",
      "                    'npath',\n",
      "                    'function',\n",
      "                    'with',\n",
      "                    'string',\n",
      "                    \"'.mo'\",\n",
      "                    'appended',\n",
      "                    'to',\n",
      "                    'the',\n",
      "                    'base_path',\n",
      "                    'as',\n",
      "                    'argument',\n",
      "                    ',',\n",
      "                    'and',\n",
      "                    'return',\n",
      "                    'value',\n",
      "                    'of',\n",
      "                    'the',\n",
      "                    'npath',\n",
      "                    'function',\n",
      "                    'with',\n",
      "                    'string',\n",
      "                    \"'.po'\",\n",
      "                    'appended',\n",
      "                    'to',\n",
      "                    'the',\n",
      "                    'base_path',\n",
      "                    'as',\n",
      "                    'argument',\n",
      "                    ',',\n",
      "                    'substitute',\n",
      "                    'it',\n",
      "                    'for',\n",
      "                    'args',\n",
      "                    '.',\n",
      "                    'call',\n",
      "                    'the',\n",
      "                    'popen_wrapper',\n",
      "                    'with',\n",
      "                    'args',\n",
      "                    'as',\n",
      "                    'the',\n",
      "                    'argument',\n",
      "                    ',',\n",
      "                    'assign',\n",
      "                    'the',\n",
      "                    'result',\n",
      "                    'to',\n",
      "                    'the',\n",
      "                    'output',\n",
      "                    ',',\n",
      "                    'errors',\n",
      "                    'and',\n",
      "                    'status',\n",
      "                    ',',\n",
      "                    'respectively',\n",
      "                    '.'],\n",
      "  'target_commands': ['K', 'R', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K'],\n",
      "  'target_insertions': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "  'target_replacements': ['<pad>',\n",
      "                          'output',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>',\n",
      "                          '<pad>']}]\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0]\n",
    "doc_ranking = retriever.BM25_search(x)\n",
    "top_2_doc = data[doc_ranking[2].doc] # get the second best document since the best doc is the same from the description\n",
    "x_, y_ = top_2_doc\n",
    "\n",
    "# convert to token array\n",
    "x = string_split(x)\n",
    "y = [\"<sos>\"] + string_split(y)\n",
    "x_ = string_split(x_)\n",
    "y_ = [\"<sos>\"] + string_split(y_)\n",
    "\n",
    "print(y, y_)\n",
    "\n",
    "dataset_edit_samples = []\n",
    "while y_ != y:\n",
    "    edit_steps = single_step_edits(y_, y)\n",
    "    commands, insertions, replacements = edit_steps\n",
    "    sample = {\n",
    "        \"encoder_input\": x,\n",
    "        \"decoder_input\": y_.copy(),\n",
    "        \"target_commands\": commands,\n",
    "        \"target_insertions\": insertions,\n",
    "        \"target_replacements\": replacements,\n",
    "        \"code_target\": y\n",
    "    }\n",
    "    dataset_edit_samples.append(sample)\n",
    "    y_ = perform_edits(y_, edit_steps, gen_tok_id=\"<gen>\")\n",
    "\n",
    "pprint(dataset_edit_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the dataset\n",
    "The trick to modularizing models effectively is to make important functions that are necessary to them. `data2dataset()` is one suuch example. Taking in the dataset provided from the paper and converting it into the format needed to train our edit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = Field(sequential=True, use_vocab=False, unk_token=0, pad_token=3)\n",
    "OOV_TEXT_FIELD = Field(sequential=True, use_vocab=False, pad_token=3)\n",
    "\n",
    "def data2dataset(data, desc_rank=1):\n",
    "    TEXT_FIELD = Field(sequential=True, use_vocab=False, unk_token=0, pad_token=3)\n",
    "    OOV_TEXT_FIELD = Field(sequential=True, use_vocab=False, pad_token=3)\n",
    "    \n",
    "    OOV_stoi = {}\n",
    "    OOV_itos = {}\n",
    "    OOV_starter_count = 30000\n",
    "    OOV_count = OOV_starter_count\n",
    "    \n",
    "    examples = []\n",
    "\n",
    "    for (src, tgt) in data:\n",
    "        \n",
    "#         print(src)\n",
    "        doc_ranking = retriever.BM25_search(src)\n",
    "        if len(doc_ranking) > 1:\n",
    "            top_2_doc = data[doc_ranking[desc_rank].doc]\n",
    "            x_, y_ = top_2_doc\n",
    "        else:\n",
    "            x_, y_ = \"\", \"\"\n",
    "        src_ids, OOVs = encode_input(src)\n",
    "        decoder_input = encode_output(y_, OOVs)\n",
    "        ground_truth_code = encode_output(tgt, OOVs)\n",
    "        \n",
    "        decoder_input = [stoi[\"<sos>\"]] + decoder_input\n",
    "        ground_truth_code = [stoi[\"<sos>\"]] + ground_truth_code\n",
    "        \n",
    "        ran_once = False\n",
    "        \n",
    "        while decoder_input != ground_truth_code or not ran_once:\n",
    "            ran_once = True\n",
    "            edit_steps = single_step_edits(decoder_input, ground_truth_code, pad_token=stoi[\"<pad>\"], token_insertions=2)\n",
    "            commands, target_insertions, target_replacements = edit_steps\n",
    "            \n",
    "            target_commands = encode_commands(commands)\n",
    "#             target_replacements = encode_output(replacements, OOVs, from_list=True)\n",
    "            \n",
    "#             print(src_ids)\n",
    "#             print(decoder_input)\n",
    "#             print(decode(decoder_input, OOVs))\n",
    "#             print(ground_truth_code)\n",
    "#             print(decode(ground_truth_code, OOVs))\n",
    "#             print(target_commands)\n",
    "#             print(target_insertions)\n",
    "#             print(target_replacements)\n",
    "#             print()\n",
    "            \n",
    "#             print(len(decoder_input) == len(target_commands))\n",
    "\n",
    "            \n",
    "            OOV_ids = []\n",
    "\n",
    "            for OOV in OOVs:\n",
    "                try:\n",
    "                    idx = OOV_stoi[OOV]\n",
    "                    OOV_ids.append(idx)\n",
    "                except KeyError as e:\n",
    "                    OOV_count += 1\n",
    "                    OOV_stoi[OOV] = OOV_count\n",
    "                    OOV_itos[OOV_count] = OOV\n",
    "                    OOV_ids.append(OOV_count)\n",
    "                    \n",
    "            \n",
    "            if \"<DELETE_ME>\" in decoder_input:\n",
    "                print(decoder_input)\n",
    "\n",
    "            example = torchtext.data.Example.fromdict({\"encoder_input\":src_ids, \n",
    "                                                       \"ground_truth_code\":ground_truth_code, \n",
    "                                                       \"OOVs\":OOV_ids, \n",
    "                                                       \"decoder_input\":decoder_input,\n",
    "                                                       \"target_commands\":target_commands, \n",
    "                                                       \"target_insertions\": target_insertions,\n",
    "                                                       \"target_replacements\":target_replacements}, \n",
    "                                                    fields={\"encoder_input\":(\"encoder_input\",TEXT_FIELD), \n",
    "                                                            \"ground_truth_code\":(\"ground_truth_code\",TEXT_FIELD),\n",
    "                                                            \"OOVs\":(\"OOVs\", OOV_TEXT_FIELD), \n",
    "                                                            \"decoder_input\":(\"decoder_input\",TEXT_FIELD),\n",
    "                                                            \"target_commands\":(\"target_commands\",TEXT_FIELD), \n",
    "                                                            \"target_insertions\": (\"target_insertions\",TEXT_FIELD),\n",
    "                                                            \"target_replacements\":(\"target_replacements\",TEXT_FIELD)})\n",
    "            examples.append(example)\n",
    "            decoder_input = perform_edits(decoder_input, edit_steps, gen_tok_id=stoi[\"<gen>\"])\n",
    "    return examples\n",
    "\n",
    "examples = data2dataset(data, desc_rank=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['errd', 'foo', 'd']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [\"foo\",\"errd\",\"d\"]\n",
    "    \n",
    "sorted(p, key=lambda x: -len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchtext.data.Dataset(examples,fields={\"encoder_input\":TEXT_FIELD, \n",
    "                                                  \"ground_truth_code\":TEXT_FIELD, \n",
    "                                                  \"OOVs\":OOV_TEXT_FIELD, \n",
    "                                                  \"decoder_input\":TEXT_FIELD, \n",
    "                                                  \"target_commands\":TEXT_FIELD, \n",
    "                                                  \"target_insertions\":TEXT_FIELD, \n",
    "                                                  \"target_replacements\":TEXT_FIELD})\n",
    "\n",
    "train_dataset, val_dataset = dataset.split([0.9,0.1])\n",
    "# train_dataset = val_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input    : substitute http_cookies . Morsel for Morsel . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "decoder_input    : <sos> dict . __setitem__ ( self , key , http_cookies . Morsel ( ) )\n",
      "ground_truth_code: <sos> Morsel = http_cookies . Morsel <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "target_commands  : [0, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 1, 1, 1]\n",
      "15 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_iterator = BucketIterator(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    repeat=True,\n",
    "    shuffle=True,\n",
    "    sort_key = lambda x: len(x.encoder_input)+len(x.decoder_input), # this doesn't seem to work, check it out later\n",
    "    device = device)\n",
    "\n",
    "# The iterator generates batches with padded length for sequences with similar sizes, a batch is [seq_length, batch_size]\n",
    "\n",
    "for i, batch in enumerate(train_iterator):\n",
    "    idx = 2\n",
    "#     print([SRC_TEXT.vocab.itos[id] for id in batch.src.cpu().numpy()[:,idx]])\n",
    "    OOVs = [OOV_itos[OOV] for OOV in batch.OOVs.cpu()[:,idx].tolist() if OOV != 3] # 3 is the <pad> token\n",
    "    encoder_input = batch.encoder_input.cpu()[:,idx].tolist()\n",
    "    decoder_input = batch.decoder_input.cpu()[:,idx].tolist()\n",
    "    ground_truth_code = batch.ground_truth_code.cpu()[:,idx].tolist()\n",
    "    target_commands = batch.target_commands.cpu()[:,idx].tolist()\n",
    "    \n",
    "    print(\"encoder_input    :\",decode(encoder_input, OOVs))\n",
    "    print(\"decoder_input    :\",decode(decoder_input, OOVs))\n",
    "    print(\"ground_truth_code:\",decode(ground_truth_code, OOVs))\n",
    "    print(\"target_commands  :\", target_commands)\n",
    "    print(len(decoder_input), len(target_commands))\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size=512, dropout=0.5):\n",
    "        super(CopyModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.pos_encoder = PositionalEncoding(embedding_size, dropout)\n",
    "        self.src_encoder = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.tgt_encoder = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        self.transformer = Transformer(d_model=embedding_size, nhead=8, num_encoder_layers=4, num_decoder_layers=4, dim_feedforward=1024)\n",
    "        self.replacement_decoder = nn.Linear(embedding_size, vocab_size)\n",
    "        self.insertion_decoder = nn.Linear(embedding_size, max_insertions)\n",
    "        self.command_decoder = nn.Linear(embedding_size, len(edit_stoi))\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.p_generator = nn.Linear(embedding_size,1)\n",
    "\n",
    "        self.init_weights()\n",
    "        self.tgt_mask = None\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.src_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.tgt_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.replacement_decoder.bias.data.zero_()\n",
    "        self.replacement_decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.insertion_decoder.bias.data.zero_()\n",
    "        self.insertion_decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.command_decoder.bias.data.zero_()\n",
    "        self.command_decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "#         noise_e = 0.05 if self.training else 0.0 # this is code to add noise to the decoding process during training\n",
    "        noise_e = 0.0 if self.training else 0.0\n",
    "        noise_mask = (torch.rand(sz,sz) > noise_e).float()\n",
    "\n",
    "        mask = (torch.triu(torch.ones(sz,sz))).transpose(0, 1)\n",
    "        mask = torch.mul(mask, noise_mask)\n",
    "        v = (torch.sum(mask, dim=-1) == 0).float()\n",
    "\n",
    "        fix_mask = torch.zeros(sz,sz)\n",
    "        fix_mask[:,0] = 1.0\n",
    "        v = v.repeat(sz, 1).transpose(0,1)\n",
    "        fix_mask = torch.mul(fix_mask,v)\n",
    "\n",
    "        mask += fix_mask\n",
    "        \n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        self.tgt_mask = self._generate_square_subsequent_mask(len(tgt)).to(self.device)\n",
    "        \n",
    "\n",
    "        src_emb = self.src_encoder(src) * math.sqrt(self.embedding_size)\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "        \n",
    "        tgt_emb = self.tgt_encoder(tgt) * math.sqrt(self.embedding_size)\n",
    "        tgt_emb = self.pos_encoder(tgt_emb)\n",
    "        \n",
    "        output, atts = self.transformer(src_emb, tgt_emb, tgt_mask=self.tgt_mask)\n",
    "        \n",
    "        \n",
    "        src_scat = src.transpose(0,1)\n",
    "        src_scat = src_scat.unsqueeze(0)\n",
    "        src_scat = torch.repeat_interleave(src_scat, tgt.shape[0], dim=0)\n",
    "#         print(\"src_scat.shqape\", src_scat.shape)\n",
    "        \n",
    "        p_gens = self.p_generator(output).sigmoid()\n",
    "        atts = atts.transpose(0,1)\n",
    "#         print(\"att.shqape\", atts.shape)\n",
    "        atts = atts * (1 - p_gens)\n",
    "                \n",
    "        target_replacements = self.replacement_decoder(output)\n",
    "#         output[:,:,12:] = -np.inf\n",
    "        target_replacements = target_replacements.softmax(-1)\n",
    "        target_replacements = target_replacements * p_gens\n",
    "        \n",
    "        target_replacements = target_replacements.scatter_add_(2,src_scat,atts)\n",
    "        \n",
    "        target_insertions = self.insertion_decoder(output)\n",
    "        \n",
    "        target_commands = self.command_decoder(output)\n",
    "        \n",
    "        return target_commands, target_insertions, target_replacements.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi[\"','\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2, 4]), torch.Size([5, 2, 20]), torch.Size([5, 2, 9378]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos) + max_seq_length\n",
    "\n",
    "model = CopyModel(vocab_size).to(device) \n",
    "src = torch.randint(0, vocab_size, (3,2)).to(device)\n",
    "tgt = torch.randint(0, vocab_size, (5,2)).to(device)\n",
    "\n",
    "target_commands, target_insertions, target_replacements = model(src, tgt)\n",
    "target_commands.shape, target_insertions.shape, target_replacements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_bleu(refrence, prediction):\n",
    "    \"\"\"\n",
    "    Implementation from ReCode\n",
    "    and moses multi belu script sets BLEU to 0.0 if len(toks) < 4\n",
    "    \"\"\"\n",
    "    ngram_weights = [0.25] * min(4, len(refrence))\n",
    "    return sentence_bleu([refrence], prediction, weights=ngram_weights, \n",
    "                          smoothing_function=SmoothingFunction().method3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmpad(arr):\n",
    "    pad_id = stoi[\"<pad>\"]\n",
    "    return [x for x in arr if x != pad_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input      : if escaped is true ,\n",
      "ground_truth_code  : <sos> if escaped :\n",
      "decoder_input      : <sos> if escaped :\n",
      "gt_target_commands : [0, 0, 0, 0]\n",
      "gt_target_insertions: [0, 0, 0, 0]\n",
      "gt_target_replacements: \n",
      "gt_edited_code     : <sos> if escaped :\n",
      "\n",
      "encoder_input      : import module warnings .\n",
      "ground_truth_code  : <sos> import warnings\n",
      "decoder_input      : <sos> import warnings\n",
      "gt_target_commands : [0, 0, 0]\n",
      "gt_target_insertions: [0, 0, 0]\n",
      "gt_target_replacements: \n",
      "gt_edited_code     : <sos> import warnings\n",
      "\n",
      "encoder_input      : try ,\n",
      "ground_truth_code  : <sos> try :\n",
      "decoder_input      : <sos> try :\n",
      "gt_target_commands : [0, 0, 0]\n",
      "gt_target_insertions: [0, 0, 0]\n",
      "gt_target_replacements: \n",
      "gt_edited_code     : <sos> try :\n",
      "\n",
      "encoder_input      : default is a string 'DEFAULT' .\n",
      "ground_truth_code  : <sos> default = 'DEFAULT'\n",
      "decoder_input      : <sos> DEFAULT_CACHE_ALIAS = 'default'\n",
      "gt_target_commands : [0, 2, 0, 2]\n",
      "gt_target_insertions: [0, 0, 0, 0]\n",
      "gt_target_replacements: default 'DEFAULT'\n",
      "gt_edited_code     : <sos> default = 'DEFAULT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def outputs2code(target_commands, target_insertions, target_replacements, decoder_input, OOVss):\n",
    "    batch_size = target_commands.shape[1]\n",
    "    \n",
    "    edited_code_samples = []\n",
    "    for i in range(batch_size):\n",
    "        code_to_edit = rmpad(decoder_input[:,i].tolist())\n",
    "        code_length = len(code_to_edit)\n",
    "        \n",
    "        sample_commands = target_commands[:code_length,i].view(-1).tolist()\n",
    "#         print(sample_commands)\n",
    "        sample_commands = decode_commands(sample_commands)\n",
    "        sample_insertions = target_insertions[:code_length,i].view(-1).tolist()\n",
    "        sample_replacements = target_replacements[:code_length,i].view(-1).tolist()\n",
    "        \n",
    "        \n",
    "        \n",
    "        edits = (sample_commands, sample_insertions, sample_replacements)\n",
    "        \n",
    "        edited_code = perform_edits(code_to_edit, edits, gen_tok_id=stoi[\"<gen>\"])\n",
    "        \n",
    "        edited_code = decode(rmpad(edited_code), OOVss[:,i].tolist())\n",
    "        edited_code_samples.append(edited_code)\n",
    "    return edited_code_samples\n",
    "    \n",
    "        \n",
    "batch = next(iter(train_iterator))\n",
    "decoder_input = batch.decoder_input\n",
    "encoder_input = batch.encoder_input\n",
    "ground_truth_code = batch.ground_truth_code\n",
    "OOVss = batch.OOVs\n",
    "\n",
    "gt_target_commands = batch.target_commands\n",
    "gt_target_insertions = batch.target_insertions\n",
    "gt_target_replacements = batch.target_replacements\n",
    "\n",
    "gt_edited_code = outputs2code(gt_target_commands, gt_target_insertions, gt_target_replacements, decoder_input, OOVss)\n",
    "\n",
    "target_commands, target_insertions, target_replacements = model(encoder_input, decoder_input)\n",
    "\n",
    "_, argmax_target_commands = target_commands.max(2)\n",
    "_, argmax_target_insertions = target_insertions.max(2)\n",
    "_, argmax_target_replacements = target_replacements.max(2)\n",
    "\n",
    "outputs2code(argmax_target_commands, argmax_target_insertions, argmax_target_replacements, decoder_input, OOVss)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print(\"encoder_input      :\", decode(rmpad(encoder_input[:,i].tolist()), []))\n",
    "    print(\"ground_truth_code  :\",decode(rmpad(ground_truth_code[:,i].tolist()), []))\n",
    "    print(\"decoder_input      :\",decode(rmpad(decoder_input[:,i].tolist()), []))\n",
    "    print(\"gt_target_commands :\", rmpad(gt_target_commands[:,i].tolist()))\n",
    "    print(\"gt_target_insertions:\", rmpad(gt_target_insertions[:,i].tolist()))\n",
    "    print(\"gt_target_replacements:\", decode(rmpad(gt_target_replacements[:,i].tolist()), []))\n",
    "    print(\"gt_edited_code     :\",gt_edited_code[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iterator = BucketIterator(val_dataset,\n",
    "    batch_size = 32,\n",
    "    sort_key = lambda x: len(x.src)+len(x.tgt),\n",
    "    device = device)\n",
    "\n",
    "def batch_filter_ids(batch_list):\n",
    "    return [[id for id in l if id not in [1,2,3]] for l in batch_list]\n",
    "\n",
    "def evaluate(beam_size=1, log=False):\n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    with torch.no_grad(), open(\"out.txt\", \"w\") as out_fp:\n",
    "        BLEU_scores = []\n",
    "        for i, batch in enumerate(valid_iterator):\n",
    "            batch_size = batch.src.shape[1]\n",
    "            \n",
    "            encoder_inputs = batch.src\n",
    "            predictions = beam_search.beam_search_decode(model,\n",
    "                              batch_encoder_ids=encoder_inputs,\n",
    "                              SOS_token=stoi[\"<sos>\"],\n",
    "                              EOS_token=stoi[\"<eos>\"],\n",
    "                              PAD_token=stoi[\"<pad>\"],\n",
    "                              beam_size=beam_size,\n",
    "                              max_length=20,\n",
    "                              num_out=1)\n",
    "            \n",
    "            sources = encoder_inputs.transpose(0,1).cpu().tolist()\n",
    "            sources = batch_filter_ids(sources)\n",
    "            \n",
    "            predictions = [t[0].view(-1).cpu().tolist() for t in predictions]\n",
    "            predictions = batch_filter_ids(predictions)\n",
    "            \n",
    "            targets = batch.tgt.transpose(0,1).cpu().tolist()\n",
    "            targets = batch_filter_ids(targets)\n",
    "            \n",
    "#             print(batch.tgt)\n",
    "            \n",
    "            OOVss = [[OOV_itos[OOV] for OOV in batch.OOVs.cpu()[:,idx].tolist() if OOV != 3] for idx in range(batch_size)]\n",
    "            \n",
    "            if i % int(len(valid_iterator)/3) == 0:\n",
    "                print(\"| EVALUATION | {:5d}/{:5d} batches |\".format(i, len(valid_iterator)))\n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                BLEU = nltk_bleu(targets[j], predictions[j])\n",
    "                BLEU_scores.append(BLEU)\n",
    "                \n",
    "                out_fp.write(\"SRC  :\" + decode(sources[j], OOVss[j]) + \"\\n\")\n",
    "                out_fp.write(\"TGT  :\" + decode(targets[j], OOVss[j]) + \"\\n\")\n",
    "                out_fp.write(\"PRED :\" + decode(predictions[j], OOVss[j]) + \"\\n\")\n",
    "                out_fp.write(\"BLEU :\" + str(BLEU) + \"\\n\")\n",
    "                out_fp.write(\"\\n\")\n",
    "                \n",
    "                if log:\n",
    "                    print(\"SRC  :\" + decode(sources[j], OOVss[j]))\n",
    "                    print(\"TGT  :\" + decode(targets[j], OOVss[j]))\n",
    "                    print(\"PRED :\" + decode(predictions[j], OOVss[j]))\n",
    "                    print(\"BLEU :\" + str(BLEU))\n",
    "                    print()\n",
    "        out_fp.write(\"\\n\\n| EVALUATION | BLEU: {:5.2f} |\\n\".format(np.average(BLEU_scores)))\n",
    "        print(\"| EVALUATION | BLEU: {:5.3f} |\".format(np.average(BLEU_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ee948df27117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-289ed9dbdf51>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(beam_size, log)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mBLEU_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'src'"
     ]
    }
   ],
   "source": [
    "evaluate(beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi['<pad>'])\n",
    "lr = 0.005 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    vocab_size = len(itos) + max_seq_length\n",
    "    encoder_input = batch.encoder_input\n",
    "    decoder_input = batch.decoder_input\n",
    "    ground_truth_commands = batch.target_commands\n",
    "    ground_truth_insertions = batch.target_insertions\n",
    "    ground_truth_replacements = batch.target_replacements\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    target_commands, target_insertions, target_replacements = model(encoder_input, decoder_input)\n",
    "\n",
    "    \n",
    "    command_loss = criterion(target_commands.view(-1, len(edit_stoi)), ground_truth_commands.view(-1))\n",
    "    insertion_loss = criterion(target_insertions.view(-1, max_insertions), ground_truth_insertions.view(-1))\n",
    "    replacement_loss = criterion(target_replacements.view(-1, vocab_size), ground_truth_replacements.view(-1))\n",
    "    \n",
    "    loss = command_loss + insertion_loss + replacement_loss\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "    elapsed = time.time() - start_time\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     4/1000000 steps | lr 0.0050 | ms/batch 528.08 | loss 11.92 | ppl 150092.90\n",
      "|     8/1000000 steps | lr 0.0050 | ms/batch 588.28 | loss  9.20 | ppl  9873.35\n",
      "|    12/1000000 steps | lr 0.0050 | ms/batch 574.45 | loss  8.94 | ppl  7595.55\n",
      "|    16/1000000 steps | lr 0.0050 | ms/batch 568.42 | loss  9.91 | ppl 20176.67\n",
      "|    20/1000000 steps | lr 0.0050 | ms/batch 507.27 | loss  7.97 | ppl  2900.74\n",
      "|    24/1000000 steps | lr 0.0050 | ms/batch 524.54 | loss  7.79 | ppl  2427.73\n",
      "|    28/1000000 steps | lr 0.0050 | ms/batch 582.48 | loss  8.09 | ppl  3250.94\n",
      "|    32/1000000 steps | lr 0.0050 | ms/batch 561.84 | loss  8.66 | ppl  5759.95\n",
      "|    36/1000000 steps | lr 0.0050 | ms/batch 599.12 | loss  9.50 | ppl 13351.32\n",
      "|    40/1000000 steps | lr 0.0050 | ms/batch 631.95 | loss  8.60 | ppl  5448.22\n",
      "|    44/1000000 steps | lr 0.0050 | ms/batch 575.42 | loss  7.03 | ppl  1131.00\n",
      "|    48/1000000 steps | lr 0.0050 | ms/batch 498.92 | loss  7.27 | ppl  1434.77\n",
      "|    52/1000000 steps | lr 0.0050 | ms/batch 514.23 | loss  5.97 | ppl   391.14\n",
      "|    56/1000000 steps | lr 0.0050 | ms/batch 519.04 | loss  7.10 | ppl  1212.33\n",
      "|    60/1000000 steps | lr 0.0050 | ms/batch 470.65 | loss  5.00 | ppl   147.85\n",
      "|    64/1000000 steps | lr 0.0050 | ms/batch 538.28 | loss  7.59 | ppl  1978.54\n",
      "|    68/1000000 steps | lr 0.0050 | ms/batch 536.02 | loss  5.34 | ppl   207.67\n",
      "|    72/1000000 steps | lr 0.0050 | ms/batch 536.42 | loss  8.88 | ppl  7178.84\n",
      "|    76/1000000 steps | lr 0.0050 | ms/batch 499.84 | loss  7.25 | ppl  1410.65\n",
      "|    80/1000000 steps | lr 0.0050 | ms/batch 533.22 | loss  8.14 | ppl  3446.06\n",
      "|    84/1000000 steps | lr 0.0050 | ms/batch 509.92 | loss  6.99 | ppl  1086.07\n",
      "|    88/1000000 steps | lr 0.0050 | ms/batch 557.66 | loss  6.06 | ppl   426.86\n",
      "|    92/1000000 steps | lr 0.0050 | ms/batch 596.74 | loss  7.57 | ppl  1931.23\n",
      "|    96/1000000 steps | lr 0.0050 | ms/batch 550.33 | loss  5.93 | ppl   376.57\n",
      "|   100/1000000 steps | lr 0.0050 | ms/batch 514.23 | loss  6.17 | ppl   480.28\n",
      "|   104/1000000 steps | lr 0.0050 | ms/batch 636.70 | loss  7.50 | ppl  1808.49\n",
      "|   108/1000000 steps | lr 0.0050 | ms/batch 551.60 | loss  7.37 | ppl  1594.97\n",
      "|   112/1000000 steps | lr 0.0050 | ms/batch 599.58 | loss  6.19 | ppl   488.91\n",
      "|   116/1000000 steps | lr 0.0050 | ms/batch 612.94 | loss  8.00 | ppl  2978.75\n",
      "|   120/1000000 steps | lr 0.0050 | ms/batch 575.14 | loss  9.15 | ppl  9421.00\n",
      "|   124/1000000 steps | lr 0.0050 | ms/batch 549.78 | loss  6.26 | ppl   523.53\n",
      "|   128/1000000 steps | lr 0.0050 | ms/batch 586.15 | loss  6.68 | ppl   796.92\n",
      "|   132/1000000 steps | lr 0.0050 | ms/batch 591.16 | loss  7.80 | ppl  2436.58\n",
      "|   136/1000000 steps | lr 0.0050 | ms/batch 565.25 | loss  6.27 | ppl   525.87\n",
      "|   140/1000000 steps | lr 0.0050 | ms/batch 561.32 | loss  5.13 | ppl   169.49\n",
      "|   144/1000000 steps | lr 0.0050 | ms/batch 552.47 | loss  7.78 | ppl  2395.24\n",
      "|   148/1000000 steps | lr 0.0050 | ms/batch 568.27 | loss  6.52 | ppl   677.68\n",
      "|   152/1000000 steps | lr 0.0050 | ms/batch 499.84 | loss  5.05 | ppl   155.93\n",
      "|   156/1000000 steps | lr 0.0050 | ms/batch 522.05 | loss  6.26 | ppl   523.62\n",
      "|   160/1000000 steps | lr 0.0050 | ms/batch 536.53 | loss  3.92 | ppl    50.62\n",
      "|   164/1000000 steps | lr 0.0050 | ms/batch 540.55 | loss  6.78 | ppl   881.46\n",
      "|   168/1000000 steps | lr 0.0050 | ms/batch 561.97 | loss  7.87 | ppl  2605.47\n",
      "|   172/1000000 steps | lr 0.0050 | ms/batch 573.70 | loss  7.60 | ppl  1995.76\n",
      "|   176/1000000 steps | lr 0.0050 | ms/batch 530.68 | loss  7.65 | ppl  2095.76\n",
      "|   180/1000000 steps | lr 0.0050 | ms/batch 535.13 | loss  7.67 | ppl  2153.26\n",
      "|   184/1000000 steps | lr 0.0050 | ms/batch 546.80 | loss  5.58 | ppl   265.21\n",
      "|   188/1000000 steps | lr 0.0050 | ms/batch 578.68 | loss  8.40 | ppl  4462.28\n",
      "|   192/1000000 steps | lr 0.0050 | ms/batch 583.51 | loss  5.19 | ppl   178.76\n",
      "|   196/1000000 steps | lr 0.0050 | ms/batch 530.88 | loss  5.78 | ppl   323.99\n",
      "|   200/1000000 steps | lr 0.0050 | ms/batch 511.54 | loss  7.65 | ppl  2109.88\n",
      "|   204/1000000 steps | lr 0.0050 | ms/batch 561.05 | loss  7.52 | ppl  1838.54\n",
      "|   208/1000000 steps | lr 0.0050 | ms/batch 556.65 | loss  6.92 | ppl  1015.19\n",
      "|   212/1000000 steps | lr 0.0050 | ms/batch 579.15 | loss  6.29 | ppl   539.22\n",
      "|   216/1000000 steps | lr 0.0050 | ms/batch 586.35 | loss  6.60 | ppl   732.00\n",
      "|   220/1000000 steps | lr 0.0050 | ms/batch 582.23 | loss  6.88 | ppl   975.33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-ec4725d202fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-ec4725d202fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(steps, log_interval, learning_interval, eval_interval)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-219dd4a1cc54>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minsertion_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreplacement_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(steps=10000, log_interval=200, learning_interval=4000, eval_interval=1000):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    step = 1\n",
    "    for batch in train_iterator:\n",
    "        loss = train_step(batch)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if step % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| {:5d}/{:5d} steps | '\n",
    "                  'lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    step, steps, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "        if step % eval_interval == 0:\n",
    "            print(\"Evaluating model\")\n",
    "            evaluate()\n",
    "            model.train()\n",
    "        \n",
    "        if step % learning_interval == 0:\n",
    "            scheduler.step()\n",
    "        \n",
    "        step += 1\n",
    "        if step >= steps:\n",
    "            print(\"Finished training\")\n",
    "\n",
    "\n",
    "\n",
    "            return\n",
    "\n",
    "train(steps=1000000,eval_interval=10000,log_interval=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
