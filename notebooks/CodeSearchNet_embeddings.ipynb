{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from src.Self_attention_sequence_encoder import SelfAttentionEmbedder\n",
    "from src.vocab_classes import BPE_Code_vocab\n",
    "from src.trainers import Model_Trainer \n",
    "from src.useful_utils import load_CSN_data\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import tqdm.notebook as tqdm \n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61019d4411ad450c8488a51a4d1a6b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71160fbbe504eef8ae5b34d71035c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da58a97390d42fea20495e9f186cf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CodeSearchNet_data_path = \"/nfs/code_search_net_archive/python/final/jsonl/\"\n",
    "train_data, valid_data, test_data = load_CSN_data(CodeSearchNet_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = []\n",
    "for sample in train_data:\n",
    "    query = \" \".join(sample[\"docstring_tokens\"])\n",
    "    doc = sample[\"code\"].replace(sample[\"docstring\"], \"\")\n",
    "    train_pairs.append((query, doc))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(\"datasets/code_search_net/code_bpe_hugging_32k-vocab.json\",\n",
    "                                  \"datasets/code_search_net/code_bpe_hugging_32k-merges.txt\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5b1b1d152940009c2126c407ab9775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cutoff = 500\n",
    "trunk_train_pairs = [(q,d) for q,d in tqdm.tqdm(train_pairs) if len(tokenizer.encode(d).ids)<cutoff and len(tokenizer.encode(q).ids)<cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = BPE_Code_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelfAttentionEmbedder(vocab_size=vocab.vocab_size, embed_dim=128, att_heads=8, layers=3, dim_feedforward=512, loss_type=\"softmax\")\n",
    "model.init_train_params(lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26710b8a3a9742c889bcd7f33910eeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=91196.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = model.data2dataset(trunk_train_pairs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = BucketIterator(\n",
    "    dataset,\n",
    "    batch_size = 32,\n",
    "    repeat=True,\n",
    "    shuffle=True,\n",
    "    device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[92.5424, 92.3537, 92.9671,  ..., 92.2242, 92.4776, 92.6549],\n",
       "        [91.4828, 92.3798, 91.9793,  ..., 92.0625, 90.8034, 91.3626],\n",
       "        [92.5334, 91.9231, 92.3086,  ..., 92.0379, 92.8420, 92.8789],\n",
       "        ...,\n",
       "        [92.7986, 92.9297, 93.1334,  ..., 92.7572, 92.6939, 92.6148],\n",
       "        [91.7903, 91.4939, 91.4189,  ..., 91.4688, 92.0508, 92.0379],\n",
       "        [92.7520, 92.2777, 92.7913,  ..., 92.2941, 93.0204, 92.9002]],\n",
       "       device='cuda:0', grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(it)\n",
    "q_vec, d_vec = model(batch.query, batch.doc)\n",
    "matrix = model.softmax_matrix(q_vec, d_vec)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 29, 25,  4,  4,  4,  4,  4, 29, 25, 29,  4,  4,  5, 29,  4, 25, 25,\n",
       "        25,  4, 25,  4, 29,  4,  4,  4,  4, 25,  4, 25,  4,  4],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(matrix, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0025, 0.3133])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_input = torch.tensor([[-1.,5],\n",
    "                          [1,0]])\n",
    "tmp_labels = torch.tensor([1,0])\n",
    "model.cross_entropy(tmp_input, tmp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'output_dir' not defined, training and model outputs won't be saved.\n"
     ]
    }
   ],
   "source": [
    "trainer = Model_Trainer(model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed95fef5742d44f991f07eb41f40952e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "train_logs = trainer.train(model, train_iterator, 100000, save_interval=10000000, log_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the same loss function as CodeSearchNet in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_query_representations = tf.constant([[-1,3.],[3,4],[5,6]])\n",
    "tf_code_representations = tf.constant([[1,2.],[3,4],[5,6]])\n",
    "margin = 1.\n",
    "\n",
    "tf_query_norms = tf.norm(tf_query_representations, axis=-1, keepdims=True) + 1e-10\n",
    "tf_code_norms = tf.norm(tf_code_representations, axis=-1, keepdims=True) + 1e-10\n",
    "\n",
    "tf_cosine_similarities = tf.matmul(tf_query_representations / tf_query_norms,\n",
    "                                tf_code_representations / tf_code_norms,\n",
    "                                transpose_a=False,\n",
    "                                transpose_b=True,\n",
    "                                name='code_query_cooccurrence_logits',\n",
    "                                )  # B x B\n",
    "tf_similarity_scores = tf_cosine_similarities\n",
    "\n",
    "# A max-margin-like loss, but do not penalize negative cosine similarities.\n",
    "tf_neg_matrix = tf.linalg.diag(tf.fill(dims=[tf.shape(tf_cosine_similarities)[0]], value=float('-inf')))\n",
    "tf_per_sample_loss = tf.maximum(0., margin\n",
    "                                 - tf.linalg.diag_part(tf_cosine_similarities)\n",
    "                                 + tf.reduce_max(tf.nn.relu(tf_cosine_similarities + tf_neg_matrix),\n",
    "                                                 axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_representations = torch.tensor([[-1,3.],[3,4],[5,6]])\n",
    "code_representations = torch.tensor([[1,2.],[3,4],[5,6]])\n",
    "margin = 1.\n",
    "\n",
    "query_norm = torch.norm(query_representations, dim=-1, keepdim=True) + 1e-10\n",
    "code_norm = torch.norm(code_representations, dim=-1, keepdim=True) + 1e-10\n",
    "\n",
    "# query_vector = query_vector/query_norm\n",
    "# doc_vector = doc_vector/doc_norm\n",
    "# batch_size = query_vector.shape[0]\n",
    "\n",
    "cosine_similarities = torch.mm(torch.div(query_representations,query_norm),\n",
    "                                torch.div(code_representations,code_norm).T\n",
    "                                )\n",
    "\n",
    "neg_matrix = torch.diag(torch.full((cosine_similarities.shape[0],), float('-inf')))\n",
    "\n",
    "good_sample_loss = torch.diagonal(cosine_similarities)\n",
    "bad_sample_loss = torch.max(cosine_similarities + neg_matrix, dim=-1)[0]\n",
    "\n",
    "\n",
    "per_sample_loss = torch.clamp(margin - good_sample_loss + bad_sample_loss, min=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF CodeSearchNet softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_logits = tf.matmul(tf_query_representations,\n",
    "                   tf_code_representations,\n",
    "                   transpose_a=False,\n",
    "                   transpose_b=True,\n",
    "                   name='code_query_cooccurrence_logits',\n",
    "                   )  # B x B\n",
    "\n",
    "similarity_scores = tf_logits\n",
    "\n",
    "tf_per_sample_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=tf.range(tf.shape(tf_code_representations)[0]),  # [0, 1, 2, 3, ..., n]\n",
    "    logits=tf_logits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=575, shape=(3,), dtype=int32, numpy=array([0, 1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(tf.shape(tf_code_representations)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=566, shape=(3,), dtype=float32, numpy=array([ 8.018479, 14.000001,  0.      ], dtype=float32)>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_per_sample_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.mm(query_representations, code_representations.T)\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "labels = torch.arange(0,code_representations.shape[0])\n",
    "per_sample_loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.0185, 14.0000, -0.0000])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_sample_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  9., 13.],\n",
       "        [11., 25., 39.],\n",
       "        [17., 39., 61.]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
