{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.RawDataLoaders import MS_Marco_RawDataLoader, CAsT_RawDataLoader\n",
    "from src.pipe_datasets import Manual_Query_BM25_Reranking_Dataset, Reranking_Validation_Dataset, Manual_Query_RUN_File_Reranking_Dataset\n",
    "from src.models_and_transforms.run_file_models import Run_File_Searcher\n",
    "from src.models_and_transforms.BERT_models import BERT_Reranker\n",
    "from src.models_and_transforms.Longformer_models import Longformer_Reranker\n",
    "from src.models_and_transforms.BM25_models import BM25_Ranker\n",
    "from src.Experiments import CAsT_experiment, Ranking_Experiment, RUN_File_Transform_Exporter\n",
    "from src.trainers import Model_Trainer\n",
    "from src.models_and_transforms.complex_transforms import BERT_Score_Transform, BERT_ReRanker_Transform, BM25_Search_Transform, \\\n",
    "                                                         Oracle_ReRanker_Transform, RUN_File_Search_Transform, monoBERT_Scorer_Transform, \\\n",
    "                                                         MonoBERT_ReRanker_Transform, DuoBERT_Scorer_Transform, DuoBERT_ReRanker_Transform\n",
    "from src.models_and_transforms.text_transforms import Query_Resolver_Transform, Document_Resolver_Transform, Reranking_Flattener_Transform, \\\n",
    "                                                      MonoBERT_Numericalise_Transform, BERT_Denumericalise_Transform,  \\\n",
    "                                                      DuoBERT_Numericalise_Transform\n",
    "\n",
    "from transformers import LongformerConfig, LongformerModel, LongformerTokenizer, BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from pytorch_lightning import Trainer, Callback, seed_everything\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "seed_everything(42)\n",
    "\n",
    "from tqdm.auto import tqdm \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='loading train queries', max=1.0, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='loading dev queries', max=1.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='loading eval queries', max=1.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data_loader = MS_Marco_RawDataLoader(from_pickle=True)\n",
    "get_query_fn = raw_data_loader.get_query\n",
    "get_doc_fn = raw_data_loader.get_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='loading train queries', max=1.0, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='loading q_rels', max=1.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw_samples = raw_data_loader.get_topics(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8c3cacb0b2e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRun_File_Searcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_models/MARCO_train_BM25_full.run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nfs/phd_by_carlos/notebooks/src/models_and_transforms/run_file_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, run_file, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrun_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mq_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "searcher = Run_File_Searcher(\"saved_models/MARCO_train_BM25_full.run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing probllematic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_samples = [sample for sample in train_raw_samples if sample['q_id'] not in searcher.query_doc_mapping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q_id': '140329', 'q_rel': ['MARCO_6542451']}\n",
      "{'q_id': '1078982', 'q_rel': ['MARCO_4115897']}\n",
      "{'q_id': '502557', 'q_rel': ['MARCO_1271975']}\n",
      "{'q_id': '48509', 'q_rel': ['MARCO_2063851']}\n",
      "{'q_id': '56573', 'q_rel': ['MARCO_3198289']}\n",
      "{'q_id': '129844', 'q_rel': ['MARCO_7817031']}\n",
      "{'q_id': '197820', 'q_rel': ['MARCO_5510763']}\n",
      "{'q_id': '522517', 'q_rel': ['MARCO_3075528']}\n",
      "{'q_id': '205266', 'q_rel': ['MARCO_5143713']}\n"
     ]
    }
   ],
   "source": [
    "for sample in bad_samples:\n",
    "    print(sample)\n",
    "    train_raw_samples.remove(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582914c09fed4f90ad6a25208740c0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab31037e9594b4da89dd60eccd0336e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Searching queries', max=502930.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c267b869d67d436dbeee06ab740cad38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sampling ± query-doc pairs', max=502930.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Manual_Query_RUN_File_Reranking_Dataset(train_raw_samples, get_query_fn, get_doc_fn, \"saved_models/MARCO_train_BM25_full.run\", hits=100, num_neg_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '502744',\n",
       " 'q_rel': ['MARCO_5338628'],\n",
       " 'query': 'starter remove on a polaris 400 sportsman',\n",
       " 'd_id': 'MARCO_5338630',\n",
       " 'label': 0,\n",
       " 'doc': \"polaris 400 starter. Follow polaris 400 starter to get e-mail alerts and updates on your eBay Feed. Unfollow polaris 400 starter to stop getting updates on your eBay Feed.Yay! You're now following polaris 400 starter in your eBay Feed.ollow polaris 400 starter to get e-mail alerts and updates on your eBay Feed. Unfollow polaris 400 starter to stop getting updates on your eBay Feed. Yay! You're now following polaris 400 starter in your eBay Feed.\",\n",
       " 'input_text': \"starter remove on a polaris 400 sportsman [SEP] polaris 400 starter. Follow polaris 400 starter to get e-mail alerts and updates on your eBay Feed. Unfollow polaris 400 starter to stop getting updates on your eBay Feed.Yay! You're now following polaris 400 starter in your eBay Feed.ollow polaris 400 starter to get e-mail alerts and updates on your eBay Feed. Unfollow polaris 400 starter to stop getting updates on your eBay Feed. Yay! You're now following polaris 400 starter in your eBay Feed.\",\n",
       " 'input_ids': [101,\n",
       "  11753,\n",
       "  6366,\n",
       "  2006,\n",
       "  1037,\n",
       "  11508,\n",
       "  2483,\n",
       "  4278,\n",
       "  27168,\n",
       "  102,\n",
       "  11508,\n",
       "  2483,\n",
       "  4278,\n",
       "  11753,\n",
       "  1012,\n",
       "  3582,\n",
       "  11508,\n",
       "  2483,\n",
       "  4278,\n",
       "  11753,\n",
       "  2000,\n",
       "  2131,\n",
       "  1041,\n",
       "  1011,\n",
       "  5653,\n",
       "  9499,\n",
       "  2015,\n",
       "  1998,\n",
       "  14409,\n",
       "  2006,\n",
       "  2115,\n",
       "  1041,\n",
       "  15907,\n",
       "  5438,\n",
       "  1012,\n",
       "  4895,\n",
       "  14876,\n",
       "  7174,\n",
       "  2860,\n",
       "  11508,\n",
       "  2483,\n",
       "  4278,\n",
       "  11753,\n",
       "  2000,\n",
       "  2644,\n",
       "  2893,\n",
       "  14409,\n",
       "  2006,\n",
       "  2115,\n",
       "  1041,\n",
       "  15907,\n",
       "  5438,\n",
       "  1012,\n",
       "  8038,\n",
       "  2100,\n",
       "  999,\n",
       "  2017,\n",
       "  1005,\n",
       "  2128,\n",
       "  2085,\n",
       "  2206,\n",
       "  11508,\n",
       "  2483,\n",
       "  4278,\n",
       "  11753,\n",
       "  1999,\n",
       "  2115,\n",
       "  1041,\n",
       "  15907,\n",
       "  5438,\n",
       "  1012,\n",
       "  19330,\n",
       "  8261,\n",
       "  11508,\n",
       "  2483,\n",
       "  4278,\n",
       "  11753,\n",
       "  2000,\n",
       "  2131,\n",
       "  1041,\n",
       "  1011,\n",
       "  5653,\n",
       "  9499,\n",
       "  2015,\n",
       "  1998,\n",
       "  14409,\n",
       "  2006,\n",
       "  2115,\n",
       "  1041,\n",
       "  15907,\n",
       "  5438,\n",
       "  1012,\n",
       "  4895,\n",
       "  14876,\n",
       "  7174,\n",
       "  2860,\n",
       "  11508,\n",
       "  2483,\n",
       "  4278,\n",
       "  11753,\n",
       "  2000,\n",
       "  2644,\n",
       "  2893,\n",
       "  14409,\n",
       "  2006,\n",
       "  2115,\n",
       "  1041,\n",
       "  15907,\n",
       "  5438,\n",
       "  1012,\n",
       "  8038,\n",
       "  2100,\n",
       "  999,\n",
       "  2017,\n",
       "  1005,\n",
       "  2128,\n",
       "  2085,\n",
       "  2206,\n",
       "  11508,\n",
       "  2483,\n",
       "  4278,\n",
       "  11753,\n",
       "  1999,\n",
       "  2115,\n",
       "  1041,\n",
       "  15907,\n",
       "  5438,\n",
       "  1012,\n",
       "  102],\n",
       " 'q_id_ascii': [53,\n",
       "  48,\n",
       "  50,\n",
       "  55,\n",
       "  52,\n",
       "  52,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1],\n",
       " 'd_id_ascii': [77,\n",
       "  65,\n",
       "  82,\n",
       "  67,\n",
       "  79,\n",
       "  95,\n",
       "  53,\n",
       "  51,\n",
       "  51,\n",
       "  56,\n",
       "  54,\n",
       "  51,\n",
       "  48,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9386d3fcc8453b813e4ecbf8841928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874403bb538b45809e4ca8827a6a915b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Searching queries', max=20000.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bfc2f110af4ea293b6824359139e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sampling ± query-doc pairs', max=20000.0, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Manual_Query_BM25_Reranking_Dataset(train_raw_samples[:20000], get_query_fn, get_doc_fn, hits=150, num_neg_samples=100, index_dir=\"datasets/MS_MARCO/MARCO_anserini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = train_dataset.to_dataloader(8, num_workers=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Longformer_Reranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"saved_models/Longformer/Longformer_ReRanker_MARCO.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"saved_models/Longformer/Longformer_ReRanker_MARCO.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "BERT ReRanker initialised on cuda. Batch size 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'input_ids': [55, 66, 33], 'score': 0.044405270367860794},\n",
       " {'input_ids': [45, 76, 33], 'score': 0.044405270367860794}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = [{\"input_ids\":[55,66,33]},{\"input_ids\":[45,76,33]}]\n",
    "score_transform = BERT_Score_Transform(\"saved_models/BERT_ReRanker_MARCO.ckpt\")\n",
    "score_transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "BERT ReRanker initialised on cuda. Batch size 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aef655b04824edcb52c528b5889c4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Reranking queries', max=1.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'q_id': '121352',\n",
       "  'query': 'define extreme',\n",
       "  'search_results': [('MARCO_6237152', 0.6), ('MARCO_2912794', 0.6)],\n",
       "  'reranked_results': [('MARCO_2912794', 0.992748498916626),\n",
       "   ('MARCO_6237152', -0.01869625225663185)]}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = [{'q_id':\"121352\",\"query\":\"define extreme\", 'search_results':[('MARCO_6237152', 0.6), ('MARCO_2912794', 0.6)]}]\n",
    "rerank_transform = BERT_ReRanker_Transform(\"saved_models/Longformer/Longformer_ReRanker_MARCO.ckpt\", get_doc_fn)\n",
    "rerank_transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='loading q_rels', max=1.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='loading dev queries', max=1.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='loading q_rels', max=1.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcb5b01708443c7893cfc2b0693c750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Searching queries', max=400.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65d3d2733164679889654dc09f882ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1791eaa99e3149a583ee2d53eaad23a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Flattening search results', max=400.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_q_rels = raw_data_loader.q_rels(\"dev\")\n",
    "valid_raw_samples = raw_data_loader.get_topics(\"dev\")[:400]\n",
    "valid_samples = Query_Resolver_Transform(get_query_fn)(valid_raw_samples)\n",
    "valid_BM25_results = RUN_File_Search_Transform('saved_models/MARCO_dev_BM25.run', hits=100)(valid_raw_samples)\n",
    "val_dataset = Reranking_Validation_Dataset(valid_BM25_results, get_query_fn, get_doc_fn)\n",
    "val_dataloader = val_dataset.to_dataloader(128, num_workers=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 results\n",
      "{'map': 0.18098515570583398, 'recip_rank': 0.18098515570583398, 'ndcg': 0.27305565934364895, 'set_recall': 0.645}\n",
      "ORACLE results\n",
      "{'map': 0.645, 'recip_rank': 0.645, 'ndcg': 0.645, 'set_recall': 0.645}\n",
      "BERT+BM25 results\n",
      "cpu\n",
      "<All keys matched successfully>\n",
      "BERT ReRanker initialised on cuda:2. Batch size 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237d83b55cb84ac0aabd4a07cd431d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Reranking queries', max=400.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'map': 0.3138712999797035, 'recip_rank': 0.3138712999797035, 'ndcg': 0.38551378521302254, 'set_recall': 0.645}\n"
     ]
    }
   ],
   "source": [
    "# experiment\n",
    "expr = Ranking_Experiment(valid_q_rels)\n",
    "print(\"BM25 results\")\n",
    "print(expr(valid_BM25_results))\n",
    "\n",
    "print(\"ORACLE results\")\n",
    "valid_oracle_rerank_results = Oracle_ReRanker_Transform(valid_q_rels)(valid_BM25_results)\n",
    "for sample in valid_oracle_rerank_results:\n",
    "    sample[\"search_results\"] = sample[\"reranked_results\"]\n",
    "print(expr(valid_oracle_rerank_results))\n",
    "\n",
    "print(\"BERT+BM25 results\")\n",
    "valid_BERT_rerank_results = BERT_ReRanker_Transform(\"saved_models/BERT_reranker_q100k_h100_checkpoints/BERT_ReRanker_MARCO_from_valid_0.38551378521302254.ckpt\", get_doc_fn, device=\"cuda:2\", batch_size=256)(valid_BM25_results)\n",
    "for sample in valid_BERT_rerank_results:\n",
    "    sample[\"search_results\"] = sample[\"reranked_results\"]\n",
    "print(expr(valid_BERT_rerank_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to resolve all measures.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e4723f569656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRanking_Experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_q_rels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_BERT_rerank_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/phd_by_carlos/notebooks/src/Experiments.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, q_rels, save_dir, save_name)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mq_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq_rels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mpytrec_q_rels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0md_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md_ids\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytrec_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRelevanceEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytrec_q_rels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'map'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndcg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set_recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recip_rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'map@5'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdict_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to resolve all measures."
     ]
    }
   ],
   "source": [
    "expr = Ranking_Experiment(valid_q_rels)\n",
    "print(expr(valid_BERT_rerank_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 8 GPUS available, using [0].\n",
      "Main device is: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718bb72ed0bb4e81897358dddb651f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12417.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keyboard Interrupt!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [tensor(0.7658, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5080, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3244, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3060, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2623, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5412, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4063, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4163, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5151, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3588, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4145, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3521, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2835, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3656, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5360, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2494, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4271, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4802, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3109, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2279, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3391, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1601, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3683, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3277, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5099, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2978, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3543, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1950, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3583, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3799, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4830, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4738, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1928, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3293, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3836, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2438, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4738, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3896, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3432, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3711, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3397, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2808, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.5506, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2479, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3068, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2484, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3382, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2625, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2396, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3105, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3180, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3752, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4213, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.6027, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3905, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4183, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3678, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3097, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3932, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1772, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2136, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2638, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3671, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1999, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4269, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3285, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2336, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4135, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2706, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4337, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4084, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4217, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3005, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3748, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1969, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1951, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3550, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2108, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3006, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3861, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3684, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1606, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3839, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2355, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4261, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2911, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3309, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4149, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2853, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3215, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3885, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4405, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2206, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3192, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2625, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2099, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2676, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3018, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3630, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2186, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4459, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2196, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3754, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3112, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2775, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4219, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3242, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3344, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3524, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2933, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3107, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3483, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1969, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2551, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2591, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3121, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3809, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3569, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1917, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2572, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2487, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2477, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2399, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3560, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2019, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2635, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2318, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2856, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1371, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3036, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3278, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3458, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2402, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1621, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2304, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2975, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2967, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2360, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1747, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4213, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2490, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3707, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2917, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3143, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2834, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3015, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2074, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3201, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2528, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2398, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2085, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2477, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3101, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2464, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3237, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3700, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2300, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3307, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3241, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2660, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2074, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2789, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2245, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2423, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1819, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2291, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3347, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2903, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3216, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2212, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1940, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2545, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1857, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2261, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2389, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2307, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1908, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2320, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2609, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1990, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2497, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2277, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2110, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2598, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2699, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1746, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3150, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3433, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3400, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2153, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3354, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2770, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3343, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3049, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1849, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2907, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2776, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2843, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2661, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2137, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2825, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2899, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2132, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2307, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2622, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1932, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2090, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2497, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3014, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2447, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2782, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2562, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2142, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2617, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2043, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2425, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2287, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2669, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2275, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2598, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2844, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1747, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1906, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2025, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3412, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2961, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1897, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3337, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1770, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2511, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2750, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2164, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1743, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2569, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2790, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2076, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2581, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1903, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3397, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2338, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2793, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3206, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2503, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2480, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2675, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1852, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2331, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2439, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2920, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2414, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2458, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2248, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2586, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2069, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1754, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2344, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2659, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3284, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2553, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2406, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2286, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1939, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2973, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2192, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2255, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2538, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2935, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2211, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2206, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2333, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2870, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2896, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2491, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1542, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2278, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1857, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1498, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2334, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2265, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3198, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2450, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2879, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2509, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3891, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2817, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2401, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2292, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2825, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2476, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2683, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2577, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1895, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1941, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2838, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2144, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2201, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2784, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2114, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2500, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2621, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2225, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2186, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1762, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2379, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2237, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2354, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3270, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2581, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2846, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1493, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2548, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2512, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2283, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2746, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2629, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1782, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2386, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2875, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3035, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2125, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2544, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1850, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2626, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2300, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2118, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2264, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2653, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1940, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1648, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2454, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2592, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1829, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2228, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2614, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2919, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3308, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2507, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2473, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2566, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2494, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2781, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2090, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2207, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1794, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1637, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1325, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2313, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2862, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2870, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3158, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1858, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1797, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2089, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2773, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2787, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1963, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2959, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3475, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2024, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2013, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3267, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2581, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1666, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2154, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2673, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2438, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2153, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3099, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2096, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2581, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2051, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1945, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2573, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3036, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2316, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1863, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1812, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1815, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2375, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2573, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2741, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1824, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2013, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2100, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2200, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2103, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2340, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1888, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2248, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1979, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3150, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1951, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2137, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2077, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2120, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2192, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2425, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2868, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3029, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1715, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2623, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4150, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2366, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1891, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1570, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2283, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1581, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1955, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1690, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2573, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2031, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2536, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2044, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2406, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2360, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2329, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3333, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2062, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2419, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1925, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1949, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1600, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2018, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1598, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1576, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2159, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1622, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1813, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2292, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2226, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2131, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1653, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2418, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1559, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1803, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2618, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2214, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2138, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1486, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3314, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3128, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1814, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3398, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2256, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4012, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2748, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2758, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1697, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1423, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2344, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2485, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1530, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2448, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1414, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2418, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1877, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2190, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2287, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2034, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1103, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2315, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2655, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2384, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1806, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1624, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2284, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1947, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1981, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1671, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2860, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2227, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2546, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3444, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.4282, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2004, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1874, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1980, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1597, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2001, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1612, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2065, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2793, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2926, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2410, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1280, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3155, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2244, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2077, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2030, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2345, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1575, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2309, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1830, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2773, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2009, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2826, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1889, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1396, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2534, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2472, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2864, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1986, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1481, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2503, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2517, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2282, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1806, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2665, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2512, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1454, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1928, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2392, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1927, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2546, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1546, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1431, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2810, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1912, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2048, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1131, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1820, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2444, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1793, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1668, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2212, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2227, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2432, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2008, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1764, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1414, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1560, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3118, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2889, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2448, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2010, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1754, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1614, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2128, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2478, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2024, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1394, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1589, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2270, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2248, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2004, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1892, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2550, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2634, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2206, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2406, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1588, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2641, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2343, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1508, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1728, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1498, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1074, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1517, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1554, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2396, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2837, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2300, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2217, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1567, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2412, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1248, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1755, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1686, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1883, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1697, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2252, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2457, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3261, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1744, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1429, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1598, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2063, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2147, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1747, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0867, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1289, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1643, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2280, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3127, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1395, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2476, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2128, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2056, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1792, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0973, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1380, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1545, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2006, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.3204, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1917, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1949, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2533, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2187, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1390, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1949, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1243, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2064, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1631, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2171, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1852, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2846, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2171, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1266, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1930, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1825, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1659, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1670, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2150, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2462, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2746, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1760, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2166, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1274, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1153, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1287, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1722, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1740, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2293, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1647, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2133, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2985, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2028, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2231, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2857, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1202, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1007, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2014, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2571, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1912, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1728, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2154, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2307, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2508, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2367, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2340, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2123, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1502, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1650, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1944, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1852, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1477, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2458, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2403, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2041, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2371, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1758, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0827, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1778, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1670, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2674, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2079, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2165, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1691, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1875, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2280, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2153, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2155, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1881, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1046, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1593, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1893, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1819, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1931, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1806, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1756, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1495, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1478, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1786, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2117, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1262, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1247, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2327, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1102, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1888, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2004, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1897, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1501, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2864, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1410, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2003, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2666, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0892, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1308, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1943, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2485, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1032, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1587, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1673, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1544, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2007, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2384, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1031, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1451, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1608, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1609, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1042, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1265, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1925, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2533, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1705, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2449, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1465, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1652, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1423, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1052, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2522, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1490, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2594, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2296, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1775, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1883, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1391, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2166, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1204, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2544, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1899, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1797, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1884, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1327, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1705, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1238, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1584, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1836, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1601, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1832, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1800, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1179, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1759, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0951, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1720, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1885, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1596, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1611, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1887, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1555, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1718, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1287, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2236, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2151, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2496, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1043, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1743, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1334, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1266, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1500, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2238, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1053, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2121, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1253, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1563, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1658, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1860, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1504, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1845, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1578, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2179, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1702, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0956, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2115, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1313, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1462, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1486, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1132, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1450, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1665, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0923, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1935, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2582, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1382, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0890, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1670, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1897, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2361, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1105, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2266, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1994, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1014, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1899, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1880, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1841, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1060, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0921, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2314, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1056, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1051, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2427, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1313, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1178, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1972, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1784, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1697, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1493, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1316, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1566, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1636, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1509, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1688, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1520, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1879, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2601, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1103, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2081, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2322, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1381, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1868, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0940, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1018, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1785, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1802, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1194, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2090, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1555, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1179, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1788, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1698, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2459, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1234, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1144, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1675, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1466, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2284, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1887, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1263, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1795, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2108, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1975, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1606, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1640, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1357, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1183, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0951, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1280, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1672, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1204, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1477, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1052, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1396, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1006, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1354, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2148, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0921, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0858, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1448, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1332, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1291, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1643, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1130, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1605, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1142, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2161, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1812, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1766, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1273, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0702, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1740, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1457, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1479, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1430, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2035, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1547, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1672, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1736, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1009, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1890, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1647, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1589, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1892, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0913, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1696, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2543, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1078, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1015, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1501, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0973, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1304, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0732, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1191, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1391, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1191, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1093, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1551, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2127, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1298, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0952, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0645, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1775, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0852, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1297, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1044, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1329, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1321, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1904, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1702, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0966, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1963, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1110, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1303, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1472, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1844, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1630, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0890, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2596, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2078, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2237, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2308, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1782, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1355, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1361, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1270, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1658, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1387, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1910, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1830, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1175, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1851, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1002, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0902, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1665, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2106, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1350, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1265, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0815, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1295, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2157, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2115, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1461, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1420, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0945, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1794, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1033, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2083, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0996, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2074, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1342, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1873, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.2198, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1243, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1507, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1089, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1888, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1064, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0939, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1643, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0874, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1071, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0857, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1135, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1583, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1181, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1382, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1162, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1301, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1673, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0909, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1139, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1458, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1131, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1168, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1245, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1589, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0567, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1569, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1876, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1869, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1046, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1242, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0742, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1792, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1213, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1402, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0734, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1522, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1334, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1749, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.1540, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  ...],\n",
       " 'eval_scores': []}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_trainer = Model_Trainer(gpus=[0])\n",
    "my_trainer.train(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='saved_models/BERT_reranker_q500k_h150_checkpoints/test_saves/',\n",
    "    save_top_k=3,\n",
    "    verbose=True,\n",
    "    monitor='ndcg',\n",
    "    mode='min',\n",
    "    prefix='BERT_reranker_500k_queries'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_validation_q_rels(valid_q_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(name='Longformer2k',project='pytorchlightning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type            | Params\n",
      "-----------------------------------------------\n",
      "0 | Longformer | LongformerModel | 148 M \n",
      "1 | dropout    | Dropout         | 0     \n",
      "2 | proj_layer | Linear          | 769   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cac825b3034aa784856454300f9cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
      "-----------------------------------------------------------------\n",
      "on_train_start      \t|  0.014943       \t|  0.014943       \n",
      "on_epoch_start      \t|  0.0012078      \t|  0.0012078      \n",
      "get_train_batch     \t|  0.0045961      \t|  13.908         \n",
      "on_batch_start      \t|  1.1327e-05     \t|  0.034276       \n",
      "model_forward       \t|  0.71043        \t|  2149.7         \n",
      "model_backward      \t|  0.45656        \t|  1381.1         \n",
      "on_after_backward   \t|  2.2378e-06     \t|  0.0067693      \n",
      "optimizer_step      \t|  0.017894       \t|  54.129         \n",
      "on_batch_end        \t|  0.0018957      \t|  5.7344         \n",
      "on_train_end        \t|  0.0012826      \t|  0.0012826      \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(gpus=1, profiler=True, \n",
    "                  print_nan_grads=True, \n",
    "                  num_sanity_val_steps=0,#len(val_dataloader), \n",
    "                  val_check_interval=0.02,\n",
    "                  accumulate_grad_batches=1,\n",
    "                  logger= wandb_logger,\n",
    "                  checkpoint_callback=checkpoint_callback)\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"example.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.validation_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.64140784740448,\n",
       " 0.650149941444397,\n",
       " 0.6211758255958557,\n",
       " 0.650149941444397,\n",
       " 0.6418268084526062,\n",
       " 0.650149941444397,\n",
       " 0.6800584197044373,\n",
       " 0.650149941444397,\n",
       " 0.6111412048339844,\n",
       " 0.650149941444397,\n",
       " 0.6355796456336975,\n",
       " 0.650149941444397,\n",
       " 0.6755321025848389,\n",
       " 0.650149941444397,\n",
       " 0.6149528622627258,\n",
       " 0.650149941444397]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"valid_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_raw_sampleget_topicsw_data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-d00a6732ef60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_raw_sampleget_topicsw_data_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mManual_Query_BM25_Reranking_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_raw_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_query_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_doc_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_raw_sampleget_topicsw_data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "train_raw_sampleget_topicsw_data_loader.get_topics(\"train\")\n",
    "train_dataset = Manual_Query_BM25_Reranking_Dataset(train_raw_samples, get_query_fn, get_doc_fn, hits=100)\n",
    "train_dataloader = train_dataset.to_dataloader(2, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bce016f5ef84cd7acb0e1c7a2c068a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9ecb85927f41b2a3fabc398c1925c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BERT_BM25_reranker = BERT_BM25_Reranker(raw_data_loader.get_doc, raw_data_loader.get_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranking_DataProcessor = Resolved_Query_Reranking_DataProcessor(raw_data_loader.get_doc, \n",
    "                                                  raw_data_loader.get_query, \n",
    "                                                  raw_data_loader.get_topics(\"train\"), \n",
    "                                                  BERT_BM25_reranker.first_pass_model.predict, \n",
    "                                                  numericalizer,\n",
    "                                                  max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = reranking_DataProcessor.to_dataloader(2, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25352"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce9bd326321495abdbede2b6c504e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=490.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/nfs/phd_by_carlos/notebooks/src/DataProcessors.py\", line 493, in __getitem__\n    samples = transform(samples)\n  File \"/nfs/phd_by_carlos/notebooks/src/DataProcessors.py\", line 465, in __call__\n    samples = transform(samples)\n  File \"/nfs/phd_by_carlos/notebooks/src/DataProcessors.py\", line 421, in __call__\n    sample_obj[\"doc\"] = self.get_doc_fn(sample_obj[\"d_id\"])\n  File \"/nfs/phd_by_carlos/notebooks/src/dataset_loaders.py\", line 256, in get_doc\n    return self.collection[d_id]\nKeyError: 'CAR_cce9dc23154a5887bbe92bfff13a4437b8ab2256'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-e9c8a58afcaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/nfs/phd_by_carlos/notebooks/src/DataProcessors.py\", line 493, in __getitem__\n    samples = transform(samples)\n  File \"/nfs/phd_by_carlos/notebooks/src/DataProcessors.py\", line 465, in __call__\n    samples = transform(samples)\n  File \"/nfs/phd_by_carlos/notebooks/src/DataProcessors.py\", line 421, in __call__\n    sample_obj[\"doc\"] = self.get_doc_fn(sample_obj[\"d_id\"])\n  File \"/nfs/phd_by_carlos/notebooks/src/dataset_loaders.py\", line 256, in get_doc\n    return self.collection[d_id]\nKeyError: 'CAR_cce9dc23154a5887bbe92bfff13a4437b8ab2256'\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm.tqdm(train_dataloader):\n",
    "    print(batch[\"input_ids\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BM25_Ranker'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM25_Ranker(get_query_fn).predict(\"32_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_call(model):\n",
    "    print(\"called evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092f26b5e6294db1ba40caadf5a8ba10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=725.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7824dd5b58da4de6b83ae31972830d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=597257159.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Longformer_Reranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval_callback = eval_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-928ed1003334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_clip_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_backend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_val_every_n_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(gpus=[0], profiler=True, gradient_clip_val=0.5, distributed_backend='dp', check_val_every_n_epoch=1)\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(torch.tensor([]), batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running an experiment on Y2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAsT_raw_data_loader = CAsT_RawDataLoader()\n",
    "get_query_fn = CAsT_raw_data_loader.get_query\n",
    "get_doc_fn = CAsT_raw_data_loader.get_doc\n",
    "eval_raw_samples = CAsT_raw_data_loader.get_topics(\"train\")\n",
    "CAsT_q_rels = CAsT_raw_data_loader.q_rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4633aec8aa47c79ea409708b3dc852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Searching queries', max=133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_samples = Query_Resolver_Transform(get_query_fn, utterance_type=\"manual_rewritten_utterance\")(eval_raw_samples)\n",
    "eval_BM25_results = BM25_Search_Transform(index_dir='datasets/TREC_CAsT/CAsT_collection_with_meta.index', hits=500)(eval_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 results\n",
      "{'map': 0.19679730164325712, 'recip_rank': 0.4596050256759099, 'ndcg_cut_3': 0.306364841910461, 'set_recall': 0.7744165761018662}\n",
      "RUN File Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0df4b7be9bc476b99c618cc8ab31e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Searching queries', max=133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'map': 0.22648101607514953, 'recip_rank': 0.48689326704789326, 'ndcg_cut_3': 0.3621256024784965, 'set_recall': 0.5633517089242985}\n",
      "ORACLE results\n",
      "{'map': 0.5633517089242985, 'recip_rank': 0.8345864661654135, 'ndcg_cut_3': 0.7816506828787912, 'set_recall': 0.5633517089242985}\n",
      "BERT+BM25 results\n",
      "cpu\n",
      "<All keys matched successfully>\n",
      "BERT ReRanker initialised on cuda:2. Batch size 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d45331ac68b4accb9f01d0038df8d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Reranking queries', max=133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'map': 0.10678501989112972, 'recip_rank': 0.25388222588499865, 'ndcg_cut_3': 0.14453453816167808, 'set_recall': 0.5633517089242985}\n"
     ]
    }
   ],
   "source": [
    "# experiment\n",
    "expr = Ranking_Experiment(CAsT_q_rels)\n",
    "print(\"BM25 results\")\n",
    "print(expr(eval_BM25_results))\n",
    "\n",
    "print(\"RUN File Model\")\n",
    "eval_run_rerank_results = RUN_File_Search_Transform('saved_models/CAsT_y1_pgbert.run', hits=500)(eval_samples)\n",
    "print(expr(eval_run_rerank_results))\n",
    "\n",
    "print(\"ORACLE results\")\n",
    "eval_oracle_rerank_results = Oracle_ReRanker_Transform(CAsT_q_rels)(eval_BM25_results)\n",
    "for sample in eval_oracle_rerank_results:\n",
    "    sample[\"search_results\"] = sample[\"reranked_results\"]\n",
    "print(expr(eval_oracle_rerank_results))\n",
    "\n",
    "print(\"BERT+BM25 results\")\n",
    "eval_BERT_rerank_results = BERT_ReRanker_Transform(\"saved_models/BERT_reranker_q100k_h100_checkpoints/BERT_ReRanker_MARCO_from_valid_0.38551378521302254.ckpt\", get_doc_fn, device=\"cuda:2\", batch_size=256)(eval_BM25_results)\n",
    "for sample in eval_BERT_rerank_results:\n",
    "    sample[\"search_results\"] = sample[\"reranked_results\"]\n",
    "print(expr(eval_BERT_rerank_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â\\x80\\x8bâ\\x80\\x8bResidential garage doors from Overhead Door are among the most dependable in the industry, so you can feel good knowing that weâ\\x80\\x99ll be there â\\x80\\x94 day or night, winter or summer. For added peace of mind, our home garage doors have also been proven to be durable and long lasting. The reliability of your garage door will help you stay on schedule in the morning. Its beauty will greet you at the end of a busy workday, opening convenient, comfortable passage to your home. And through the night, the security of your garage door will help you rest assured that your family is safe.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_doc_fn('MARCO_5593358')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPassageRanking(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BertForPassageRanking(BertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.weight = torch.autograd.Variable(torch.ones(2, config.hidden_size),\n",
    "                                              requires_grad=True)\n",
    "        self.bias = torch.autograd.Variable(torch.ones(2), requires_grad=True)\n",
    "\n",
    "bert_ranking = BertForPassageRanking.from_pretrained(\"saved_models/duoBERT/\",\n",
    "                                                     from_tf=True)\n",
    "type_embed_weight = bert_ranking.bert.embeddings.token_type_embeddings.weight.data\n",
    "bert_ranking.bert.embeddings.token_type_embeddings.weight.data = torch.cat((type_embed_weight, torch.zeros(1,1024)))\n",
    "bert_ranking.eval()\n",
    "bert_ranking.cuda()\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(\"saved_models/monoBERT/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1037, 102, 1038, 102], 'token_type_ids': [0, 0, 0, 1, 1], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(text=\"a\", text_pair='b', is_pretokenized=False,return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input length=torch.Size([1, 272])\n"
     ]
    }
   ],
   "source": [
    "query = 'how can I unfollow polaris 400 emails'\n",
    "bad_passage = 'Best Answer: Plastics are used in wide range of things. So it is produced in a very huge amount and its convenience is undeniable. Recycling of plastic is very important because it is made from the oil which will cause the regular depletion of this limited resource.With the recycling of plastic we can save oil and can use it for longer time. Moreover recycling do not cause harm to the quality of plastics.est Answer: Plastics are used in wide range of things. So it is produced in a very huge amount and its convenience is undeniable. Recycling of plastic is very important because it is made from the oil which will cause the regular depletion of this limited resource.'\n",
    "good_passage= \"polaris 400 starter. Follow polaris 400 starter to get e-mail alerts and updates on your eBay Feed. Unfollow polaris 400 starter to stop getting updates on your eBay Feed.Yay! You're now following polaris 400 starter in your eBay Feed.ollow polaris 400 starter to get e-mail alerts and updates on your eBay Feed. Unfollow polaris 400 starter to stop getting updates on your eBay Feed. Yay! You're now following polaris 400 starter in your eBay Feed.\"\n",
    "\n",
    "def custom_numericalize(query, docA, docB):\n",
    "    query_ids = [tokenizer.cls_token_id] + tokenizer.encode(query, add_special_tokens=False) + [tokenizer.sep_token_id]\n",
    "    query_token_type_ids = [0]*len(query_ids)\n",
    "\n",
    "    docA_ids = tokenizer.encode(docA, add_special_tokens=False) + [tokenizer.sep_token_id]\n",
    "    docA_token_type_ids = [1]*len(docA_ids)\n",
    "\n",
    "    docB_ids = tokenizer.encode(docB, add_special_tokens=False) + [tokenizer.sep_token_id]\n",
    "    docB_token_type_ids = [2]*len(docB_ids)\n",
    "\n",
    "    input_ids = torch.tensor(query_ids+docA_ids+docB_ids).unsqueeze(0)\n",
    "    input_type_ids = torch.tensor(query_token_type_ids+docA_token_type_ids+docB_token_type_ids).unsqueeze(0)\n",
    "    return input_ids, input_type_ids\n",
    "\n",
    "print(f\"Input length={input_ids.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chekcpoint from saved_models/duoBERT/\n",
      "DuoBERT ReRanker initialised on cuda. Batch size 32\n"
     ]
    }
   ],
   "source": [
    "duoBERT_reranker_transform = DuoBERT_ReRanker_Transform(\"saved_models/duoBERT/\", get_doc_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaea8abf1d445b18dd0970aa24a12da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Reranking queries', max=1.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'query': 'query text',\n",
       "  'search_results': [('MARCO_32', 0.4), ('MARCO_55', 0.3)],\n",
       "  'reranked_results': [('MARCO_32', 4.047558307647705),\n",
       "   ('MARCO_55', -4.047558307647705)]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples = [{'query':\"query text\",'search_results':[(\"MARCO_32\", 0.4), (\"MARCO_55\",0.3)]}]\n",
    "\n",
    "test_samples = duoBERT_reranker_transform(test_samples)\n",
    "test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0861,  0.6057]], grad_fn=<AddmmBackward>),)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = bert_ranking(input_ids, token_type_ids=input_type_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2233, -0.7396]], grad_fn=<AddmmBackward>),)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = bert_ranking(input_ids, token_type_ids=input_type_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2688,  0.3415]], device='cuda:0', grad_fn=<AddmmBackward>),)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids, input_type_ids = custom_numericalize(query, good_passage, bad_passage)\n",
    "outputs = bert_ranking(input_ids.cuda(), token_type_ids=input_type_ids.cuda())\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5154, -0.5022]], device='cuda:0', grad_fn=<AddmmBackward>),)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids, input_type_ids = custom_numericalize(query, bad_passage, good_passage)\n",
    "outputs = bert_ranking(input_ids.cuda(), token_type_ids=input_type_ids.cuda())\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1037,  1031, 19802,  1033,  1038,   102]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(tokenizer.encode(\"a [SEP] b\")).unsqueeze(0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why is it important to recycle plastic bags'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(query_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0415, -0.0227]]),)\n",
      "(tensor([[-0.9739,  0.0645]]),)\n"
     ]
    }
   ],
   "source": [
    "dummy_query = [\n",
    "    'why is it important to recycle plastic bags',\n",
    "    'why is it important to recycle plastic bags'\n",
    "]\n",
    "\n",
    "dummy_passage = [\n",
    "    'Best Answer: Plastics are used in wide range of things. So it is produced in a very huge amount and its convenience is undeniable. Recycling of plastic is very important because it is made from the oil which will cause the regular depletion of this limited resource.With the recycling of plastic we can save oil and can use it for longer time. Moreover recycling do not cause harm to the quality of plastics.est Answer: Plastics are used in wide range of things. So it is produced in a very huge amount and its convenience is undeniable. Recycling of plastic is very important because it is made from the oil which will cause the regular depletion of this limited resource.',\n",
    "    \"polaris 400 starter. Follow polaris 400 starter to get e-mail alerts and updates on your eBay Feed. Unfollow polaris 400 starter to stop getting updates on your eBay Feed.Yay! You're now following polaris 400 starter in your eBay Feed.ollow polaris 400 starter to get e-mail alerts and updates on your eBay Feed. Unfollow polaris 400 starter to stop getting updates on your eBay Feed. Yay! You're now following polaris 400 starter in your eBay Feed.\"\n",
    "]\n",
    "bert_ranking.eval()\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(dummy_query)):\n",
    "        input_ids = torch.tensor(tokenizer.encode(text=dummy_query[idx], \\\n",
    "            text_pair=dummy_passage[idx], add_special_tokens=True)).unsqueeze(0)\n",
    "        outputs = bert_ranking(input_ids)\n",
    "        print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10, shape=(4, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.one_hot([0,1,2,3], depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=21, shape=(1, 2), dtype=int32, numpy=array([[2, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul([[1,0]], [[2,3],\n",
    "                    [4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAsT_raw_data_loader = CAsT_RawDataLoader()\n",
    "get_query_fn = CAsT_raw_data_loader.get_query\n",
    "get_doc_fn = CAsT_raw_data_loader.get_doc\n",
    "eval_raw_samples = CAsT_raw_data_loader.get_topics(\"all\")\n",
    "CAsT_q_rels = CAsT_raw_data_loader.q_rels\n",
    "len(eval_raw_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd78691d07f5458face49d884dee51d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Searching queries', max=163.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BM25 results\n",
      "{'map': 0.19751538242688302, 'recip_rank': 0.44835046104876053, 'ndcg_cut_3': 0.28929055308073365, 'set_recall': 0.8436929924957347}\n"
     ]
    }
   ],
   "source": [
    "eval_samples = Query_Resolver_Transform(get_query_fn, utterance_type=\"manual_rewritten_utterance\")(eval_raw_samples)\n",
    "eval_BM25_results = BM25_Search_Transform(index_dir='datasets/TREC_CAsT/CAsT_collection_with_meta.index', hits=1000)(eval_samples)\n",
    "expr = Ranking_Experiment(CAsT_q_rels)\n",
    "print(\"BM25 results\")\n",
    "print(expr(eval_BM25_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1808273385c40aabfcc7c112881220e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Flattening search results', max=163.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8bd53409ff50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_BM25_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReranking_Flattener_Transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_BM25_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nfs/phd_by_carlos/notebooks/src/models_and_transforms/text_transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"search_results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0md_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mnew_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mnew_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"d_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mnew_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'search_results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_tuple\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;31m# We're not going to put the tuple in the memo, but it's still important we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m# check for it, in case the tuple contains recursive mutable structures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_BM25_results = Reranking_Flattener_Transform()(eval_BM25_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-2a6c3769b8fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0meval_BM25_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument_Resolver_Transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_doc_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_BM25_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meval_BM25_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonoBERT_Numericalise_Transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_models/monoBERT/vocab.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_BM25_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nfs/phd_by_carlos/notebooks/src/models_and_transforms/text_transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mdoc_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mdoc_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mdoc_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             )\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtok_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_strip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_split_on_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhitespace_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_BM25_results = Document_Resolver_Transform(get_doc_fn)(eval_BM25_results)\n",
    "eval_BM25_results = MonoBERT_Numericalise_Transform(\"saved_models/monoBERT/vocab.txt\")(eval_BM25_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chekcpoint from ./saved_models/monoBERT/\n",
      "MonoBERT ReRanker initialised on device cpu. Batch size 32\n"
     ]
    }
   ],
   "source": [
    "monoBERT_transform = monoBERT_Scorer_Transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_samples = eval_BM25_results[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = [\n",
    "    {'q_id':'31_1', 'd_id':'CAR_2174ad0aa50712ff24035c23f59a3c2b43267650'}, # relevant\n",
    "    {'q_id':'31_1', 'd_id':'MARCO_2182567'} # not relevant\n",
    "]\n",
    "test_samples = Query_Resolver_Transform(get_query_fn, utterance_type=\"manual_rewritten_utterance\")(test_samples)\n",
    "test_samples = Document_Resolver_Transform(get_doc_fn)(test_samples)\n",
    "test_samples = MonoBERT_Numericalise_Transform(\"saved_models/monoBERT/vocab.txt\")(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f7a08c083e4cc49b20d32f6b5e660e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2858, 0.1724], device='cuda:0') torch.Size([2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monoBERT_results = monoBERT_transform(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bac36355e8f494cbb9df7f7ec5c1c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Searching queries', max=133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_mono_reranked_samples = RUN_File_Search_Transform('saved_models/monoBERT/manual_y1_BM25_monoBERT_500.run', hits=500)(eval_BM25_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chekcpoint from saved_models/monoBERT/\n",
      "MonoBERT ReRanker initialised on device cuda:0. Batch size 100\n"
     ]
    }
   ],
   "source": [
    "monoBERT_reranker_transform = MonoBERT_ReRanker_Transform('saved_models/monoBERT/', get_doc_fn, device=\"cuda:0\", batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6933c8277c8d48d4b2fa3b6c0f8a9793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Reranking queries', max=163.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 1353.54 s\n",
       "File: /nfs/phd_by_carlos/notebooks/src/models_and_transforms/complex_transforms.py\n",
       "Function: __call__ at line 197\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   197                                               def __call__(self, samples):\n",
       "   198                                                   '''\n",
       "   199                                                   samples: [dict]: [{'input_ids':[34,2,8...], 'type_ids':[0,0,1,1]}]\n",
       "   200                                                   returns: [dict]: [{'input_ids':[34,2,8...], 'type_ids':[0,0,1,1], \"score\":0.56}]\n",
       "   201                                                   '''\n",
       "   202       163      11336.0     69.5      0.0          all_scores = torch.zeros((0,1), device=self.device)\n",
       "   203      1793      13774.0      7.7      0.0          for sample_obj_batch in chunks(samples, self.batch_size):\n",
       "   204      1630       6335.0      3.9      0.0              with torch.no_grad():\n",
       "   205      1630       3960.0      2.4      0.0                  input_tensor = torch.nn.utils.rnn.pad_sequence(\n",
       "   206      1630    2945287.0   1806.9      0.2                                  [torch.tensor(sample_obj[\"input_ids\"], dtype=torch.long, device=self.device) for sample_obj in sample_obj_batch], \n",
       "   207      1630    2118393.0   1299.6      0.2                                                       padding_value=self.PAD).T\n",
       "   208      1630       3654.0      2.2      0.0                  type_ids = torch.nn.utils.rnn.pad_sequence(\n",
       "   209      1630     532379.0    326.6      0.0                                  [torch.tensor(sample_obj[\"type_ids\"], dtype=torch.long) for sample_obj in sample_obj_batch], \n",
       "   210      1630    1752044.0   1074.9      0.1                                                       padding_value=self.PAD).T.to(self.device)\n",
       "   211      1630      99330.0     60.9      0.0                  attention_mask = (input_tensor != self.PAD).type(torch.float).to(self.device)\n",
       "   212      1630 1345833835.0 825664.9     99.4                  scores = self.BERT_Reranker(input_tensor, attention_mask=attention_mask, token_type_ids=type_ids)[0][:,1].tolist()\n",
       "   213    164630     101236.0      0.6      0.0              for sample_obj, score in zip(sample_obj_batch, scores):\n",
       "   214    163000     117556.0      0.7      0.0                  sample_obj[\"score\"] = score\n",
       "   215       163         95.0      0.6      0.0          return samples"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f monoBERT_reranker_transform.monoBERT_score_transform.__call__ eval_mono_reranked_samples = monoBERT_reranker_transform(eval_BM25_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((1,1000000), device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  ...]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 results\n",
      "{'map': 0.3276171720443938, 'recip_rank': 0.6457977304271202, 'ndcg_cut_3': 0.4980726465235735, 'set_recall': 0.7744165761018662}\n"
     ]
    }
   ],
   "source": [
    "# for sample in eval_mono_reranked_samples:\n",
    "#     sample[\"search_results\"] = [(d_id, score) for d_id, score in sample[\"reranked_results\"]]\n",
    "expr = Ranking_Experiment(CAsT_q_rels)\n",
    "print(\"BM25 results\")\n",
    "print(expr(eval_mono_reranked_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chekcpoint from saved_models/duoBERT/\n",
      "DuoBERT ReRanker initialised on cuda. Batch size 32\n"
     ]
    }
   ],
   "source": [
    "duoBERT_reranker_transform = DuoBERT_ReRanker_Transform(\"saved_models/duoBERT/\", get_doc_fn, rerank_top=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ba81e662a14943afc40bd49485e33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Reranking queries', max=133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_duo_reranked_samples = duoBERT_reranker_transform(eval_mono_reranked_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in eval_mono_reranked_samples:\n",
    "    sample[\"search_results\"] = [(d_id, score) for d_id, score in sample[\"reranked_results\"]]\n",
    "expr = Ranking_Experiment(CAsT_q_rels)\n",
    "print(\"BM25 results\")\n",
    "print(expr(eval_duo_reranked_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing to RUN file', max=163.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 81500 samples from 163 queries run to: saved_models/monoBERT/manual_y1_BM25_monoBERT_500.run\n"
     ]
    }
   ],
   "source": [
    "run_file_exporter = RUN_File_Transform_Exporter('saved_models/monoBERT/manual_y1_BM25_monoBERT_500.run', model_name='monoBERT')\n",
    "run_file_exporter(eval_mono_reranked_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': 0.052117325670267264, 'recip_rank': 0.01098901098901099, 'ndcg_cut_3': 0.0, 'set_recall': 0.9523809523809523}\n",
      "{'map': 0.010214954952767282, 'recip_rank': 0.0056179775280898875, 'ndcg_cut_3': 0.0, 'set_recall': 0.5151515151515151}\n",
      "{'map': 0.06408624931028395, 'recip_rank': 0.01818181818181818, 'ndcg_cut_3': 0.0, 'set_recall': 0.675}\n",
      "{'map': 0.04213950997777283, 'recip_rank': 0.011596268899639687, 'ndcg_cut_3': 0.0, 'set_recall': 0.7141774891774891}\n"
     ]
    }
   ],
   "source": [
    "print(expr(eval_mono_reranked_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in eval_mono_reranked_samples:\n",
    "    del sample['q_rel']\n",
    "    del sample['prev_turns']\n",
    "    del sample['q_id']\n",
    "    del sample['reranked_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev_turns': ['31_1', '31_2', '31_3'],\n",
       " 'q_id': '31_4',\n",
       " 'q_rel': ['CAR_10d3185b987e4a3247ddf302d1a77af0d8089057',\n",
       "  'CAR_2345165208413ae4d82c1a5f4145564a1216b267',\n",
       "  'CAR_2dfe7045bf79ea1c881c0fce663113cb941e1b8d',\n",
       "  'CAR_6d9ed0c735dfc7b5e4c487b3582fa9e24adece7e',\n",
       "  'CAR_6fd0c21b5771545db27842d1cbb35961bc78d548',\n",
       "  'CAR_80b9307468496c2e2cda4d3f67c3424adf40a2d1',\n",
       "  'CAR_abd3181f15bc33e8ef101761ef7f29d5d8943f87',\n",
       "  'CAR_be26d2e44cbc807a3477aeba36d49931df11be1e',\n",
       "  'CAR_dedad08c40164cee79464fdeb8da5e3e46b402ea',\n",
       "  'CAR_fd096e610b37453cb360b8b45f90f876dac850d1',\n",
       "  'CAR_ff289fa20c9d45ffdb79d31487034aaf513e027b',\n",
       "  'MARCO_1127654',\n",
       "  'MARCO_1198831',\n",
       "  'MARCO_1734120',\n",
       "  'MARCO_1736079',\n",
       "  'MARCO_1801310',\n",
       "  'MARCO_1801311',\n",
       "  'MARCO_1826636',\n",
       "  'MARCO_1855231',\n",
       "  'MARCO_1916591',\n",
       "  'MARCO_1916598',\n",
       "  'MARCO_1976714',\n",
       "  'MARCO_217417',\n",
       "  'MARCO_217421',\n",
       "  'MARCO_2539075',\n",
       "  'MARCO_2700408',\n",
       "  'MARCO_28054',\n",
       "  'MARCO_28058',\n",
       "  'MARCO_2916594',\n",
       "  'MARCO_2916597',\n",
       "  'MARCO_3368653',\n",
       "  'MARCO_3368661',\n",
       "  'MARCO_353890',\n",
       "  'MARCO_353891',\n",
       "  'MARCO_353893',\n",
       "  'MARCO_3818695',\n",
       "  'MARCO_407855',\n",
       "  'MARCO_4641439',\n",
       "  'MARCO_4703036',\n",
       "  'MARCO_484107',\n",
       "  'MARCO_5032908',\n",
       "  'MARCO_5032914',\n",
       "  'MARCO_5242227',\n",
       "  'MARCO_530132',\n",
       "  'MARCO_580156',\n",
       "  'MARCO_580162',\n",
       "  'MARCO_6472757',\n",
       "  'MARCO_6559518',\n",
       "  'MARCO_6661766',\n",
       "  'MARCO_6661767',\n",
       "  'MARCO_6661768',\n",
       "  'MARCO_6661771',\n",
       "  'MARCO_695583',\n",
       "  'MARCO_7225072',\n",
       "  'MARCO_7242148',\n",
       "  'MARCO_7471766',\n",
       "  'MARCO_7471772',\n",
       "  'MARCO_7471773',\n",
       "  'MARCO_7513923',\n",
       "  'MARCO_7562357',\n",
       "  'MARCO_8666788',\n",
       "  'MARCO_940332'],\n",
       " 'query': \"What are lung cancer's symptoms?\",\n",
       " 'search_results': [('MARCO_7796731', -0.40620577335357666),\n",
       "  ('MARCO_3061647', -0.376916766166687),\n",
       "  ('MARCO_8747676', -0.3404342234134674),\n",
       "  ('MARCO_2771362', -0.3383066654205322),\n",
       "  ('MARCO_353892', -0.3357889950275421),\n",
       "  ('CAR_aa5c2a61aefc3679ad81ad8673abbc4da5723eb1', -0.33421850204467773),\n",
       "  ('MARCO_7150693', -0.326328843832016),\n",
       "  ('MARCO_7653912', -0.32380765676498413),\n",
       "  ('MARCO_2437377', -0.31336838006973267),\n",
       "  ('MARCO_3368657', -0.3114825487136841),\n",
       "  ('MARCO_3962523', -0.3111346364021301),\n",
       "  ('MARCO_4888192', -0.3096495270729065),\n",
       "  ('MARCO_8801845', -0.30848824977874756),\n",
       "  ('MARCO_4196556', -0.3069588541984558),\n",
       "  ('MARCO_217420', -0.30263614654541016),\n",
       "  ('MARCO_6243037', -0.2991548180580139),\n",
       "  ('MARCO_3818696', -0.2985265851020813),\n",
       "  ('CAR_2345165208413ae4d82c1a5f4145564a1216b267', -0.29432520270347595),\n",
       "  ('MARCO_1868370', -0.2921411097049713),\n",
       "  ('MARCO_97872', -0.2910309433937073),\n",
       "  ('MARCO_3061641', -0.286838173866272),\n",
       "  ('MARCO_3403545', -0.28480425477027893),\n",
       "  ('CAR_ddc63cc2ada780683dba8934e96991764268c482', -0.2830232083797455),\n",
       "  ('MARCO_2019127', -0.2829996645450592),\n",
       "  ('MARCO_5883839', -0.28245049715042114),\n",
       "  ('MARCO_1278953', -0.2805783450603485),\n",
       "  ('MARCO_7679244', -0.2794209122657776),\n",
       "  ('MARCO_4215954', -0.2762289047241211),\n",
       "  ('MARCO_8211636', -0.26857441663742065),\n",
       "  ('MARCO_3400285', -0.2674144506454468),\n",
       "  ('MARCO_3678356', -0.26680150628089905),\n",
       "  ('MARCO_2337295', -0.2653082013130188),\n",
       "  ('MARCO_8567129', -0.25481265783309937),\n",
       "  ('MARCO_5222288', -0.2469460666179657),\n",
       "  ('CAR_be26d2e44cbc807a3477aeba36d49931df11be1e', -0.24432364106178284),\n",
       "  ('MARCO_8804941', -0.23873086273670197),\n",
       "  ('MARCO_1621872', -0.23395130038261414),\n",
       "  ('MARCO_4882255', -0.23376896977424622),\n",
       "  ('MARCO_135784', -0.22586122155189514),\n",
       "  ('MARCO_1037979', -0.21693605184555054),\n",
       "  ('CAR_da577b4897cc5c1e1854ffd3f020699d801de745', -0.21459953486919403),\n",
       "  ('MARCO_3685141', -0.21413807570934296),\n",
       "  ('MARCO_5289777', -0.20432667434215546),\n",
       "  ('MARCO_1198831', -0.20330435037612915),\n",
       "  ('MARCO_2416874', -0.19573789834976196),\n",
       "  ('MARCO_6478901', -0.1931971311569214),\n",
       "  ('MARCO_3417415', -0.18848347663879395),\n",
       "  ('MARCO_1734120', -0.18240970373153687),\n",
       "  ('CAR_c1ac2e36df99e79291d18ba5193bb378238ece6c', -0.1808847188949585),\n",
       "  ('MARCO_2377194', -0.17859190702438354),\n",
       "  ('MARCO_1251563', -0.1769723892211914),\n",
       "  ('MARCO_5483954', -0.16808323562145233),\n",
       "  ('MARCO_2590787', -0.16639912128448486),\n",
       "  ('CAR_563db7ec73378a21d17f67172678640d89420070', -0.1564759910106659),\n",
       "  ('MARCO_6974024', -0.15449747443199158),\n",
       "  ('MARCO_407855', -0.151314377784729),\n",
       "  ('MARCO_5222283', -0.15102969110012054),\n",
       "  ('MARCO_1037976', -0.14712318778038025),\n",
       "  ('MARCO_3811532', -0.14496202766895294),\n",
       "  ('MARCO_4020155', -0.14373049139976501),\n",
       "  ('CAR_041ec49de60bad7c42e953c53bb8516eee6e7e84', -0.14349153637886047),\n",
       "  ('MARCO_3400281', -0.14321230351924896),\n",
       "  ('CAR_6fd0c21b5771545db27842d1cbb35961bc78d548', -0.14193573594093323),\n",
       "  ('MARCO_558907', -0.13783004879951477),\n",
       "  ('MARCO_7796732', -0.12872636318206787),\n",
       "  ('MARCO_5043573', -0.12773719429969788),\n",
       "  ('MARCO_5703220', -0.1273094117641449),\n",
       "  ('MARCO_2585716', -0.121678426861763),\n",
       "  ('MARCO_7796734', -0.12028755992650986),\n",
       "  ('MARCO_7679247', -0.11530318111181259),\n",
       "  ('MARCO_1826636', -0.11336006969213486),\n",
       "  ('MARCO_3403546', -0.11110945791006088),\n",
       "  ('MARCO_2257661', -0.11099973320960999),\n",
       "  ('MARCO_171675', -0.10752978175878525),\n",
       "  ('MARCO_4020152', -0.103643998503685),\n",
       "  ('MARCO_1976711', -0.09946028888225555),\n",
       "  ('MARCO_1978626', -0.09803487360477448),\n",
       "  ('MARCO_4627140', -0.09426569938659668),\n",
       "  ('MARCO_3909436', -0.09388165920972824),\n",
       "  ('MARCO_6973312', -0.09340950846672058),\n",
       "  ('MARCO_6852557', -0.09338943660259247),\n",
       "  ('CAR_826d785b9bde75ea3f8f519e3c96514fe6b7bc96', -0.09231286495923996),\n",
       "  ('MARCO_1941329', -0.0913235992193222),\n",
       "  ('CAR_02a460927d09c91fa3d4f3ea8a29e8ffa5219c5c', -0.08852747082710266),\n",
       "  ('CAR_2373ac4b54980061dd412b3d2738c28387dbc769', -0.08796162903308868),\n",
       "  ('MARCO_3565865', -0.0869525820016861),\n",
       "  ('CAR_beaa19b9206e1bf4ec09931cee92f4eab58c1597', -0.0861138105392456),\n",
       "  ('MARCO_8317504', -0.08533311635255814),\n",
       "  ('MARCO_3143910', -0.08374010026454926),\n",
       "  ('CAR_7b05e5fc480de635475f0475110ca2a1b2ecde50', -0.08118720352649689),\n",
       "  ('MARCO_6748841', -0.07869147509336472),\n",
       "  ('MARCO_7556533', -0.0785345509648323),\n",
       "  ('MARCO_7541281', -0.07766593992710114),\n",
       "  ('MARCO_6661770', -0.07727839052677155),\n",
       "  ('MARCO_493988', -0.07673414051532745),\n",
       "  ('MARCO_1244914', -0.07556181401014328),\n",
       "  ('MARCO_8422445', -0.07450161874294281),\n",
       "  ('MARCO_1244907', -0.07397547364234924),\n",
       "  ('MARCO_2377407', -0.07241035997867584),\n",
       "  ('MARCO_3970689', -0.07240894436836243),\n",
       "  ('MARCO_6235797', -0.0710233598947525),\n",
       "  ('MARCO_2796572', -0.07097116112709045),\n",
       "  ('MARCO_656173', -0.07066785544157028),\n",
       "  ('MARCO_580162', -0.07012869417667389),\n",
       "  ('MARCO_8791607', -0.06835224479436874),\n",
       "  ('MARCO_5241416', -0.067720927298069),\n",
       "  ('MARCO_1855020', -0.06662296503782272),\n",
       "  ('MARCO_6914828', -0.06656848639249802),\n",
       "  ('MARCO_4677844', -0.06629373133182526),\n",
       "  ('MARCO_7814093', -0.06530901789665222),\n",
       "  ('MARCO_5703222', -0.06499502062797546),\n",
       "  ('MARCO_765808', -0.06492854654788971),\n",
       "  ('MARCO_4675037', -0.06451111286878586),\n",
       "  ('MARCO_4244556', -0.06436972320079803),\n",
       "  ('MARCO_8422444', -0.06397522985935211),\n",
       "  ('MARCO_6624627', -0.063791424036026),\n",
       "  ('MARCO_7958619', -0.06357426196336746),\n",
       "  ('MARCO_6608643', -0.06291940808296204),\n",
       "  ('MARCO_7966318', -0.06282675266265869),\n",
       "  ('MARCO_3425311', -0.06274241209030151),\n",
       "  ('MARCO_7626948', -0.06241161376237869),\n",
       "  ('MARCO_4998693', -0.06232786178588867),\n",
       "  ('MARCO_7824045', -0.06168990582227707),\n",
       "  ('MARCO_962771', -0.06168385595083237),\n",
       "  ('MARCO_1514920', -0.0614943653345108),\n",
       "  ('MARCO_5540414', -0.061183348298072815),\n",
       "  ('CAR_f3a33904b0049b80e0bf94b19ab6fb34693f95c6', -0.06111568212509155),\n",
       "  ('MARCO_492805', -0.061083875596523285),\n",
       "  ('MARCO_407860', -0.060522712767124176),\n",
       "  ('MARCO_227179', -0.060431912541389465),\n",
       "  ('CAR_0620fda4a62096b0f568e662fbc16f73cb4f0fbf', -0.059959135949611664),\n",
       "  ('MARCO_3143140', -0.05970682203769684),\n",
       "  ('MARCO_654272', -0.058593399822711945),\n",
       "  ('MARCO_5896774', -0.058028094470500946),\n",
       "  ('MARCO_580156', -0.05788569152355194),\n",
       "  ('MARCO_825811', -0.05741308629512787),\n",
       "  ('MARCO_2257662', -0.05707171559333801),\n",
       "  ('MARCO_7536007', -0.05674968659877777),\n",
       "  ('MARCO_7001837', -0.05663607269525528),\n",
       "  ('MARCO_3379756', -0.05658358335494995),\n",
       "  ('MARCO_140073', -0.05627540498971939),\n",
       "  ('MARCO_7811014', -0.05593400448560715),\n",
       "  ('MARCO_5043576', -0.05576212704181671),\n",
       "  ('MARCO_7150698', -0.05576083064079285),\n",
       "  ('MARCO_1741184', -0.05463649332523346),\n",
       "  ('MARCO_1681894', -0.054620690643787384),\n",
       "  ('MARCO_8334625', -0.05447841435670853),\n",
       "  ('MARCO_4396328', -0.05428692698478699),\n",
       "  ('MARCO_4881454', -0.05415376275777817),\n",
       "  ('MARCO_129475', -0.05367017537355423),\n",
       "  ('MARCO_977359', -0.053668275475502014),\n",
       "  ('MARCO_830026', -0.05366311967372894),\n",
       "  ('MARCO_353891', -0.0536496639251709),\n",
       "  ('MARCO_830027', -0.053047455847263336),\n",
       "  ('CAR_dedad08c40164cee79464fdeb8da5e3e46b402ea', -0.0528101772069931),\n",
       "  ('MARCO_589747', -0.05280429124832153),\n",
       "  ('MARCO_4243822', -0.05269871652126312),\n",
       "  ('MARCO_102050', -0.05261418968439102),\n",
       "  ('MARCO_6618125', -0.05192698538303375),\n",
       "  ('MARCO_940332', -0.05182307958602905),\n",
       "  ('MARCO_6048118', -0.05162035673856735),\n",
       "  ('MARCO_1736079', -0.051520854234695435),\n",
       "  ('CAR_bb03d4c17092b6f9fcf66aae6e8eb33a158b2eb0', -0.05151118338108063),\n",
       "  ('MARCO_493981', -0.05131770670413971),\n",
       "  ('MARCO_1769388', -0.0510641485452652),\n",
       "  ('MARCO_580159', -0.05096600204706192),\n",
       "  ('MARCO_2873522', -0.05092594772577286),\n",
       "  ('MARCO_1868373', -0.050645679235458374),\n",
       "  ('MARCO_6785834', -0.05061739683151245),\n",
       "  ('MARCO_7694051', -0.0505402535200119),\n",
       "  ('CAR_e3f6a71641b264d86f4d90d494c7d71204a941dc', -0.050436101853847504),\n",
       "  ('MARCO_8772511', -0.05017904192209244),\n",
       "  ('MARCO_1475376', -0.04927036166191101),\n",
       "  ('MARCO_3962526', -0.0491933673620224),\n",
       "  ('MARCO_2524398', -0.049191877245903015),\n",
       "  ('MARCO_7966319', -0.049165576696395874),\n",
       "  ('MARCO_4365692', -0.048740074038505554),\n",
       "  ('MARCO_4925208', -0.048724688589572906),\n",
       "  ('MARCO_7513928', -0.04855047166347504),\n",
       "  ('CAR_1ee4535ac037409a6dee25cc293b43f2386ac954', -0.04777871444821358),\n",
       "  ('MARCO_4263415', -0.04762019217014313),\n",
       "  ('MARCO_1604973', -0.047429993748664856),\n",
       "  ('CAR_9217a8308fb48b02e36606808d5b5a1541fe3c66', -0.047314584255218506),\n",
       "  ('MARCO_531524', -0.04712036997079849),\n",
       "  ('MARCO_6811694', -0.04711248725652695),\n",
       "  ('CAR_10d3185b987e4a3247ddf302d1a77af0d8089057', -0.04682272672653198),\n",
       "  ('MARCO_8422443', -0.046577103435993195),\n",
       "  ('MARCO_7797156', -0.04656708985567093),\n",
       "  ('MARCO_1278952', -0.046392619609832764),\n",
       "  ('MARCO_3368658', -0.046350523829460144),\n",
       "  ('MARCO_353888', -0.046173855662345886),\n",
       "  ('MARCO_4641439', -0.04615825414657593),\n",
       "  ('MARCO_8025746', -0.0460820347070694),\n",
       "  ('MARCO_1868371', -0.046055786311626434),\n",
       "  ('MARCO_8162046', -0.04602561146020889),\n",
       "  ('MARCO_5040135', -0.04597315937280655),\n",
       "  ('MARCO_6109393', -0.04584190249443054),\n",
       "  ('MARCO_8163476', -0.045725367963314056),\n",
       "  ('MARCO_5641308', -0.045144110918045044),\n",
       "  ('MARCO_353887', -0.04504463076591492),\n",
       "  ('CAR_75df9a77d12622d6ec98fe76435da01dfb652d5e', -0.044829435646533966),\n",
       "  ('MARCO_654271', -0.04425700753927231),\n",
       "  ('MARCO_735329', -0.04423574358224869),\n",
       "  ('MARCO_377997', -0.0440114364027977),\n",
       "  ('MARCO_7646892', -0.04386594891548157),\n",
       "  ('MARCO_8334626', -0.04386376589536667),\n",
       "  ('MARCO_797500', -0.04380036145448685),\n",
       "  ('MARCO_3056456', -0.04374511539936066),\n",
       "  ('MARCO_3818695', -0.043700143694877625),\n",
       "  ('MARCO_305235', -0.04324604570865631),\n",
       "  ('MARCO_7606759', -0.04308287799358368),\n",
       "  ('MARCO_8397814', -0.04263579100370407),\n",
       "  ('MARCO_217415', -0.04257754981517792),\n",
       "  ('MARCO_2141694', -0.042516253888607025),\n",
       "  ('MARCO_2573511', -0.04235658049583435),\n",
       "  ('MARCO_1976714', -0.04226060211658478),\n",
       "  ('MARCO_73784', -0.042230382561683655),\n",
       "  ('MARCO_7242148', -0.042067766189575195),\n",
       "  ('MARCO_8299655', -0.0419364869594574),\n",
       "  ('MARCO_6826590', -0.0415269136428833),\n",
       "  ('MARCO_925772', -0.041309475898742676),\n",
       "  ('MARCO_7958622', -0.04120267927646637),\n",
       "  ('MARCO_4367351', -0.04114263504743576),\n",
       "  ('MARCO_4238136', -0.04100121557712555),\n",
       "  ('MARCO_735334', -0.04096604138612747),\n",
       "  ('MARCO_6826593', -0.04091736674308777),\n",
       "  ('MARCO_2630154', -0.040821418166160583),\n",
       "  ('MARCO_3985694', -0.040812231600284576),\n",
       "  ('MARCO_2491347', -0.04079337418079376),\n",
       "  ('MARCO_8025747', -0.04046855866909027),\n",
       "  ('MARCO_1423443', -0.04043082892894745),\n",
       "  ('CAR_f061e731dd7727ce45ab9332dab72a672463b03b', -0.04000601917505264),\n",
       "  ('CAR_3f9696422624d6e10c022b8d62c6827d284038c6', -0.0399644672870636),\n",
       "  ('MARCO_6322532', -0.039950162172317505),\n",
       "  ('CAR_fcc94d4f8056003ec0b2490000dc6b3272302d83', -0.03994809091091156),\n",
       "  ('MARCO_4856548', -0.03994006663560867),\n",
       "  ('MARCO_5861900', -0.039933472871780396),\n",
       "  ('MARCO_1433066', -0.0398830771446228),\n",
       "  ('MARCO_4227676', -0.03973694145679474),\n",
       "  ('MARCO_1153271', -0.03971049189567566),\n",
       "  ('CAR_34af28ae6a8ecfeadb12fe31954cacbf3e237437', -0.03966712951660156),\n",
       "  ('MARCO_8486480', -0.03965136408805847),\n",
       "  ('CAR_8496d6efabfe289446c9215973e11020c8d19a5e', -0.039608366787433624),\n",
       "  ('CAR_21ddff105fbbf8b638f367cf1eb980a7f610d384', -0.03949602693319321),\n",
       "  ('MARCO_1035406', -0.039260782301425934),\n",
       "  ('MARCO_4858046', -0.03911682963371277),\n",
       "  ('MARCO_5858872', -0.039043813943862915),\n",
       "  ('MARCO_7621229', -0.03865721821784973),\n",
       "  ('MARCO_2771361', -0.03864899277687073),\n",
       "  ('MARCO_8775216', -0.03846712410449982),\n",
       "  ('MARCO_5641305', -0.03844917565584183),\n",
       "  ('MARCO_4612534', -0.03839697688817978),\n",
       "  ('MARCO_7471772', -0.038204118609428406),\n",
       "  ('MARCO_5510268', -0.03773385286331177),\n",
       "  ('MARCO_2462478', -0.03758467733860016),\n",
       "  ('MARCO_6482702', -0.03754027187824249),\n",
       "  ('MARCO_5242226', -0.03749026358127594),\n",
       "  ('MARCO_6051424', -0.03742114454507828),\n",
       "  ('MARCO_4926579', -0.037252262234687805),\n",
       "  ('MARCO_7560124', -0.03713387995958328),\n",
       "  ('MARCO_510725', -0.037030600011348724),\n",
       "  ('MARCO_2141693', -0.036839619278907776),\n",
       "  ('MARCO_6405364', -0.03671377897262573),\n",
       "  ('MARCO_1182756', -0.0367128849029541),\n",
       "  ('MARCO_4627143', -0.03661881387233734),\n",
       "  ('MARCO_4675032', -0.03657030314207077),\n",
       "  ('CAR_a412e40701b1dd9465cc4bc2faf52a02d649db70', -0.03647001087665558),\n",
       "  ('MARCO_2084165', -0.03639787435531616),\n",
       "  ('MARCO_8360907', -0.03626180440187454),\n",
       "  ('MARCO_4156092', -0.03569580614566803),\n",
       "  ('MARCO_8053655', -0.03563348948955536),\n",
       "  ('MARCO_6472757', -0.035437777638435364),\n",
       "  ('MARCO_3154342', -0.0354141965508461),\n",
       "  ('MARCO_8628539', -0.03523474931716919),\n",
       "  ('MARCO_2906820', -0.03487040847539902),\n",
       "  ('MARCO_7225072', -0.034755975008010864),\n",
       "  ('CAR_18f37e3f233544e97b713a9b51af2c151757df96', -0.03449995815753937),\n",
       "  ('CAR_dac77fabd1c894bd95f2336b1de3a6094137f9e7', -0.03448449820280075),\n",
       "  ('MARCO_4049174', -0.03447891026735306),\n",
       "  ('MARCO_5289784', -0.03439194709062576),\n",
       "  ('MARCO_6920322', -0.03428759425878525),\n",
       "  ('MARCO_7137237', -0.03382480889558792),\n",
       "  ('MARCO_730114', -0.0337909460067749),\n",
       "  ('MARCO_1294280', -0.03370903432369232),\n",
       "  ('MARCO_6631774', -0.033632390201091766),\n",
       "  ('MARCO_2583487', -0.03361596167087555),\n",
       "  ('MARCO_2308119', -0.03355368226766586),\n",
       "  ('MARCO_4186108', -0.033201657235622406),\n",
       "  ('MARCO_2916591', -0.033074915409088135),\n",
       "  ('CAR_8ff1dc8d11884eebd234851e1a0766bed67e0624', -0.03302038088440895),\n",
       "  ('MARCO_6580948', -0.032709307968616486),\n",
       "  ('MARCO_8397819', -0.03267517685890198),\n",
       "  ('MARCO_2695643', -0.032593414187431335),\n",
       "  ('MARCO_2462476', -0.032535962760448456),\n",
       "  ('MARCO_1058736', -0.032528236508369446),\n",
       "  ('MARCO_6184312', -0.03248390555381775),\n",
       "  ('MARCO_6341701', -0.032269418239593506),\n",
       "  ('MARCO_7058938', -0.03206074982881546),\n",
       "  ('MARCO_2033694', -0.031977877020835876),\n",
       "  ('MARCO_1171205', -0.03183142840862274),\n",
       "  ('MARCO_4149967', -0.03165847808122635),\n",
       "  ('MARCO_3430743', -0.03097987174987793),\n",
       "  ('MARCO_2916589', -0.030905380845069885),\n",
       "  ('MARCO_7064997', -0.030767351388931274),\n",
       "  ('MARCO_2975462', -0.03067353367805481),\n",
       "  ('MARCO_6855900', -0.030561409890651703),\n",
       "  ('MARCO_4020153', -0.030323222279548645),\n",
       "  ('MARCO_4149974', -0.030123397707939148),\n",
       "  ('MARCO_2700411', -0.02968905121088028),\n",
       "  ('MARCO_492802', -0.029553167521953583),\n",
       "  ('MARCO_7116502', -0.029538333415985107),\n",
       "  ('MARCO_6276868', -0.029500141739845276),\n",
       "  ('MARCO_2916594', -0.029497414827346802),\n",
       "  ('MARCO_5507500', -0.02943260967731476),\n",
       "  ('MARCO_3368656', -0.02929195761680603),\n",
       "  ('MARCO_7070161', -0.02918243408203125),\n",
       "  ('MARCO_2916597', -0.029172316193580627),\n",
       "  ('MARCO_1826630', -0.029141172766685486),\n",
       "  ('MARCO_261843', -0.029105082154273987),\n",
       "  ('MARCO_1916595', -0.02894875407218933),\n",
       "  ('MARCO_7471769', -0.028772279620170593),\n",
       "  ('CAR_0d6c3a7717af58097ccbe57a4f943dda746290ba', -0.02851264178752899),\n",
       "  ('CAR_2dfe7045bf79ea1c881c0fce663113cb941e1b8d', -0.02785186469554901),\n",
       "  ('MARCO_6809543', -0.0278436541557312),\n",
       "  ('MARCO_424535', -0.027702651917934418),\n",
       "  ('MARCO_353889', -0.027692005038261414),\n",
       "  ('MARCO_8832289', -0.027659296989440918),\n",
       "  ('MARCO_8360905', -0.02746853232383728),\n",
       "  ('MARCO_5222526', -0.027186401188373566),\n",
       "  ('MARCO_1734125', -0.02714124321937561),\n",
       "  ('MARCO_4523997', -0.0268351212143898),\n",
       "  ('MARCO_7679243', -0.026822268962860107),\n",
       "  ('MARCO_4926582', -0.02640584111213684),\n",
       "  ('MARCO_6312687', -0.026386648416519165),\n",
       "  ('MARCO_4149966', -0.026321232318878174),\n",
       "  ('MARCO_4528316', -0.026225417852401733),\n",
       "  ('MARCO_8157272', -0.026102900505065918),\n",
       "  ('MARCO_7621230', -0.025719240307807922),\n",
       "  ('MARCO_3555376', -0.02560422569513321),\n",
       "  ('MARCO_830033', -0.02554546296596527),\n",
       "  ('MARCO_3368653', -0.025455862283706665),\n",
       "  ('MARCO_3754740', -0.025435276329517365),\n",
       "  ('MARCO_1381760', -0.025251217186450958),\n",
       "  ('MARCO_3916953', -0.024984590709209442),\n",
       "  ('MARCO_4549026', -0.024934180080890656),\n",
       "  ('MARCO_7562357', -0.024801865220069885),\n",
       "  ('CAR_92f38a3fd60d280b5092d8df212a7952e3c35fff', -0.024190865457057953),\n",
       "  ('MARCO_5879919', -0.02405717968940735),\n",
       "  ('MARCO_7188553', -0.023982040584087372),\n",
       "  ('MARCO_3430746', -0.023979805409908295),\n",
       "  ('MARCO_353884', -0.02379334717988968),\n",
       "  ('MARCO_1214175', -0.023601844906806946),\n",
       "  ('MARCO_6748842', -0.023483306169509888),\n",
       "  ('MARCO_3344757', -0.023387081921100616),\n",
       "  ('MARCO_8179199', -0.02332165837287903),\n",
       "  ('MARCO_4417192', -0.022965364158153534),\n",
       "  ('MARCO_1053451', -0.022610560059547424),\n",
       "  ('MARCO_6184313', -0.02254478633403778),\n",
       "  ('MARCO_4183866', -0.022428981959819794),\n",
       "  ('MARCO_6202140', -0.022197499871253967),\n",
       "  ('MARCO_5371065', -0.02214377373456955),\n",
       "  ('MARCO_5289783', -0.022037483751773834),\n",
       "  ('MARCO_5241417', -0.021959468722343445),\n",
       "  ('MARCO_5558071', -0.021942533552646637),\n",
       "  ('MARCO_1058729', -0.02174033224582672),\n",
       "  ('MARCO_8037083', -0.02159133553504944),\n",
       "  ('MARCO_227941', -0.02141350507736206),\n",
       "  ('MARCO_7958618', -0.021355807781219482),\n",
       "  ('MARCO_7363064', -0.021258391439914703),\n",
       "  ('MARCO_3400282', -0.020963340997695923),\n",
       "  ('MARCO_5371067', -0.020872414112091064),\n",
       "  ('MARCO_1608275', -0.020381569862365723),\n",
       "  ('MARCO_4858049', -0.020306803286075592),\n",
       "  ('MARCO_8397818', -0.019972071051597595),\n",
       "  ('MARCO_3061640', -0.01978302001953125),\n",
       "  ('MARCO_6661772', -0.019721761345863342),\n",
       "  ('MARCO_2496625', -0.019562795758247375),\n",
       "  ('MARCO_3873761', -0.019472047686576843),\n",
       "  ('MARCO_6922011', -0.019402891397476196),\n",
       "  ('MARCO_5558069', -0.019254498183727264),\n",
       "  ('MARCO_5366055', -0.019139796495437622),\n",
       "  ('MARCO_4244557', -0.01904238760471344),\n",
       "  ('MARCO_7182060', -0.019031964242458344),\n",
       "  ('MARCO_6559519', -0.01888519525527954),\n",
       "  ('MARCO_6661765', -0.01851765811443329),\n",
       "  ('MARCO_6559518', -0.018032535910606384),\n",
       "  ('MARCO_3533604', -0.01762808859348297),\n",
       "  ('MARCO_403158', -0.01737748086452484),\n",
       "  ('MARCO_5026050', -0.017340317368507385),\n",
       "  ('MARCO_1244915', -0.017148800194263458),\n",
       "  ('MARCO_7513923', -0.017122507095336914),\n",
       "  ('MARCO_4834516', -0.016936272382736206),\n",
       "  ('MARCO_2585717', -0.016780883073806763),\n",
       "  ('MARCO_4858051', -0.016503963619470596),\n",
       "  ('MARCO_2958745', -0.016499891877174377),\n",
       "  ('MARCO_353890', -0.016485363245010376),\n",
       "  ('MARCO_2890600', -0.015988707542419434),\n",
       "  ('MARCO_2643316', -0.01594105362892151),\n",
       "  ('MARCO_4607048', -0.015722133219242096),\n",
       "  ('MARCO_8422441', -0.01563432812690735),\n",
       "  ('CAR_fd096e610b37453cb360b8b45f90f876dac850d1', -0.015373289585113525),\n",
       "  ('MARCO_6172041', -0.015214748680591583),\n",
       "  ('MARCO_4926581', -0.014973260462284088),\n",
       "  ('MARCO_3368661', -0.01466473937034607),\n",
       "  ('MARCO_6787167', -0.014661215245723724),\n",
       "  ('MARCO_2233565', -0.01461087167263031),\n",
       "  ('MARCO_1916591', -0.014307573437690735),\n",
       "  ('MARCO_3296523', -0.014265298843383789),\n",
       "  ('MARCO_938132', -0.014228500425815582),\n",
       "  ('CAR_ff289fa20c9d45ffdb79d31487034aaf513e027b', -0.014153465628623962),\n",
       "  ('MARCO_2522439', -0.013860315084457397),\n",
       "  ('MARCO_7958620', -0.01346663385629654),\n",
       "  ('MARCO_706416', -0.013365820050239563),\n",
       "  ('MARCO_7471766', -0.013122394680976868),\n",
       "  ('MARCO_28054', -0.013098105788230896),\n",
       "  ('MARCO_1171208', -0.012727096676826477),\n",
       "  ('MARCO_6533442', -0.012355923652648926),\n",
       "  ('MARCO_5491063', -0.012192606925964355),\n",
       "  ('MARCO_1273970', -0.012182682752609253),\n",
       "  ('MARCO_6748836', -0.012114718556404114),\n",
       "  ('MARCO_558908', -0.011844038963317871),\n",
       "  ('MARCO_4703036', -0.011732950806617737),\n",
       "  ('MARCO_1058731', -0.01157638430595398),\n",
       "  ('MARCO_6866533', -0.011279910802841187),\n",
       "  ('MARCO_4607050', -0.01112009584903717),\n",
       "  ('MARCO_8747673', -0.010849833488464355),\n",
       "  ('MARCO_8008670', -0.010781601071357727),\n",
       "  ('CAR_e99cb504102f05629eb8216eba0e046e946ec726', -0.010769255459308624),\n",
       "  ('MARCO_7103363', -0.010768532752990723),\n",
       "  ('MARCO_571179', -0.01066635549068451),\n",
       "  ('MARCO_1855231', -0.010575413703918457),\n",
       "  ('MARCO_730119', -0.01020096242427826),\n",
       "  ('MARCO_271786', -0.01005484163761139),\n",
       "  ('MARCO_6661767', -0.009946495294570923),\n",
       "  ('MARCO_6254651', -0.009500116109848022),\n",
       "  ('MARCO_1536800', -0.00875093787908554),\n",
       "  ('MARCO_4519563', -0.008604250848293304),\n",
       "  ('MARCO_2700408', -0.008419975638389587),\n",
       "  ('MARCO_5242227', -0.008135318756103516),\n",
       "  ('MARCO_2967969', -0.007824324071407318),\n",
       "  ('MARCO_4982907', -0.007780253887176514),\n",
       "  ('MARCO_2138287', -0.007502168416976929),\n",
       "  ('CAR_6d9ed0c735dfc7b5e4c487b3582fa9e24adece7e', -0.007211998105049133),\n",
       "  ('MARCO_1658779', -0.006866686046123505),\n",
       "  ('MARCO_2771358', -0.006840139627456665),\n",
       "  ('MARCO_6312702', -0.006832905113697052),\n",
       "  ('MARCO_2885587', -0.006791509687900543),\n",
       "  ('MARCO_5330009', -0.006737604737281799),\n",
       "  ('MARCO_6661768', -0.006433457136154175),\n",
       "  ('MARCO_353893', -0.005783930420875549),\n",
       "  ('MARCO_938133', -0.005774609744548798),\n",
       "  ('MARCO_245986', -0.005422651767730713),\n",
       "  ('MARCO_5654548', -0.005349904298782349),\n",
       "  ('MARCO_5211105', -0.004652254283428192),\n",
       "  ('MARCO_8666788', -0.003997281193733215),\n",
       "  ('MARCO_7543217', -0.003955468535423279),\n",
       "  ('MARCO_5032914', -0.0035369396209716797),\n",
       "  ('CAR_29ec552061ee4433f109d3087384e25a27357742', -0.003305472433567047),\n",
       "  ('MARCO_5179950', -0.002798229455947876),\n",
       "  ('MARCO_3484877', -0.002184458076953888),\n",
       "  ('MARCO_2257657', -0.002174168825149536),\n",
       "  ('MARCO_6866529', -0.002104252576828003),\n",
       "  ('MARCO_72354', -0.0013579651713371277),\n",
       "  ('MARCO_23171', -0.00043500959873199463),\n",
       "  ('MARCO_1608274', -0.000374816358089447),\n",
       "  ('MARCO_5743580', -0.0002780035138130188),\n",
       "  ('MARCO_217418', 0.0004490315914154053),\n",
       "  ('MARCO_1195780', 0.0005285367369651794),\n",
       "  ('MARCO_3316394', 0.001847483217716217),\n",
       "  ('MARCO_7106148', 0.00202980637550354),\n",
       "  ('MARCO_3210994', 0.002226985991001129),\n",
       "  ('MARCO_4607049', 0.0053603798151016235),\n",
       "  ('MARCO_6627910', 0.0060008615255355835),\n",
       "  ('MARCO_4330495', 0.006378650665283203),\n",
       "  ('MARCO_8200388', 0.006987586617469788),\n",
       "  ('MARCO_580158', 0.006990119814872742),\n",
       "  ('CAR_69b0aa552825e621aad083f97e741410baee1899', 0.0073435381054878235),\n",
       "  ('MARCO_2539075', 0.008249521255493164),\n",
       "  ('CAR_21b4b199faff44d82fd36e5f0ac458659e90088c', 0.008329570293426514),\n",
       "  ('CAR_96cfd2f159f3c0ed504cc50778100d3c28321848', 0.009071126580238342),\n",
       "  ('MARCO_6641761', 0.009240776300430298),\n",
       "  ('MARCO_6661771', 0.010140061378479004),\n",
       "  ('MARCO_217422', 0.011125147342681885),\n",
       "  ('MARCO_6303473', 0.011270254850387573),\n",
       "  ('MARCO_4149970', 0.011300697922706604),\n",
       "  ('MARCO_3341265', 0.011809736490249634),\n",
       "  ('MARCO_8366288', 0.012517333030700684),\n",
       "  ('MARCO_2257654', 0.013457626104354858),\n",
       "  ('MARCO_6965468', 0.01617048680782318),\n",
       "  ('MARCO_5222523', 0.016405954957008362),\n",
       "  ('MARCO_6914827', 0.020584046840667725),\n",
       "  ('MARCO_3368652', 0.022692903876304626),\n",
       "  ('MARCO_1868374', 0.02423807978630066),\n",
       "  ('MARCO_5510270', 0.031094282865524292),\n",
       "  ('MARCO_7760585', 0.03213389217853546),\n",
       "  ('MARCO_1826634', 0.033427685499191284),\n",
       "  ('MARCO_5921929', 0.03364016115665436),\n",
       "  ('MARCO_2700410', 0.04004128277301788),\n",
       "  ('MARCO_1317525', 0.0502215176820755),\n",
       "  ('MARCO_6575537', 0.050236865878105164)],\n",
       " 'map': 0.09373439729758559,\n",
       " 'recip_rank': 0.05263157894736842,\n",
       " 'ndcg_cut_3': 0.0,\n",
       " 'set_recall': 0.7580645161290323,\n",
       " 'reranked_results': [('MARCO_7796731', 0.40620577335357666),\n",
       "  ('MARCO_3061647', 0.376916766166687),\n",
       "  ('MARCO_8747676', 0.3404342234134674),\n",
       "  ('MARCO_2771362', 0.3383066654205322),\n",
       "  ('MARCO_353892', 0.3357889950275421),\n",
       "  ('CAR_aa5c2a61aefc3679ad81ad8673abbc4da5723eb1', 0.33421850204467773),\n",
       "  ('MARCO_7150693', 0.326328843832016),\n",
       "  ('MARCO_7653912', 0.32380765676498413),\n",
       "  ('MARCO_2437377', 0.31336838006973267),\n",
       "  ('MARCO_3368657', 0.3114825487136841),\n",
       "  ('MARCO_3962523', 0.3111346364021301),\n",
       "  ('MARCO_4888192', 0.3096495270729065),\n",
       "  ('MARCO_8801845', 0.30848824977874756),\n",
       "  ('MARCO_4196556', 0.3069588541984558),\n",
       "  ('MARCO_217420', 0.30263614654541016),\n",
       "  ('MARCO_6243037', 0.2991548180580139),\n",
       "  ('MARCO_3818696', 0.2985265851020813),\n",
       "  ('CAR_2345165208413ae4d82c1a5f4145564a1216b267', 0.29432520270347595),\n",
       "  ('MARCO_1868370', 0.2921411097049713),\n",
       "  ('MARCO_97872', 0.2910309433937073),\n",
       "  ('MARCO_3061641', 0.286838173866272),\n",
       "  ('MARCO_3403545', 0.28480425477027893),\n",
       "  ('CAR_ddc63cc2ada780683dba8934e96991764268c482', 0.2830232083797455),\n",
       "  ('MARCO_2019127', 0.2829996645450592),\n",
       "  ('MARCO_5883839', 0.28245049715042114),\n",
       "  ('MARCO_1278953', 0.2805783450603485),\n",
       "  ('MARCO_7679244', 0.2794209122657776),\n",
       "  ('MARCO_4215954', 0.2762289047241211),\n",
       "  ('MARCO_8211636', 0.26857441663742065),\n",
       "  ('MARCO_3400285', 0.2674144506454468),\n",
       "  ('MARCO_3678356', 0.26680150628089905),\n",
       "  ('MARCO_2337295', 0.2653082013130188),\n",
       "  ('MARCO_8567129', 0.25481265783309937),\n",
       "  ('MARCO_5222288', 0.2469460666179657),\n",
       "  ('CAR_be26d2e44cbc807a3477aeba36d49931df11be1e', 0.24432364106178284),\n",
       "  ('MARCO_8804941', 0.23873086273670197),\n",
       "  ('MARCO_1621872', 0.23395130038261414),\n",
       "  ('MARCO_4882255', 0.23376896977424622),\n",
       "  ('MARCO_135784', 0.22586122155189514),\n",
       "  ('MARCO_1037979', 0.21693605184555054),\n",
       "  ('CAR_da577b4897cc5c1e1854ffd3f020699d801de745', 0.21459953486919403),\n",
       "  ('MARCO_3685141', 0.21413807570934296),\n",
       "  ('MARCO_5289777', 0.20432667434215546),\n",
       "  ('MARCO_1198831', 0.20330435037612915),\n",
       "  ('MARCO_2416874', 0.19573789834976196),\n",
       "  ('MARCO_6478901', 0.1931971311569214),\n",
       "  ('MARCO_3417415', 0.18848347663879395),\n",
       "  ('MARCO_1734120', 0.18240970373153687),\n",
       "  ('CAR_c1ac2e36df99e79291d18ba5193bb378238ece6c', 0.1808847188949585),\n",
       "  ('MARCO_2377194', 0.17859190702438354),\n",
       "  ('MARCO_1251563', 0.1769723892211914),\n",
       "  ('MARCO_5483954', 0.16808323562145233),\n",
       "  ('MARCO_2590787', 0.16639912128448486),\n",
       "  ('CAR_563db7ec73378a21d17f67172678640d89420070', 0.1564759910106659),\n",
       "  ('MARCO_6974024', 0.15449747443199158),\n",
       "  ('MARCO_407855', 0.151314377784729),\n",
       "  ('MARCO_5222283', 0.15102969110012054),\n",
       "  ('MARCO_1037976', 0.14712318778038025),\n",
       "  ('MARCO_3811532', 0.14496202766895294),\n",
       "  ('MARCO_4020155', 0.14373049139976501),\n",
       "  ('CAR_041ec49de60bad7c42e953c53bb8516eee6e7e84', 0.14349153637886047),\n",
       "  ('MARCO_3400281', 0.14321230351924896),\n",
       "  ('CAR_6fd0c21b5771545db27842d1cbb35961bc78d548', 0.14193573594093323),\n",
       "  ('MARCO_558907', 0.13783004879951477),\n",
       "  ('MARCO_7796732', 0.12872636318206787),\n",
       "  ('MARCO_5043573', 0.12773719429969788),\n",
       "  ('MARCO_5703220', 0.1273094117641449),\n",
       "  ('MARCO_2585716', 0.121678426861763),\n",
       "  ('MARCO_7796734', 0.12028755992650986),\n",
       "  ('MARCO_7679247', 0.11530318111181259),\n",
       "  ('MARCO_1826636', 0.11336006969213486),\n",
       "  ('MARCO_3403546', 0.11110945791006088),\n",
       "  ('MARCO_2257661', 0.11099973320960999),\n",
       "  ('MARCO_171675', 0.10752978175878525),\n",
       "  ('MARCO_4020152', 0.103643998503685),\n",
       "  ('MARCO_1976711', 0.09946028888225555),\n",
       "  ('MARCO_1978626', 0.09803487360477448),\n",
       "  ('MARCO_4627140', 0.09426569938659668),\n",
       "  ('MARCO_3909436', 0.09388165920972824),\n",
       "  ('MARCO_6973312', 0.09340950846672058),\n",
       "  ('MARCO_6852557', 0.09338943660259247),\n",
       "  ('CAR_826d785b9bde75ea3f8f519e3c96514fe6b7bc96', 0.09231286495923996),\n",
       "  ('MARCO_1941329', 0.0913235992193222),\n",
       "  ('CAR_02a460927d09c91fa3d4f3ea8a29e8ffa5219c5c', 0.08852747082710266),\n",
       "  ('CAR_2373ac4b54980061dd412b3d2738c28387dbc769', 0.08796162903308868),\n",
       "  ('MARCO_3565865', 0.0869525820016861),\n",
       "  ('CAR_beaa19b9206e1bf4ec09931cee92f4eab58c1597', 0.0861138105392456),\n",
       "  ('MARCO_8317504', 0.08533311635255814),\n",
       "  ('MARCO_3143910', 0.08374010026454926),\n",
       "  ('CAR_7b05e5fc480de635475f0475110ca2a1b2ecde50', 0.08118720352649689),\n",
       "  ('MARCO_6748841', 0.07869147509336472),\n",
       "  ('MARCO_7556533', 0.0785345509648323),\n",
       "  ('MARCO_7541281', 0.07766593992710114),\n",
       "  ('MARCO_6661770', 0.07727839052677155),\n",
       "  ('MARCO_493988', 0.07673414051532745),\n",
       "  ('MARCO_1244914', 0.07556181401014328),\n",
       "  ('MARCO_8422445', 0.07450161874294281),\n",
       "  ('MARCO_1244907', 0.07397547364234924),\n",
       "  ('MARCO_2377407', 0.07241035997867584),\n",
       "  ('MARCO_3970689', 0.07240894436836243),\n",
       "  ('MARCO_6235797', 0.0710233598947525),\n",
       "  ('MARCO_2796572', 0.07097116112709045),\n",
       "  ('MARCO_656173', 0.07066785544157028),\n",
       "  ('MARCO_580162', 0.07012869417667389),\n",
       "  ('MARCO_8791607', 0.06835224479436874),\n",
       "  ('MARCO_5241416', 0.067720927298069),\n",
       "  ('MARCO_1855020', 0.06662296503782272),\n",
       "  ('MARCO_6914828', 0.06656848639249802),\n",
       "  ('MARCO_4677844', 0.06629373133182526),\n",
       "  ('MARCO_7814093', 0.06530901789665222),\n",
       "  ('MARCO_5703222', 0.06499502062797546),\n",
       "  ('MARCO_765808', 0.06492854654788971),\n",
       "  ('MARCO_4675037', 0.06451111286878586),\n",
       "  ('MARCO_4244556', 0.06436972320079803),\n",
       "  ('MARCO_8422444', 0.06397522985935211),\n",
       "  ('MARCO_6624627', 0.063791424036026),\n",
       "  ('MARCO_7958619', 0.06357426196336746),\n",
       "  ('MARCO_6608643', 0.06291940808296204),\n",
       "  ('MARCO_7966318', 0.06282675266265869),\n",
       "  ('MARCO_3425311', 0.06274241209030151),\n",
       "  ('MARCO_7626948', 0.06241161376237869),\n",
       "  ('MARCO_4998693', 0.06232786178588867),\n",
       "  ('MARCO_7824045', 0.06168990582227707),\n",
       "  ('MARCO_962771', 0.06168385595083237),\n",
       "  ('MARCO_1514920', 0.0614943653345108),\n",
       "  ('MARCO_5540414', 0.061183348298072815),\n",
       "  ('CAR_f3a33904b0049b80e0bf94b19ab6fb34693f95c6', 0.06111568212509155),\n",
       "  ('MARCO_492805', 0.061083875596523285),\n",
       "  ('MARCO_407860', 0.060522712767124176),\n",
       "  ('MARCO_227179', 0.060431912541389465),\n",
       "  ('CAR_0620fda4a62096b0f568e662fbc16f73cb4f0fbf', 0.059959135949611664),\n",
       "  ('MARCO_3143140', 0.05970682203769684),\n",
       "  ('MARCO_654272', 0.058593399822711945),\n",
       "  ('MARCO_5896774', 0.058028094470500946),\n",
       "  ('MARCO_580156', 0.05788569152355194),\n",
       "  ('MARCO_825811', 0.05741308629512787),\n",
       "  ('MARCO_2257662', 0.05707171559333801),\n",
       "  ('MARCO_7536007', 0.05674968659877777),\n",
       "  ('MARCO_7001837', 0.05663607269525528),\n",
       "  ('MARCO_3379756', 0.05658358335494995),\n",
       "  ('MARCO_140073', 0.05627540498971939),\n",
       "  ('MARCO_7811014', 0.05593400448560715),\n",
       "  ('MARCO_5043576', 0.05576212704181671),\n",
       "  ('MARCO_7150698', 0.05576083064079285),\n",
       "  ('MARCO_1741184', 0.05463649332523346),\n",
       "  ('MARCO_1681894', 0.054620690643787384),\n",
       "  ('MARCO_8334625', 0.05447841435670853),\n",
       "  ('MARCO_4396328', 0.05428692698478699),\n",
       "  ('MARCO_4881454', 0.05415376275777817),\n",
       "  ('MARCO_129475', 0.05367017537355423),\n",
       "  ('MARCO_977359', 0.053668275475502014),\n",
       "  ('MARCO_830026', 0.05366311967372894),\n",
       "  ('MARCO_353891', 0.0536496639251709),\n",
       "  ('MARCO_830027', 0.053047455847263336),\n",
       "  ('CAR_dedad08c40164cee79464fdeb8da5e3e46b402ea', 0.0528101772069931),\n",
       "  ('MARCO_589747', 0.05280429124832153),\n",
       "  ('MARCO_4243822', 0.05269871652126312),\n",
       "  ('MARCO_102050', 0.05261418968439102),\n",
       "  ('MARCO_6618125', 0.05192698538303375),\n",
       "  ('MARCO_940332', 0.05182307958602905),\n",
       "  ('MARCO_6048118', 0.05162035673856735),\n",
       "  ('MARCO_1736079', 0.051520854234695435),\n",
       "  ('CAR_bb03d4c17092b6f9fcf66aae6e8eb33a158b2eb0', 0.05151118338108063),\n",
       "  ('MARCO_493981', 0.05131770670413971),\n",
       "  ('MARCO_1769388', 0.0510641485452652),\n",
       "  ('MARCO_580159', 0.05096600204706192),\n",
       "  ('MARCO_2873522', 0.05092594772577286),\n",
       "  ('MARCO_1868373', 0.050645679235458374),\n",
       "  ('MARCO_6785834', 0.05061739683151245),\n",
       "  ('MARCO_7694051', 0.0505402535200119),\n",
       "  ('CAR_e3f6a71641b264d86f4d90d494c7d71204a941dc', 0.050436101853847504),\n",
       "  ('MARCO_8772511', 0.05017904192209244),\n",
       "  ('MARCO_1475376', 0.04927036166191101),\n",
       "  ('MARCO_3962526', 0.0491933673620224),\n",
       "  ('MARCO_2524398', 0.049191877245903015),\n",
       "  ('MARCO_7966319', 0.049165576696395874),\n",
       "  ('MARCO_4365692', 0.048740074038505554),\n",
       "  ('MARCO_4925208', 0.048724688589572906),\n",
       "  ('MARCO_7513928', 0.04855047166347504),\n",
       "  ('CAR_1ee4535ac037409a6dee25cc293b43f2386ac954', 0.04777871444821358),\n",
       "  ('MARCO_4263415', 0.04762019217014313),\n",
       "  ('MARCO_1604973', 0.047429993748664856),\n",
       "  ('CAR_9217a8308fb48b02e36606808d5b5a1541fe3c66', 0.047314584255218506),\n",
       "  ('MARCO_531524', 0.04712036997079849),\n",
       "  ('MARCO_6811694', 0.04711248725652695),\n",
       "  ('CAR_10d3185b987e4a3247ddf302d1a77af0d8089057', 0.04682272672653198),\n",
       "  ('MARCO_8422443', 0.046577103435993195),\n",
       "  ('MARCO_7797156', 0.04656708985567093),\n",
       "  ('MARCO_1278952', 0.046392619609832764),\n",
       "  ('MARCO_3368658', 0.046350523829460144),\n",
       "  ('MARCO_353888', 0.046173855662345886),\n",
       "  ('MARCO_4641439', 0.04615825414657593),\n",
       "  ('MARCO_8025746', 0.0460820347070694),\n",
       "  ('MARCO_1868371', 0.046055786311626434),\n",
       "  ('MARCO_8162046', 0.04602561146020889),\n",
       "  ('MARCO_5040135', 0.04597315937280655),\n",
       "  ('MARCO_6109393', 0.04584190249443054),\n",
       "  ('MARCO_8163476', 0.045725367963314056),\n",
       "  ('MARCO_5641308', 0.045144110918045044),\n",
       "  ('MARCO_353887', 0.04504463076591492),\n",
       "  ('CAR_75df9a77d12622d6ec98fe76435da01dfb652d5e', 0.044829435646533966),\n",
       "  ('MARCO_654271', 0.04425700753927231),\n",
       "  ('MARCO_735329', 0.04423574358224869),\n",
       "  ('MARCO_377997', 0.0440114364027977),\n",
       "  ('MARCO_7646892', 0.04386594891548157),\n",
       "  ('MARCO_8334626', 0.04386376589536667),\n",
       "  ('MARCO_797500', 0.04380036145448685),\n",
       "  ('MARCO_3056456', 0.04374511539936066),\n",
       "  ('MARCO_3818695', 0.043700143694877625),\n",
       "  ('MARCO_305235', 0.04324604570865631),\n",
       "  ('MARCO_7606759', 0.04308287799358368),\n",
       "  ('MARCO_8397814', 0.04263579100370407),\n",
       "  ('MARCO_217415', 0.04257754981517792),\n",
       "  ('MARCO_2141694', 0.042516253888607025),\n",
       "  ('MARCO_2573511', 0.04235658049583435),\n",
       "  ('MARCO_1976714', 0.04226060211658478),\n",
       "  ('MARCO_73784', 0.042230382561683655),\n",
       "  ('MARCO_7242148', 0.042067766189575195),\n",
       "  ('MARCO_8299655', 0.0419364869594574),\n",
       "  ('MARCO_6826590', 0.0415269136428833),\n",
       "  ('MARCO_925772', 0.041309475898742676),\n",
       "  ('MARCO_7958622', 0.04120267927646637),\n",
       "  ('MARCO_4367351', 0.04114263504743576),\n",
       "  ('MARCO_4238136', 0.04100121557712555),\n",
       "  ('MARCO_735334', 0.04096604138612747),\n",
       "  ('MARCO_6826593', 0.04091736674308777),\n",
       "  ('MARCO_2630154', 0.040821418166160583),\n",
       "  ('MARCO_3985694', 0.040812231600284576),\n",
       "  ('MARCO_2491347', 0.04079337418079376),\n",
       "  ('MARCO_8025747', 0.04046855866909027),\n",
       "  ('MARCO_1423443', 0.04043082892894745),\n",
       "  ('CAR_f061e731dd7727ce45ab9332dab72a672463b03b', 0.04000601917505264),\n",
       "  ('CAR_3f9696422624d6e10c022b8d62c6827d284038c6', 0.0399644672870636),\n",
       "  ('MARCO_6322532', 0.039950162172317505),\n",
       "  ('CAR_fcc94d4f8056003ec0b2490000dc6b3272302d83', 0.03994809091091156),\n",
       "  ('MARCO_4856548', 0.03994006663560867),\n",
       "  ('MARCO_5861900', 0.039933472871780396),\n",
       "  ('MARCO_1433066', 0.0398830771446228),\n",
       "  ('MARCO_4227676', 0.03973694145679474),\n",
       "  ('MARCO_1153271', 0.03971049189567566),\n",
       "  ('CAR_34af28ae6a8ecfeadb12fe31954cacbf3e237437', 0.03966712951660156),\n",
       "  ('MARCO_8486480', 0.03965136408805847),\n",
       "  ('CAR_8496d6efabfe289446c9215973e11020c8d19a5e', 0.039608366787433624),\n",
       "  ('CAR_21ddff105fbbf8b638f367cf1eb980a7f610d384', 0.03949602693319321),\n",
       "  ('MARCO_1035406', 0.039260782301425934),\n",
       "  ('MARCO_4858046', 0.03911682963371277),\n",
       "  ('MARCO_5858872', 0.039043813943862915),\n",
       "  ('MARCO_7621229', 0.03865721821784973),\n",
       "  ('MARCO_2771361', 0.03864899277687073),\n",
       "  ('MARCO_8775216', 0.03846712410449982),\n",
       "  ('MARCO_5641305', 0.03844917565584183),\n",
       "  ('MARCO_4612534', 0.03839697688817978),\n",
       "  ('MARCO_7471772', 0.038204118609428406),\n",
       "  ('MARCO_5510268', 0.03773385286331177),\n",
       "  ('MARCO_2462478', 0.03758467733860016),\n",
       "  ('MARCO_6482702', 0.03754027187824249),\n",
       "  ('MARCO_5242226', 0.03749026358127594),\n",
       "  ('MARCO_6051424', 0.03742114454507828),\n",
       "  ('MARCO_4926579', 0.037252262234687805),\n",
       "  ('MARCO_7560124', 0.03713387995958328),\n",
       "  ('MARCO_510725', 0.037030600011348724),\n",
       "  ('MARCO_2141693', 0.036839619278907776),\n",
       "  ('MARCO_6405364', 0.03671377897262573),\n",
       "  ('MARCO_1182756', 0.0367128849029541),\n",
       "  ('MARCO_4627143', 0.03661881387233734),\n",
       "  ('MARCO_4675032', 0.03657030314207077),\n",
       "  ('CAR_a412e40701b1dd9465cc4bc2faf52a02d649db70', 0.03647001087665558),\n",
       "  ('MARCO_2084165', 0.03639787435531616),\n",
       "  ('MARCO_8360907', 0.03626180440187454),\n",
       "  ('MARCO_4156092', 0.03569580614566803),\n",
       "  ('MARCO_8053655', 0.03563348948955536),\n",
       "  ('MARCO_6472757', 0.035437777638435364),\n",
       "  ('MARCO_3154342', 0.0354141965508461),\n",
       "  ('MARCO_8628539', 0.03523474931716919),\n",
       "  ('MARCO_2906820', 0.03487040847539902),\n",
       "  ('MARCO_7225072', 0.034755975008010864),\n",
       "  ('CAR_18f37e3f233544e97b713a9b51af2c151757df96', 0.03449995815753937),\n",
       "  ('CAR_dac77fabd1c894bd95f2336b1de3a6094137f9e7', 0.03448449820280075),\n",
       "  ('MARCO_4049174', 0.03447891026735306),\n",
       "  ('MARCO_5289784', 0.03439194709062576),\n",
       "  ('MARCO_6920322', 0.03428759425878525),\n",
       "  ('MARCO_7137237', 0.03382480889558792),\n",
       "  ('MARCO_730114', 0.0337909460067749),\n",
       "  ('MARCO_1294280', 0.03370903432369232),\n",
       "  ('MARCO_6631774', 0.033632390201091766),\n",
       "  ('MARCO_2583487', 0.03361596167087555),\n",
       "  ('MARCO_2308119', 0.03355368226766586),\n",
       "  ('MARCO_4186108', 0.033201657235622406),\n",
       "  ('MARCO_2916591', 0.033074915409088135),\n",
       "  ('CAR_8ff1dc8d11884eebd234851e1a0766bed67e0624', 0.03302038088440895),\n",
       "  ('MARCO_6580948', 0.032709307968616486),\n",
       "  ('MARCO_8397819', 0.03267517685890198),\n",
       "  ('MARCO_2695643', 0.032593414187431335),\n",
       "  ('MARCO_2462476', 0.032535962760448456),\n",
       "  ('MARCO_1058736', 0.032528236508369446),\n",
       "  ('MARCO_6184312', 0.03248390555381775),\n",
       "  ('MARCO_6341701', 0.032269418239593506),\n",
       "  ('MARCO_7058938', 0.03206074982881546),\n",
       "  ('MARCO_2033694', 0.031977877020835876),\n",
       "  ('MARCO_1171205', 0.03183142840862274),\n",
       "  ('MARCO_4149967', 0.03165847808122635),\n",
       "  ('MARCO_3430743', 0.03097987174987793),\n",
       "  ('MARCO_2916589', 0.030905380845069885),\n",
       "  ('MARCO_7064997', 0.030767351388931274),\n",
       "  ('MARCO_2975462', 0.03067353367805481),\n",
       "  ('MARCO_6855900', 0.030561409890651703),\n",
       "  ('MARCO_4020153', 0.030323222279548645),\n",
       "  ('MARCO_4149974', 0.030123397707939148),\n",
       "  ('MARCO_2700411', 0.02968905121088028),\n",
       "  ('MARCO_492802', 0.029553167521953583),\n",
       "  ('MARCO_7116502', 0.029538333415985107),\n",
       "  ('MARCO_6276868', 0.029500141739845276),\n",
       "  ('MARCO_2916594', 0.029497414827346802),\n",
       "  ('MARCO_5507500', 0.02943260967731476),\n",
       "  ('MARCO_3368656', 0.02929195761680603),\n",
       "  ('MARCO_7070161', 0.02918243408203125),\n",
       "  ('MARCO_2916597', 0.029172316193580627),\n",
       "  ('MARCO_1826630', 0.029141172766685486),\n",
       "  ('MARCO_261843', 0.029105082154273987),\n",
       "  ('MARCO_1916595', 0.02894875407218933),\n",
       "  ('MARCO_7471769', 0.028772279620170593),\n",
       "  ('CAR_0d6c3a7717af58097ccbe57a4f943dda746290ba', 0.02851264178752899),\n",
       "  ('CAR_2dfe7045bf79ea1c881c0fce663113cb941e1b8d', 0.02785186469554901),\n",
       "  ('MARCO_6809543', 0.0278436541557312),\n",
       "  ('MARCO_424535', 0.027702651917934418),\n",
       "  ('MARCO_353889', 0.027692005038261414),\n",
       "  ('MARCO_8832289', 0.027659296989440918),\n",
       "  ('MARCO_8360905', 0.02746853232383728),\n",
       "  ('MARCO_5222526', 0.027186401188373566),\n",
       "  ('MARCO_1734125', 0.02714124321937561),\n",
       "  ('MARCO_4523997', 0.0268351212143898),\n",
       "  ('MARCO_7679243', 0.026822268962860107),\n",
       "  ('MARCO_4926582', 0.02640584111213684),\n",
       "  ('MARCO_6312687', 0.026386648416519165),\n",
       "  ('MARCO_4149966', 0.026321232318878174),\n",
       "  ('MARCO_4528316', 0.026225417852401733),\n",
       "  ('MARCO_8157272', 0.026102900505065918),\n",
       "  ('MARCO_7621230', 0.025719240307807922),\n",
       "  ('MARCO_3555376', 0.02560422569513321),\n",
       "  ('MARCO_830033', 0.02554546296596527),\n",
       "  ('MARCO_3368653', 0.025455862283706665),\n",
       "  ('MARCO_3754740', 0.025435276329517365),\n",
       "  ('MARCO_1381760', 0.025251217186450958),\n",
       "  ('MARCO_3916953', 0.024984590709209442),\n",
       "  ('MARCO_4549026', 0.024934180080890656),\n",
       "  ('MARCO_7562357', 0.024801865220069885),\n",
       "  ('CAR_92f38a3fd60d280b5092d8df212a7952e3c35fff', 0.024190865457057953),\n",
       "  ('MARCO_5879919', 0.02405717968940735),\n",
       "  ('MARCO_7188553', 0.023982040584087372),\n",
       "  ('MARCO_3430746', 0.023979805409908295),\n",
       "  ('MARCO_353884', 0.02379334717988968),\n",
       "  ('MARCO_1214175', 0.023601844906806946),\n",
       "  ('MARCO_6748842', 0.023483306169509888),\n",
       "  ('MARCO_3344757', 0.023387081921100616),\n",
       "  ('MARCO_8179199', 0.02332165837287903),\n",
       "  ('MARCO_4417192', 0.022965364158153534),\n",
       "  ('MARCO_1053451', 0.022610560059547424),\n",
       "  ('MARCO_6184313', 0.02254478633403778),\n",
       "  ('MARCO_4183866', 0.022428981959819794),\n",
       "  ('MARCO_6202140', 0.022197499871253967),\n",
       "  ('MARCO_5371065', 0.02214377373456955),\n",
       "  ('MARCO_5289783', 0.022037483751773834),\n",
       "  ('MARCO_5241417', 0.021959468722343445),\n",
       "  ('MARCO_5558071', 0.021942533552646637),\n",
       "  ('MARCO_1058729', 0.02174033224582672),\n",
       "  ('MARCO_8037083', 0.02159133553504944),\n",
       "  ('MARCO_227941', 0.02141350507736206),\n",
       "  ('MARCO_7958618', 0.021355807781219482),\n",
       "  ('MARCO_7363064', 0.021258391439914703),\n",
       "  ('MARCO_3400282', 0.020963340997695923),\n",
       "  ('MARCO_5371067', 0.020872414112091064),\n",
       "  ('MARCO_1608275', 0.020381569862365723),\n",
       "  ('MARCO_4858049', 0.020306803286075592),\n",
       "  ('MARCO_8397818', 0.019972071051597595),\n",
       "  ('MARCO_3061640', 0.01978302001953125),\n",
       "  ('MARCO_6661772', 0.019721761345863342),\n",
       "  ('MARCO_2496625', 0.019562795758247375),\n",
       "  ('MARCO_3873761', 0.019472047686576843),\n",
       "  ('MARCO_6922011', 0.019402891397476196),\n",
       "  ('MARCO_5558069', 0.019254498183727264),\n",
       "  ('MARCO_5366055', 0.019139796495437622),\n",
       "  ('MARCO_4244557', 0.01904238760471344),\n",
       "  ('MARCO_7182060', 0.019031964242458344),\n",
       "  ('MARCO_6559519', 0.01888519525527954),\n",
       "  ('MARCO_6661765', 0.01851765811443329),\n",
       "  ('MARCO_6559518', 0.018032535910606384),\n",
       "  ('MARCO_3533604', 0.01762808859348297),\n",
       "  ('MARCO_403158', 0.01737748086452484),\n",
       "  ('MARCO_5026050', 0.017340317368507385),\n",
       "  ('MARCO_1244915', 0.017148800194263458),\n",
       "  ('MARCO_7513923', 0.017122507095336914),\n",
       "  ('MARCO_4834516', 0.016936272382736206),\n",
       "  ('MARCO_2585717', 0.016780883073806763),\n",
       "  ('MARCO_4858051', 0.016503963619470596),\n",
       "  ('MARCO_2958745', 0.016499891877174377),\n",
       "  ('MARCO_353890', 0.016485363245010376),\n",
       "  ('MARCO_2890600', 0.015988707542419434),\n",
       "  ('MARCO_2643316', 0.01594105362892151),\n",
       "  ('MARCO_4607048', 0.015722133219242096),\n",
       "  ('MARCO_8422441', 0.01563432812690735),\n",
       "  ('CAR_fd096e610b37453cb360b8b45f90f876dac850d1', 0.015373289585113525),\n",
       "  ('MARCO_6172041', 0.015214748680591583),\n",
       "  ('MARCO_4926581', 0.014973260462284088),\n",
       "  ('MARCO_3368661', 0.01466473937034607),\n",
       "  ('MARCO_6787167', 0.014661215245723724),\n",
       "  ('MARCO_2233565', 0.01461087167263031),\n",
       "  ('MARCO_1916591', 0.014307573437690735),\n",
       "  ('MARCO_3296523', 0.014265298843383789),\n",
       "  ('MARCO_938132', 0.014228500425815582),\n",
       "  ('CAR_ff289fa20c9d45ffdb79d31487034aaf513e027b', 0.014153465628623962),\n",
       "  ('MARCO_2522439', 0.013860315084457397),\n",
       "  ('MARCO_7958620', 0.01346663385629654),\n",
       "  ('MARCO_706416', 0.013365820050239563),\n",
       "  ('MARCO_7471766', 0.013122394680976868),\n",
       "  ('MARCO_28054', 0.013098105788230896),\n",
       "  ('MARCO_1171208', 0.012727096676826477),\n",
       "  ('MARCO_6533442', 0.012355923652648926),\n",
       "  ('MARCO_5491063', 0.012192606925964355),\n",
       "  ('MARCO_1273970', 0.012182682752609253),\n",
       "  ('MARCO_6748836', 0.012114718556404114),\n",
       "  ('MARCO_558908', 0.011844038963317871),\n",
       "  ('MARCO_4703036', 0.011732950806617737),\n",
       "  ('MARCO_1058731', 0.01157638430595398),\n",
       "  ('MARCO_6866533', 0.011279910802841187),\n",
       "  ('MARCO_4607050', 0.01112009584903717),\n",
       "  ('MARCO_8747673', 0.010849833488464355),\n",
       "  ('MARCO_8008670', 0.010781601071357727),\n",
       "  ('CAR_e99cb504102f05629eb8216eba0e046e946ec726', 0.010769255459308624),\n",
       "  ('MARCO_7103363', 0.010768532752990723),\n",
       "  ('MARCO_571179', 0.01066635549068451),\n",
       "  ('MARCO_1855231', 0.010575413703918457),\n",
       "  ('MARCO_730119', 0.01020096242427826),\n",
       "  ('MARCO_271786', 0.01005484163761139),\n",
       "  ('MARCO_6661767', 0.009946495294570923),\n",
       "  ('MARCO_6254651', 0.009500116109848022),\n",
       "  ('MARCO_1536800', 0.00875093787908554),\n",
       "  ('MARCO_4519563', 0.008604250848293304),\n",
       "  ('MARCO_2700408', 0.008419975638389587),\n",
       "  ('MARCO_5242227', 0.008135318756103516),\n",
       "  ('MARCO_2967969', 0.007824324071407318),\n",
       "  ('MARCO_4982907', 0.007780253887176514),\n",
       "  ('MARCO_2138287', 0.007502168416976929),\n",
       "  ('CAR_6d9ed0c735dfc7b5e4c487b3582fa9e24adece7e', 0.007211998105049133),\n",
       "  ('MARCO_1658779', 0.006866686046123505),\n",
       "  ('MARCO_2771358', 0.006840139627456665),\n",
       "  ('MARCO_6312702', 0.006832905113697052),\n",
       "  ('MARCO_2885587', 0.006791509687900543),\n",
       "  ('MARCO_5330009', 0.006737604737281799),\n",
       "  ('MARCO_6661768', 0.006433457136154175),\n",
       "  ('MARCO_353893', 0.005783930420875549),\n",
       "  ('MARCO_938133', 0.005774609744548798),\n",
       "  ('MARCO_245986', 0.005422651767730713),\n",
       "  ('MARCO_5654548', 0.005349904298782349),\n",
       "  ('MARCO_5211105', 0.004652254283428192),\n",
       "  ('MARCO_8666788', 0.003997281193733215),\n",
       "  ('MARCO_7543217', 0.003955468535423279),\n",
       "  ('MARCO_5032914', 0.0035369396209716797),\n",
       "  ('CAR_29ec552061ee4433f109d3087384e25a27357742', 0.003305472433567047),\n",
       "  ('MARCO_5179950', 0.002798229455947876),\n",
       "  ('MARCO_3484877', 0.002184458076953888),\n",
       "  ('MARCO_2257657', 0.002174168825149536),\n",
       "  ('MARCO_6866529', 0.002104252576828003),\n",
       "  ('MARCO_72354', 0.0013579651713371277),\n",
       "  ('MARCO_23171', 0.00043500959873199463),\n",
       "  ('MARCO_1608274', 0.000374816358089447),\n",
       "  ('MARCO_5743580', 0.0002780035138130188),\n",
       "  ('MARCO_217418', -0.0004490315914154053),\n",
       "  ('MARCO_1195780', -0.0005285367369651794),\n",
       "  ('MARCO_3316394', -0.001847483217716217),\n",
       "  ('MARCO_7106148', -0.00202980637550354),\n",
       "  ('MARCO_3210994', -0.002226985991001129),\n",
       "  ('MARCO_4607049', -0.0053603798151016235),\n",
       "  ('MARCO_6627910', -0.0060008615255355835),\n",
       "  ('MARCO_4330495', -0.006378650665283203),\n",
       "  ('MARCO_8200388', -0.006987586617469788),\n",
       "  ('MARCO_580158', -0.006990119814872742),\n",
       "  ('CAR_69b0aa552825e621aad083f97e741410baee1899', -0.0073435381054878235),\n",
       "  ('MARCO_2539075', -0.008249521255493164),\n",
       "  ('CAR_21b4b199faff44d82fd36e5f0ac458659e90088c', -0.008329570293426514),\n",
       "  ('CAR_96cfd2f159f3c0ed504cc50778100d3c28321848', -0.009071126580238342),\n",
       "  ('MARCO_6641761', -0.009240776300430298),\n",
       "  ('MARCO_6661771', -0.010140061378479004),\n",
       "  ('MARCO_217422', -0.011125147342681885),\n",
       "  ('MARCO_6303473', -0.011270254850387573),\n",
       "  ('MARCO_4149970', -0.011300697922706604),\n",
       "  ('MARCO_3341265', -0.011809736490249634),\n",
       "  ('MARCO_8366288', -0.012517333030700684),\n",
       "  ('MARCO_2257654', -0.013457626104354858),\n",
       "  ('MARCO_6965468', -0.01617048680782318),\n",
       "  ('MARCO_5222523', -0.016405954957008362),\n",
       "  ('MARCO_6914827', -0.020584046840667725),\n",
       "  ('MARCO_3368652', -0.022692903876304626),\n",
       "  ('MARCO_1868374', -0.02423807978630066),\n",
       "  ('MARCO_5510270', -0.031094282865524292),\n",
       "  ('MARCO_7760585', -0.03213389217853546),\n",
       "  ('MARCO_1826634', -0.033427685499191284),\n",
       "  ('MARCO_5921929', -0.03364016115665436),\n",
       "  ('MARCO_2700410', -0.04004128277301788),\n",
       "  ('MARCO_1317525', -0.0502215176820755),\n",
       "  ('MARCO_6575537', -0.050236865878105164)]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_mono_reranked_samples[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iron poisoning causes abdominal pain, vomiting, diarrhea, lethargy, and dehydration. Non-small cell lung cancer is the most common type of lung cancer and can cause a cough, chest pain, and more. Carbon monoxide poisoning can be fatal, symptoms include headache, dizziness, nausea, and vomiting.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_doc_fn('MARCO_6575537')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "keys = eval_raw_samples[0].keys()\n",
    "with open('manual_y1_BM25_monoBERT_500.csv', 'w', newline='')  as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(eval_raw_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
