{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import tqdm\n",
    "from torchnlp.metrics import get_moses_multi_bleu\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
    "from io import BytesIO\n",
    "\n",
    "import linecache\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  1 17:56:47 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.40       Driver Version: 430.40       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 27%   28C    P5     6W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories already exists\n",
      "--2019-11-01 17:56:47--  https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.anno\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1382085 (1.3M) [text/plain]\n",
      "Saving to: './datasets/all.desc'\n",
      "\n",
      "./datasets/all.desc 100%[===================>]   1.32M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2019-11-01 17:56:48 (19.7 MB/s) - './datasets/all.desc' saved [1382085/1382085]\n",
      "\n",
      "--2019-11-01 17:56:48--  https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.code\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 906732 (885K) [text/plain]\n",
      "Saving to: './datasets/all.code'\n",
      "\n",
      "./datasets/all.code 100%[===================>] 885.48K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2019-11-01 17:56:49 (13.6 MB/s) - './datasets/all.code' saved [906732/906732]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"./datasets\")\n",
    "except FileExistsError:\n",
    "    print(\"Directories already exists\")\n",
    "\n",
    "# getting descriptions\n",
    "!wget https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.anno -O ./datasets/all.desc\n",
    "\n",
    "# getting code\n",
    "!wget https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.code -O ./datasets/all.code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a token text encoder\n",
    "An encoder will take a file and a splitting function and return an object able to encode and decode a string. It will also be able to save a vocab file and retrieve from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['append', 'rel_to', 'to', 'string', \"'\", 'ForeignKey', ',', '(', 'substitute', 'the', 'result', 'for', 'field_type', '.', ')']\n"
     ]
    }
   ],
   "source": [
    "text = \" append rel_to to string 'ForeignKey, (substitute the result for field_type.)\"\n",
    "\n",
    "# looks like code split need parenthesis to be matched in the same string, if not it gives an error...\n",
    "def code_split(s):\n",
    "    return [x.string for x in tokenize(BytesIO(s.encode('utf-8')).readline) if x.string != '' and x.string != \"\\n\" and not x.string.isspace()][1:]\n",
    "\n",
    "print(code_split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['append', 'rel', '_', 'to', 'to', 'string', \"'\", 'ForeignKey', ',', '(', 'subs', '_', '_', 'titute', 'the', 'result', \"'\", 'for', 'field', '_', 'type', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \" append rel_to to string 'ForeignKey, (subs__titute the result' for field_type.\"\n",
    "\n",
    "def string_split(s):\n",
    "    return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(_|\\W)', s))) # this will chunk all code properly by plits strings with quotes\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|_|\\W)', s))) # this keeps the strings intact\n",
    "\n",
    "print(string_split(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_array(src_fp, tgt_fp):\n",
    "    lines = []\n",
    "    with open(src_fp, \"r\") as src_file, open(tgt_fp, \"r\") as tgt_file:\n",
    "        for src, tgt in zip(src_file, tgt_file):\n",
    "            lines.append((src, tgt))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_corpus(data, max_seq_length=200, tokenizer=string_split):\n",
    "    return [(src, tgt) for src, tgt in data if len(string_split(src)) <= max_seq_length and len(string_split(tgt)) <= max_seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_dataset(samples, src_field, tgt_field):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samples: [(src_string),(tgt_string)]\n",
    "        src/tgt_tokenizer: a func that takes a string and returns an array of strings\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        src_string, tgt_string = sample\n",
    "        examples.append(torchtext.data.Example.fromdict({\"src\":src_string, \"tgt\":tgt_string}, \n",
    "                                        fields={\"src\":(\"src\",src_field), \"tgt\":(\"tgt\",tgt_field)}))\n",
    "        \n",
    "    dataset = torchtext.data.Dataset(examples,fields={\"src\":src_field, \"tgt\":tgt_field})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = corpus_to_array(\"datasets/all.desc\", \"datasets/all.code\")\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max src length: 586\n",
      "Max tgt length: 1087\n"
     ]
    }
   ],
   "source": [
    "print(\"Max src length:\", max([len(string_split(src)) for src, tgt in data]))\n",
    "print(\"Max tgt length:\", max([len(string_split(tgt)) for src, tgt in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 18805\n",
      "Limited dataset size: 18781\n"
     ]
    }
   ],
   "source": [
    "print(\"Full dataset size:\", len(data))\n",
    "max_seq_length=200\n",
    "data = filter_corpus(data, max_seq_length=200, tokenizer=string_split)\n",
    "print(\"Limited dataset size:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "TGT_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "\n",
    "dataset = samples_to_dataset(data, SRC_TEXT, TGT_TEXT)\n",
    "\n",
    "train_dataset, val_dataset = dataset.split([0.9,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging dataset\n",
    "This will be a small dataset of only 3 or 4 sentences to ensure the model can overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_data = [\n",
    "#     (\"my favourite foods are banana and toast\",\"would you like banana and toast ?\"),\n",
    "#     (\"my favourite foods are eggs and bacon and beans\",\"would you like eggs and bacon and beans ?\"),\n",
    "#     (\"my favourite food is chocolate\",\"would you like chocolate ?\"),\n",
    "#     (\"my favourite food is avocado\",\"would you like avocado ?\")\n",
    "# ]\n",
    "\n",
    "# other_data = [\n",
    "#     (\"what age is she ?\", \"she is 8 years old\"),\n",
    "#     (\"what age is he ?\", \"he is 4 years old\"),\n",
    "#     (\"how old are you ?\", \"i am 22 years old\"),\n",
    "#     (\"how old am i ?\", \"you are 28 years old\")\n",
    "# ]\n",
    "\n",
    "# SRC_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "# TGT_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "\n",
    "# train_dataset = val_dataset = samples_to_dataset(other_data, SRC_TEXT, TGT_TEXT)\n",
    "\n",
    "# # train_dataset, val_dataset = dataset.split([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0) # choose GPU from nvidia-smi \n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for -> 13\n",
      "every -> 62\n",
      "fixture -> 275\n",
      "_ -> 5\n",
      "file -> 70\n",
      ", -> 6\n",
      "fixture -> 275\n",
      "_ -> 5\n",
      "dir -> 235\n",
      "and -> 14\n",
      "fixture -> 275\n",
      "_ -> 5\n",
      "name -> 29\n",
      "in -> 39\n",
      "return -> 28\n",
      "value -> 25\n",
      "of -> 18\n",
      "the -> 7\n",
      "method -> 16\n",
      "self -> 10\n",
      ". -> 4\n",
      "find -> 297\n",
      "_ -> 5\n",
      "fixtures -> 1171\n",
      "called -> 96\n",
      "with -> 9\n",
      "an -> 12\n",
      "argument -> 20\n",
      "fixture -> 275\n",
      "_ -> 5\n",
      "label -> 130\n",
      ", -> 6\n"
     ]
    }
   ],
   "source": [
    "SRC_TEXT.build_vocab(train_dataset)\n",
    "TGT_TEXT.build_vocab(train_dataset)\n",
    "\n",
    "\n",
    "sample = dataset[2].src\n",
    "for tok, id in zip(sample, SRC_TEXT.numericalize([sample])):\n",
    "    print(\"{} -> {}\".format(tok, id.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4207"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TGT_TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    50/   59 batches |\n",
      "| EVALUATION | BLEU:  0.00 |\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4207"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TGT_TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', 'incomment', 'is', 'boolean', 'True', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[   2 2146   11   52   77    4    3    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1]\n",
      "[   2 2027   10   60    3    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_iterator = BucketIterator(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    repeat=True,\n",
    "#     shuffle=True,\n",
    "    sort_key = lambda x: len(x.src)+len(x.tgt),\n",
    "    device = device)\n",
    "\n",
    "valid_iterator = BucketIterator(val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    sort_key = lambda x: len(x.src)+len(x.tgt),\n",
    "    device = device)\n",
    "\n",
    "# The iterator generates batches with padded length for sequences with similar sizes, a batch is [seq_length, batch_size]\n",
    "\n",
    "for i, batch in enumerate(train_iterator):\n",
    "    idx = 0\n",
    "    print([SRC_TEXT.vocab.itos[id] for id in batch.src.cpu().numpy()[:,idx]])\n",
    "    print(batch.src.cpu().numpy()[:,idx])\n",
    "    print(batch.tgt.cpu().numpy()[:,idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample transformer without positional encoding, it uses the built in transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_transformer_model = nn.Transformer() # uses default hyperparameters\n",
    "src = torch.rand((10, 32, 512)) # [src_seq_length, batch_size, embedding_size]\n",
    "tgt = torch.rand((20, 32, 512)) # [tgt_seq_length, batch_size, embedding_size]\n",
    "rand_transformer_model(src, tgt).shape # [tgt_seq_length, batch_size, embedding_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, embedding_size=512, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.pos_encoder = PositionalEncoding(embedding_size, dropout)\n",
    "        self.src_encoder = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.tgt_encoder = nn.Embedding(tgt_vocab_size, embedding_size)\n",
    "        \n",
    "        self.transformer = nn.Transformer(d_model=embedding_size, nhead=8, num_encoder_layers=4, num_decoder_layers=4, dim_feedforward=1024)\n",
    "        self.decoder = nn.Linear(embedding_size, tgt_vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "        self.tgt_mask = None\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        noise_e = 0.05 if self.training else 0.0\n",
    "        noise_mask = (torch.rand(sz,sz) > noise_e).float()\n",
    "\n",
    "        mask = (torch.triu(torch.ones(sz,sz))).transpose(0, 1)\n",
    "        mask = torch.mul(mask, noise_mask)\n",
    "        v = (torch.sum(mask, dim=-1) == 0).float()\n",
    "\n",
    "        fix_mask = torch.zeros(sz,sz)\n",
    "        fix_mask[:,0] = 1.0\n",
    "        v = v.repeat(sz, 1).transpose(0,1)\n",
    "        fix_mask = torch.mul(fix_mask,v)\n",
    "\n",
    "        mask += fix_mask\n",
    "        \n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.src_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.tgt_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        self.tgt_mask = self._generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "\n",
    "        src = self.src_encoder(src) * math.sqrt(self.embedding_size)\n",
    "        src = self.pos_encoder(src)\n",
    "        \n",
    "        tgt = self.tgt_encoder(tgt) * math.sqrt(self.embedding_size)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        \n",
    "        output = self.transformer(src, tgt, tgt_mask=self.tgt_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(SRC_TEXT.vocab.itos)\n",
    "tgt_vocab_size = len(TGT_TEXT.vocab.itos)\n",
    "\n",
    "model = TransformerModel(src_vocab_size, tgt_vocab_size, dropout=0.2).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., -inf]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._generate_square_subsequent_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [0, 4]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],\n",
    "                  [3,4]])\n",
    "b = torch.tensor([[1,0],\n",
    "                  [0,1]])\n",
    "\n",
    "\n",
    "torch.mul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [-inf, 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, 0., -inf, -inf, 0., -inf, 0., -inf, -inf],\n",
       "        [0., -inf, -inf, -inf, 0., -inf, 0., -inf, 0., -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, 0., 0.]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_e = 0.5\n",
    "noise_mask = (torch.rand(10,10) > noise_e).float()\n",
    "\n",
    "mask = (torch.triu(torch.ones(10,10))).transpose(0, 1)\n",
    "mask = torch.mul(mask, noise_mask)\n",
    "v = (torch.sum(mask, dim=-1) == 0).float()\n",
    "\n",
    "fix_mask = torch.zeros(10,10)\n",
    "fix_mask[:,0] = 1.0\n",
    "v = v.repeat(10, 1).transpose(0,1)\n",
    "fix_mask = torch.mul(fix_mask,v)\n",
    "\n",
    "print(fix_mask)\n",
    "mask += fix_mask\n",
    "\n",
    "\n",
    "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [-inf, 0., 0., 0.],\n",
       "        [-inf, -inf, 0., 0.],\n",
       "        [-inf, -inf, -inf, 0.]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.generate_square_subsequent_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([float('-inf'),0])).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 8, 4207])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.randint(0, src_vocab_size, (10,8), device=device) # [src_seq_length, batch_size]\n",
    "tgt = torch.randint(0, tgt_vocab_size, (33,8), device=device) # [src_seq_length, batch_size]\n",
    "model(src, tgt).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1,4,3,6,2]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_batch_ids(encoder_input, max_seq_length=50):\n",
    "    batch_len = encoder_input.shape[1]\n",
    "    sos_id = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "    decoder_input = torch.zeros((1, batch_len), dtype=torch.long, device=device).fill_(sos_id)\n",
    "\n",
    "    for i in range(max_seq_length):\n",
    "        output = model(encoder_input, decoder_input)\n",
    "        last_pred = output[-1:].argmax(dim=2)\n",
    "\n",
    "        decoder_input = torch.cat((decoder_input, last_pred))\n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decode_batch_ids(encoder_input, beam_size=3, max_seq_length=50):\n",
    "    batch_len = encoder_input.shape[1]\n",
    "    sos_id = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "    decoder_input = torch.zeros((1, batch_len), dtype=torch.long, device=device).fill_(sos_id)\n",
    "    \n",
    "    for i in range(max_seq_length):\n",
    "        output = model(encoder_input, decoder_input)\n",
    "        last_pred = output[-1:].argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2740311596835683"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nltk_bleu(refrence, prediction):\n",
    "    \"\"\"\n",
    "    Implementation from ReCode\n",
    "    and moses multi belu script sets BLEU to 0.0 if len(toks) < 4\n",
    "    \"\"\"\n",
    "    ngram_weights = [0.25] * min(4, len(refrence))\n",
    "    return sentence_bleu([refrence], prediction, weights=ngram_weights, \n",
    "                          smoothing_function=SmoothingFunction().method3)\n",
    "\n",
    "nltk_bleu(np.array([1,2,3,4,5,6]), np.array([1,2,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        sources = []\n",
    "        results = []\n",
    "        targets = []\n",
    "        BLEU_scores = []\n",
    "        for i, batch in enumerate(valid_iterator):\n",
    "            encoder_inputs = batch.src\n",
    "            target = batch.tgt\n",
    "            predictions = greedy_decode_batch_ids(encoder_inputs, max_seq_length=20)\n",
    "            \n",
    "            sources += encoder_inputs.transpose(0,1).cpu().tolist()\n",
    "            results += predictions.transpose(0,1).cpu().tolist()\n",
    "            targets += target.transpose(0,1).cpu().tolist()\n",
    "            if i % 50 == 0:\n",
    "                print(\"| EVALUATION | {:5d}/{:5d} batches |\".format(i, len(valid_iterator)))\n",
    "        \n",
    "        for r_ids, target in zip(results, targets):\n",
    "            eos_id = TGT_TEXT.vocab.stoi[\"<eos>\"]\n",
    "            eos_index = r_ids.index(eos_id) if eos_id in r_ids else None\n",
    "            cut_ids = r_ids[:eos_index]\n",
    "            filtered_ids = [id for id in cut_ids if id not in [0,1,2,3]]\n",
    "            filtered_target_ids = [id for id in target if id not in [0,1,2,3]]\n",
    "            BLEU_scores.append(nltk_bleu(filtered_target_ids, filtered_ids))\n",
    "        \n",
    "        with open(\"out.txt\", \"w\") as out_fp:\n",
    "            for source, result, target, BLEU in zip(sources, results, targets, BLEU_scores):\n",
    "                eos_id = TGT_TEXT.vocab.stoi[\"<eos>\"]\n",
    "                eos_index = result.index(eos_id) if eos_id in result else None\n",
    "                cut_ids = result[:eos_index]\n",
    "                filtered_ids = [id for id in cut_ids if id not in [0,1,2,3]]\n",
    "                filtered_target_ids = [id for id in target if id not in [0,1,2,3]]\n",
    "                filtered_source_ids = [id for id in source if id not in [0,1,2,3]]\n",
    "                \n",
    "                out_fp.write(\"SRC  :\" + \" \".join([SRC_TEXT.vocab.itos[id] for id in filtered_source_ids]) + \"\\n\")\n",
    "                out_fp.write(\"TGT  :\" + \" \".join([TGT_TEXT.vocab.itos[id] for id in filtered_target_ids]) + \"\\n\")\n",
    "                out_fp.write(\"PRED :\" + \" \".join([TGT_TEXT.vocab.itos[id] for id in filtered_ids]) + \"\\n\")\n",
    "                out_fp.write(\"BLEU :\" + str(BLEU) + \"\\n\")\n",
    "                out_fp.write(\"\\n\")\n",
    "                \n",
    "        print(\"| EVALUATION | BLEU: {:5.2f} |\".format(np.average(BLEU_scores)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    tgt_vocab_size = len(TGT_TEXT.vocab.itos)\n",
    "    encoder_input = batch.src\n",
    "    decoder_input = batch.tgt[:-1]\n",
    "    targets = batch.tgt[1:]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(encoder_input, decoder_input)\n",
    "\n",
    "    loss = criterion(output.view(-1, tgt_vocab_size), targets.view(-1))\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "    elapsed = time.time() - start_time\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=TGT_TEXT.vocab.stoi['<pad>'])\n",
    "lr = 0.005 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   200/500000 steps | lr 0.0047 | ms/batch 46.54 | loss  3.38 | ppl    29.44\n",
      "|   400/500000 steps | lr 0.0047 | ms/batch 45.50 | loss  3.39 | ppl    29.55\n",
      "|   600/500000 steps | lr 0.0047 | ms/batch 45.39 | loss  3.39 | ppl    29.54\n",
      "|   800/500000 steps | lr 0.0047 | ms/batch 44.86 | loss  3.35 | ppl    28.52\n",
      "|  1000/500000 steps | lr 0.0047 | ms/batch 45.90 | loss  3.39 | ppl    29.69\n",
      "|  1200/500000 steps | lr 0.0047 | ms/batch 47.18 | loss  3.38 | ppl    29.28\n",
      "|  1400/500000 steps | lr 0.0047 | ms/batch 47.94 | loss  3.36 | ppl    28.88\n",
      "|  1600/500000 steps | lr 0.0047 | ms/batch 46.72 | loss  3.37 | ppl    28.97\n",
      "|  1800/500000 steps | lr 0.0047 | ms/batch 48.52 | loss  3.35 | ppl    28.47\n",
      "|  2000/500000 steps | lr 0.0047 | ms/batch 46.67 | loss  3.35 | ppl    28.52\n",
      "|  2200/500000 steps | lr 0.0047 | ms/batch 47.84 | loss  3.35 | ppl    28.42\n",
      "|  2400/500000 steps | lr 0.0047 | ms/batch 47.22 | loss  3.33 | ppl    27.85\n",
      "|  2600/500000 steps | lr 0.0047 | ms/batch 48.34 | loss  3.39 | ppl    29.60\n",
      "|  2800/500000 steps | lr 0.0047 | ms/batch 47.22 | loss  3.35 | ppl    28.39\n",
      "|  3000/500000 steps | lr 0.0047 | ms/batch 48.09 | loss  3.34 | ppl    28.21\n",
      "|  3200/500000 steps | lr 0.0047 | ms/batch 47.23 | loss  3.30 | ppl    27.11\n",
      "|  3400/500000 steps | lr 0.0047 | ms/batch 46.67 | loss  3.33 | ppl    27.94\n",
      "|  3600/500000 steps | lr 0.0047 | ms/batch 44.79 | loss  3.29 | ppl    26.89\n",
      "|  3800/500000 steps | lr 0.0047 | ms/batch 48.00 | loss  3.31 | ppl    27.50\n",
      "|  4000/500000 steps | lr 0.0047 | ms/batch 47.22 | loss  3.31 | ppl    27.50\n",
      "|  4200/500000 steps | lr 0.0047 | ms/batch 46.14 | loss  3.34 | ppl    28.15\n",
      "|  4400/500000 steps | lr 0.0047 | ms/batch 45.82 | loss  3.27 | ppl    26.24\n",
      "|  4600/500000 steps | lr 0.0047 | ms/batch 48.20 | loss  3.29 | ppl    26.72\n",
      "|  4800/500000 steps | lr 0.0047 | ms/batch 47.24 | loss  3.32 | ppl    27.54\n",
      "|  5000/500000 steps | lr 0.0047 | ms/batch 46.61 | loss  3.30 | ppl    27.25\n",
      "|  5200/500000 steps | lr 0.0047 | ms/batch 44.86 | loss  3.28 | ppl    26.52\n",
      "|  5400/500000 steps | lr 0.0047 | ms/batch 45.58 | loss  3.28 | ppl    26.68\n",
      "|  5600/500000 steps | lr 0.0047 | ms/batch 45.27 | loss  3.25 | ppl    25.76\n",
      "|  5800/500000 steps | lr 0.0047 | ms/batch 48.64 | loss  3.31 | ppl    27.28\n",
      "|  6000/500000 steps | lr 0.0047 | ms/batch 47.96 | loss  3.26 | ppl    25.99\n",
      "|  6200/500000 steps | lr 0.0047 | ms/batch 46.28 | loss  3.29 | ppl    26.72\n",
      "|  6400/500000 steps | lr 0.0047 | ms/batch 45.46 | loss  3.24 | ppl    25.62\n",
      "|  6600/500000 steps | lr 0.0047 | ms/batch 45.66 | loss  3.27 | ppl    26.34\n",
      "|  6800/500000 steps | lr 0.0047 | ms/batch 44.76 | loss  3.25 | ppl    25.66\n",
      "|  7000/500000 steps | lr 0.0047 | ms/batch 46.18 | loss  3.25 | ppl    25.81\n",
      "|  7200/500000 steps | lr 0.0047 | ms/batch 46.18 | loss  3.26 | ppl    26.09\n",
      "|  7400/500000 steps | lr 0.0047 | ms/batch 44.88 | loss  3.24 | ppl    25.65\n",
      "|  7600/500000 steps | lr 0.0047 | ms/batch 46.11 | loss  3.24 | ppl    25.55\n",
      "|  7800/500000 steps | lr 0.0047 | ms/batch 46.19 | loss  3.25 | ppl    25.70\n",
      "|  8000/500000 steps | lr 0.0047 | ms/batch 47.92 | loss  3.23 | ppl    25.23\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    50/   59 batches |\n",
      "| EVALUATION | BLEU:  0.27 |\n",
      "|  8200/500000 steps | lr 0.0046 | ms/batch 204.14 | loss  3.22 | ppl    25.07\n",
      "|  8400/500000 steps | lr 0.0046 | ms/batch 44.89 | loss  3.22 | ppl    24.93\n",
      "|  8600/500000 steps | lr 0.0046 | ms/batch 43.51 | loss  3.22 | ppl    24.98\n",
      "|  8800/500000 steps | lr 0.0046 | ms/batch 47.24 | loss  3.24 | ppl    25.50\n",
      "|  9000/500000 steps | lr 0.0046 | ms/batch 48.70 | loss  3.21 | ppl    24.79\n",
      "|  9200/500000 steps | lr 0.0046 | ms/batch 45.89 | loss  3.22 | ppl    24.94\n",
      "|  9400/500000 steps | lr 0.0046 | ms/batch 44.66 | loss  3.19 | ppl    24.41\n",
      "|  9600/500000 steps | lr 0.0046 | ms/batch 46.28 | loss  3.20 | ppl    24.61\n",
      "|  9800/500000 steps | lr 0.0046 | ms/batch 44.65 | loss  3.20 | ppl    24.65\n",
      "| 10000/500000 steps | lr 0.0046 | ms/batch 46.18 | loss  3.19 | ppl    24.38\n",
      "| 10200/500000 steps | lr 0.0046 | ms/batch 45.14 | loss  3.16 | ppl    23.53\n",
      "| 10400/500000 steps | lr 0.0046 | ms/batch 45.93 | loss  3.18 | ppl    23.93\n",
      "| 10600/500000 steps | lr 0.0046 | ms/batch 46.11 | loss  3.22 | ppl    25.06\n",
      "| 10800/500000 steps | lr 0.0046 | ms/batch 46.51 | loss  3.19 | ppl    24.38\n",
      "| 11000/500000 steps | lr 0.0046 | ms/batch 44.64 | loss  3.15 | ppl    23.42\n",
      "| 11200/500000 steps | lr 0.0046 | ms/batch 45.46 | loss  3.18 | ppl    24.03\n",
      "| 11400/500000 steps | lr 0.0046 | ms/batch 47.46 | loss  3.18 | ppl    24.13\n",
      "| 11600/500000 steps | lr 0.0046 | ms/batch 43.92 | loss  3.15 | ppl    23.33\n",
      "| 11800/500000 steps | lr 0.0046 | ms/batch 45.26 | loss  3.16 | ppl    23.61\n",
      "| 12000/500000 steps | lr 0.0046 | ms/batch 47.18 | loss  3.19 | ppl    24.36\n",
      "| 12200/500000 steps | lr 0.0046 | ms/batch 44.00 | loss  3.13 | ppl    22.96\n",
      "| 12400/500000 steps | lr 0.0046 | ms/batch 46.17 | loss  3.16 | ppl    23.69\n",
      "| 12600/500000 steps | lr 0.0046 | ms/batch 46.66 | loss  3.15 | ppl    23.28\n",
      "| 12800/500000 steps | lr 0.0046 | ms/batch 44.43 | loss  3.15 | ppl    23.36\n",
      "| 13000/500000 steps | lr 0.0046 | ms/batch 47.01 | loss  3.16 | ppl    23.55\n",
      "| 13200/500000 steps | lr 0.0046 | ms/batch 44.44 | loss  3.12 | ppl    22.54\n",
      "| 13400/500000 steps | lr 0.0046 | ms/batch 46.95 | loss  3.17 | ppl    23.73\n",
      "| 13600/500000 steps | lr 0.0046 | ms/batch 44.36 | loss  3.11 | ppl    22.50\n",
      "| 13800/500000 steps | lr 0.0046 | ms/batch 46.44 | loss  3.14 | ppl    23.04\n",
      "| 14000/500000 steps | lr 0.0046 | ms/batch 46.20 | loss  3.13 | ppl    22.77\n",
      "| 14200/500000 steps | lr 0.0046 | ms/batch 44.65 | loss  3.15 | ppl    23.26\n",
      "| 14400/500000 steps | lr 0.0046 | ms/batch 46.73 | loss  3.12 | ppl    22.63\n",
      "| 14600/500000 steps | lr 0.0046 | ms/batch 48.59 | loss  3.13 | ppl    22.83\n",
      "| 14800/500000 steps | lr 0.0046 | ms/batch 47.78 | loss  3.10 | ppl    22.29\n",
      "| 15000/500000 steps | lr 0.0046 | ms/batch 47.66 | loss  3.12 | ppl    22.61\n",
      "| 15200/500000 steps | lr 0.0046 | ms/batch 46.48 | loss  3.10 | ppl    22.22\n",
      "| 15400/500000 steps | lr 0.0046 | ms/batch 44.83 | loss  3.11 | ppl    22.36\n",
      "| 15600/500000 steps | lr 0.0046 | ms/batch 46.53 | loss  3.13 | ppl    22.81\n",
      "| 15800/500000 steps | lr 0.0046 | ms/batch 45.04 | loss  3.07 | ppl    21.51\n",
      "| 16000/500000 steps | lr 0.0046 | ms/batch 45.64 | loss  3.10 | ppl    22.09\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    50/   59 batches |\n",
      "| EVALUATION | BLEU:  0.28 |\n",
      "| 16200/500000 steps | lr 0.0045 | ms/batch 205.68 | loss  3.06 | ppl    21.28\n",
      "| 16400/500000 steps | lr 0.0045 | ms/batch 47.09 | loss  3.15 | ppl    23.29\n",
      "| 16600/500000 steps | lr 0.0045 | ms/batch 46.76 | loss  3.10 | ppl    22.12\n",
      "| 16800/500000 steps | lr 0.0045 | ms/batch 44.50 | loss  3.08 | ppl    21.72\n",
      "| 17000/500000 steps | lr 0.0045 | ms/batch 46.22 | loss  3.09 | ppl    21.95\n",
      "| 17200/500000 steps | lr 0.0045 | ms/batch 47.37 | loss  3.09 | ppl    21.90\n",
      "| 17400/500000 steps | lr 0.0045 | ms/batch 46.32 | loss  3.06 | ppl    21.33\n",
      "| 17600/500000 steps | lr 0.0045 | ms/batch 46.95 | loss  3.06 | ppl    21.34\n",
      "| 17800/500000 steps | lr 0.0045 | ms/batch 48.02 | loss  3.08 | ppl    21.76\n",
      "| 18000/500000 steps | lr 0.0045 | ms/batch 46.02 | loss  3.06 | ppl    21.38\n",
      "| 18200/500000 steps | lr 0.0045 | ms/batch 44.98 | loss  3.05 | ppl    21.13\n",
      "| 18400/500000 steps | lr 0.0045 | ms/batch 45.82 | loss  3.07 | ppl    21.45\n",
      "| 18600/500000 steps | lr 0.0045 | ms/batch 46.10 | loss  3.09 | ppl    21.94\n",
      "| 18800/500000 steps | lr 0.0045 | ms/batch 45.38 | loss  3.06 | ppl    21.29\n",
      "| 19000/500000 steps | lr 0.0045 | ms/batch 46.26 | loss  3.04 | ppl    20.92\n",
      "| 19200/500000 steps | lr 0.0045 | ms/batch 47.23 | loss  3.07 | ppl    21.64\n",
      "| 19400/500000 steps | lr 0.0045 | ms/batch 47.82 | loss  3.05 | ppl    21.02\n",
      "| 19600/500000 steps | lr 0.0045 | ms/batch 45.57 | loss  3.06 | ppl    21.43\n",
      "| 19800/500000 steps | lr 0.0045 | ms/batch 44.74 | loss  3.04 | ppl    21.00\n",
      "| 20000/500000 steps | lr 0.0045 | ms/batch 46.00 | loss  3.03 | ppl    20.79\n",
      "| 20200/500000 steps | lr 0.0045 | ms/batch 46.58 | loss  3.04 | ppl    20.96\n",
      "| 20400/500000 steps | lr 0.0045 | ms/batch 44.95 | loss  3.02 | ppl    20.50\n",
      "| 20600/500000 steps | lr 0.0045 | ms/batch 46.12 | loss  3.02 | ppl    20.39\n",
      "| 20800/500000 steps | lr 0.0045 | ms/batch 45.06 | loss  3.02 | ppl    20.59\n",
      "| 21000/500000 steps | lr 0.0045 | ms/batch 45.14 | loss  3.02 | ppl    20.46\n",
      "| 21200/500000 steps | lr 0.0045 | ms/batch 47.70 | loss  3.04 | ppl    20.85\n",
      "| 21400/500000 steps | lr 0.0045 | ms/batch 44.06 | loss  2.99 | ppl    19.85\n",
      "| 21600/500000 steps | lr 0.0045 | ms/batch 47.05 | loss  3.04 | ppl    20.99\n",
      "| 21800/500000 steps | lr 0.0045 | ms/batch 45.96 | loss  3.03 | ppl    20.60\n",
      "| 22000/500000 steps | lr 0.0045 | ms/batch 45.47 | loss  2.99 | ppl    19.92\n",
      "| 22200/500000 steps | lr 0.0045 | ms/batch 45.38 | loss  3.02 | ppl    20.53\n",
      "| 22400/500000 steps | lr 0.0045 | ms/batch 46.10 | loss  3.02 | ppl    20.42\n",
      "| 22600/500000 steps | lr 0.0045 | ms/batch 45.47 | loss  3.00 | ppl    20.18\n",
      "| 22800/500000 steps | lr 0.0045 | ms/batch 45.05 | loss  3.00 | ppl    20.06\n",
      "| 23000/500000 steps | lr 0.0045 | ms/batch 46.53 | loss  2.99 | ppl    19.92\n",
      "| 23200/500000 steps | lr 0.0045 | ms/batch 46.02 | loss  2.99 | ppl    19.89\n",
      "| 23400/500000 steps | lr 0.0045 | ms/batch 44.51 | loss  3.01 | ppl    20.33\n",
      "| 23600/500000 steps | lr 0.0045 | ms/batch 46.87 | loss  3.01 | ppl    20.26\n",
      "| 23800/500000 steps | lr 0.0045 | ms/batch 48.45 | loss  2.97 | ppl    19.50\n",
      "| 24000/500000 steps | lr 0.0045 | ms/batch 44.87 | loss  2.97 | ppl    19.54\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    50/   59 batches |\n",
      "| EVALUATION | BLEU:  0.30 |\n",
      "| 24200/500000 steps | lr 0.0044 | ms/batch 205.10 | loss  2.98 | ppl    19.74\n",
      "| 24400/500000 steps | lr 0.0044 | ms/batch 45.33 | loss  3.01 | ppl    20.32\n",
      "| 24600/500000 steps | lr 0.0044 | ms/batch 45.39 | loss  2.99 | ppl    19.96\n",
      "| 24800/500000 steps | lr 0.0044 | ms/batch 45.71 | loss  2.95 | ppl    19.07\n",
      "| 25000/500000 steps | lr 0.0044 | ms/batch 45.35 | loss  2.97 | ppl    19.45\n",
      "| 25200/500000 steps | lr 0.0044 | ms/batch 45.65 | loss  2.96 | ppl    19.33\n",
      "| 25400/500000 steps | lr 0.0044 | ms/batch 45.08 | loss  2.98 | ppl    19.61\n",
      "| 25600/500000 steps | lr 0.0044 | ms/batch 46.10 | loss  3.01 | ppl    20.30\n",
      "| 25800/500000 steps | lr 0.0044 | ms/batch 44.87 | loss  2.94 | ppl    18.94\n",
      "| 26000/500000 steps | lr 0.0044 | ms/batch 44.74 | loss  2.94 | ppl    18.82\n",
      "| 26200/500000 steps | lr 0.0044 | ms/batch 46.51 | loss  2.96 | ppl    19.31\n",
      "| 26400/500000 steps | lr 0.0044 | ms/batch 45.61 | loss  2.96 | ppl    19.31\n",
      "| 26600/500000 steps | lr 0.0044 | ms/batch 47.34 | loss  2.98 | ppl    19.67\n",
      "| 26800/500000 steps | lr 0.0044 | ms/batch 46.37 | loss  2.95 | ppl    19.18\n",
      "| 27000/500000 steps | lr 0.0044 | ms/batch 42.89 | loss  2.90 | ppl    18.09\n",
      "| 27200/500000 steps | lr 0.0044 | ms/batch 46.78 | loss  2.96 | ppl    19.37\n",
      "| 27400/500000 steps | lr 0.0044 | ms/batch 46.22 | loss  2.97 | ppl    19.44\n",
      "| 27600/500000 steps | lr 0.0044 | ms/batch 44.22 | loss  2.91 | ppl    18.44\n",
      "| 27800/500000 steps | lr 0.0044 | ms/batch 45.24 | loss  2.93 | ppl    18.77\n",
      "| 28000/500000 steps | lr 0.0044 | ms/batch 46.55 | loss  2.95 | ppl    19.13\n",
      "| 28200/500000 steps | lr 0.0044 | ms/batch 45.78 | loss  2.94 | ppl    18.87\n",
      "| 28400/500000 steps | lr 0.0044 | ms/batch 45.49 | loss  2.93 | ppl    18.71\n",
      "| 28600/500000 steps | lr 0.0044 | ms/batch 45.85 | loss  2.95 | ppl    19.05\n",
      "| 28800/500000 steps | lr 0.0044 | ms/batch 48.07 | loss  2.97 | ppl    19.52\n",
      "| 29000/500000 steps | lr 0.0044 | ms/batch 46.25 | loss  2.90 | ppl    18.20\n",
      "| 29200/500000 steps | lr 0.0044 | ms/batch 46.63 | loss  2.93 | ppl    18.81\n",
      "| 29400/500000 steps | lr 0.0044 | ms/batch 45.68 | loss  2.93 | ppl    18.82\n",
      "| 29600/500000 steps | lr 0.0044 | ms/batch 45.26 | loss  2.90 | ppl    18.09\n",
      "| 29800/500000 steps | lr 0.0044 | ms/batch 46.64 | loss  2.91 | ppl    18.31\n",
      "| 30000/500000 steps | lr 0.0044 | ms/batch 47.28 | loss  2.90 | ppl    18.22\n",
      "| 30200/500000 steps | lr 0.0044 | ms/batch 47.36 | loss  2.93 | ppl    18.67\n",
      "| 30400/500000 steps | lr 0.0044 | ms/batch 46.80 | loss  2.88 | ppl    17.83\n",
      "| 30600/500000 steps | lr 0.0044 | ms/batch 44.52 | loss  2.90 | ppl    18.23\n",
      "| 30800/500000 steps | lr 0.0044 | ms/batch 46.95 | loss  2.93 | ppl    18.81\n",
      "| 31000/500000 steps | lr 0.0044 | ms/batch 45.06 | loss  2.90 | ppl    18.23\n",
      "| 31200/500000 steps | lr 0.0044 | ms/batch 45.04 | loss  2.89 | ppl    17.91\n",
      "| 31400/500000 steps | lr 0.0044 | ms/batch 46.55 | loss  2.87 | ppl    17.68\n",
      "| 31600/500000 steps | lr 0.0044 | ms/batch 45.86 | loss  2.93 | ppl    18.68\n",
      "| 31800/500000 steps | lr 0.0044 | ms/batch 45.93 | loss  2.91 | ppl    18.34\n",
      "| 32000/500000 steps | lr 0.0044 | ms/batch 44.96 | loss  2.87 | ppl    17.58\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    50/   59 batches |\n",
      "| EVALUATION | BLEU:  0.31 |\n",
      "| 32200/500000 steps | lr 0.0043 | ms/batch 204.13 | loss  2.90 | ppl    18.24\n",
      "| 32400/500000 steps | lr 0.0043 | ms/batch 45.99 | loss  2.89 | ppl    18.04\n",
      "| 32600/500000 steps | lr 0.0043 | ms/batch 46.10 | loss  2.90 | ppl    18.22\n",
      "| 32800/500000 steps | lr 0.0043 | ms/batch 45.68 | loss  2.86 | ppl    17.40\n",
      "| 33000/500000 steps | lr 0.0043 | ms/batch 46.06 | loss  2.89 | ppl    18.06\n",
      "| 33200/500000 steps | lr 0.0043 | ms/batch 46.00 | loss  2.89 | ppl    17.99\n",
      "| 33400/500000 steps | lr 0.0043 | ms/batch 44.39 | loss  2.85 | ppl    17.26\n",
      "| 33600/500000 steps | lr 0.0043 | ms/batch 45.73 | loss  2.90 | ppl    18.20\n",
      "| 33800/500000 steps | lr 0.0043 | ms/batch 46.20 | loss  2.84 | ppl    17.18\n",
      "| 34000/500000 steps | lr 0.0043 | ms/batch 45.03 | loss  2.86 | ppl    17.53\n",
      "| 34200/500000 steps | lr 0.0043 | ms/batch 47.39 | loss  2.86 | ppl    17.54\n",
      "| 34400/500000 steps | lr 0.0043 | ms/batch 47.81 | loss  2.87 | ppl    17.61\n",
      "| 34600/500000 steps | lr 0.0043 | ms/batch 48.65 | loss  2.87 | ppl    17.72\n",
      "| 34800/500000 steps | lr 0.0043 | ms/batch 47.67 | loss  2.87 | ppl    17.56\n",
      "| 35000/500000 steps | lr 0.0043 | ms/batch 45.13 | loss  2.81 | ppl    16.69\n",
      "| 35200/500000 steps | lr 0.0043 | ms/batch 46.02 | loss  2.86 | ppl    17.52\n",
      "| 35400/500000 steps | lr 0.0043 | ms/batch 46.15 | loss  2.88 | ppl    17.77\n",
      "| 35600/500000 steps | lr 0.0043 | ms/batch 46.07 | loss  2.86 | ppl    17.50\n",
      "| 35800/500000 steps | lr 0.0043 | ms/batch 44.74 | loss  2.82 | ppl    16.81\n",
      "| 36000/500000 steps | lr 0.0043 | ms/batch 46.98 | loss  2.87 | ppl    17.56\n",
      "| 36200/500000 steps | lr 0.0043 | ms/batch 46.50 | loss  2.88 | ppl    17.80\n",
      "| 36400/500000 steps | lr 0.0043 | ms/batch 45.19 | loss  2.81 | ppl    16.63\n",
      "| 36600/500000 steps | lr 0.0043 | ms/batch 45.71 | loss  2.84 | ppl    17.13\n",
      "| 36800/500000 steps | lr 0.0043 | ms/batch 46.75 | loss  2.85 | ppl    17.32\n",
      "| 37000/500000 steps | lr 0.0043 | ms/batch 46.40 | loss  2.83 | ppl    16.94\n",
      "| 37200/500000 steps | lr 0.0043 | ms/batch 44.78 | loss  2.85 | ppl    17.32\n",
      "| 37400/500000 steps | lr 0.0043 | ms/batch 46.31 | loss  2.83 | ppl    16.94\n",
      "| 37600/500000 steps | lr 0.0043 | ms/batch 45.95 | loss  2.82 | ppl    16.86\n",
      "| 37800/500000 steps | lr 0.0043 | ms/batch 47.27 | loss  2.84 | ppl    17.10\n",
      "| 38000/500000 steps | lr 0.0043 | ms/batch 46.53 | loss  2.83 | ppl    16.93\n",
      "| 38200/500000 steps | lr 0.0043 | ms/batch 45.34 | loss  2.79 | ppl    16.27\n",
      "| 38400/500000 steps | lr 0.0043 | ms/batch 45.12 | loss  2.83 | ppl    16.87\n",
      "| 38600/500000 steps | lr 0.0043 | ms/batch 45.95 | loss  2.84 | ppl    17.10\n",
      "| 38800/500000 steps | lr 0.0043 | ms/batch 47.34 | loss  2.82 | ppl    16.73\n",
      "| 39000/500000 steps | lr 0.0043 | ms/batch 47.39 | loss  2.81 | ppl    16.68\n",
      "| 39200/500000 steps | lr 0.0043 | ms/batch 45.72 | loss  2.81 | ppl    16.63\n",
      "| 39400/500000 steps | lr 0.0043 | ms/batch 45.46 | loss  2.81 | ppl    16.59\n",
      "| 39600/500000 steps | lr 0.0043 | ms/batch 46.24 | loss  2.82 | ppl    16.77\n",
      "| 39800/500000 steps | lr 0.0043 | ms/batch 46.14 | loss  2.81 | ppl    16.53\n",
      "| 40000/500000 steps | lr 0.0043 | ms/batch 46.69 | loss  2.82 | ppl    16.74\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    50/   59 batches |\n",
      "| EVALUATION | BLEU:  0.33 |\n",
      "| 40200/500000 steps | lr 0.0043 | ms/batch 204.21 | loss  2.81 | ppl    16.67\n",
      "| 40400/500000 steps | lr 0.0043 | ms/batch 45.26 | loss  2.80 | ppl    16.47\n",
      "| 40600/500000 steps | lr 0.0043 | ms/batch 45.20 | loss  2.81 | ppl    16.53\n",
      "| 40800/500000 steps | lr 0.0043 | ms/batch 46.18 | loss  2.77 | ppl    16.00\n",
      "| 41000/500000 steps | lr 0.0043 | ms/batch 46.53 | loss  2.81 | ppl    16.61\n",
      "| 41200/500000 steps | lr 0.0043 | ms/batch 45.41 | loss  2.82 | ppl    16.73\n",
      "| 41400/500000 steps | lr 0.0043 | ms/batch 45.42 | loss  2.76 | ppl    15.80\n",
      "| 41600/500000 steps | lr 0.0043 | ms/batch 46.08 | loss  2.80 | ppl    16.38\n",
      "| 41800/500000 steps | lr 0.0043 | ms/batch 45.78 | loss  2.82 | ppl    16.70\n",
      "| 42000/500000 steps | lr 0.0043 | ms/batch 45.01 | loss  2.76 | ppl    15.76\n",
      "| 42200/500000 steps | lr 0.0043 | ms/batch 45.35 | loss  2.80 | ppl    16.48\n",
      "| 42400/500000 steps | lr 0.0043 | ms/batch 46.90 | loss  2.80 | ppl    16.40\n",
      "| 42600/500000 steps | lr 0.0043 | ms/batch 46.98 | loss  2.79 | ppl    16.35\n",
      "| 42800/500000 steps | lr 0.0043 | ms/batch 44.55 | loss  2.77 | ppl    15.98\n",
      "| 43000/500000 steps | lr 0.0043 | ms/batch 46.49 | loss  2.78 | ppl    16.18\n",
      "| 43200/500000 steps | lr 0.0043 | ms/batch 44.91 | loss  2.78 | ppl    16.10\n",
      "| 43400/500000 steps | lr 0.0043 | ms/batch 46.62 | loss  2.77 | ppl    15.91\n",
      "| 43600/500000 steps | lr 0.0043 | ms/batch 45.79 | loss  2.78 | ppl    16.06\n",
      "| 43800/500000 steps | lr 0.0043 | ms/batch 47.44 | loss  2.77 | ppl    15.95\n",
      "| 44000/500000 steps | lr 0.0043 | ms/batch 45.45 | loss  2.76 | ppl    15.87\n",
      "| 44200/500000 steps | lr 0.0042 | ms/batch 46.23 | loss  2.75 | ppl    15.65\n",
      "| 44400/500000 steps | lr 0.0042 | ms/batch 47.71 | loss  2.79 | ppl    16.30\n",
      "| 44600/500000 steps | lr 0.0042 | ms/batch 46.91 | loss  2.77 | ppl    15.93\n"
     ]
    }
   ],
   "source": [
    "def train(steps=10000, log_interval=200, learning_interval=4000, eval_interval=1000):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    step = 1\n",
    "    for batch in train_iterator:\n",
    "        loss = train_step(batch)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if step % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| {:5d}/{:5d} steps | '\n",
    "                  'lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    step, steps, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "        if step % eval_interval == 0:\n",
    "            print(\"Evaluating model\")\n",
    "            evaluate()\n",
    "            model.train()\n",
    "        \n",
    "        if step % learning_interval == 0:\n",
    "            scheduler.step()\n",
    "        \n",
    "        step += 1\n",
    "        if step >= steps:\n",
    "            print(\"Finished training\")\n",
    "            return\n",
    "\n",
    "train(steps=500000,eval_interval=8000,log_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> substitute args for self . _ _ args . <eos>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([SRC_TEXT.vocab.itos[i] for i in [ 2,21,83,13,10, 4, 5, 5,83, 4, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> self . _'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([TGT_TEXT.vocab.itos[i] for i in [ 2,12,5,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC ids shape: tensor([[  2],\n",
      "        [ 72],\n",
      "        [ 25],\n",
      "        [ 17],\n",
      "        [301],\n",
      "        [  4],\n",
      "        [  3]], device='cuda:0')\n",
      "output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> "
     ]
    }
   ],
   "source": [
    "def translate(s):\n",
    "    src_ids = SRC_TEXT.numericalize([[\"<sos>\"] + SRC_TEXT.preprocess(s) + [\"<eos>\"]], device=device)\n",
    "#     src_ids = torch.tensor([ [2],[21],[83],[13],[10], [4], [5], [5],[83], [4], [3]], device=device)\n",
    "    print(\"SRC ids shape:\",src_ids)\n",
    "    model.eval\n",
    "    with torch.no_grad():\n",
    "        sos_id = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "#         decoder_input = torch.zeros((1, 1), dtype=torch.long, device=device).fill_(sos_id)\n",
    "        decoder_input = torch.tensor(np.array([ [2]]), device=device)\n",
    "#         print(\"Decoder input shape:\", decoder_input.shape)\n",
    "        \n",
    "        for i in range(10):\n",
    "#             print(\"Decoder input\", decoder_input)\n",
    "            output = model(src_ids, decoder_input)\n",
    "#             print(model.tgt_mask)\n",
    "            print(\"output:\", output)\n",
    "#             print(\"predicted ids:\", output.argmax(dim=-1))\n",
    "            last_pred = output[-1:].argmax(dim=2)\n",
    "#             decoder_input[i+1][0] = last_pred\n",
    "#             print(\"last pred:\", TGT_TEXT.vocab.itos[last_pred.cpu().numpy()[0][0]], last_pred.cpu().numpy()[0][0])\n",
    "            print(TGT_TEXT.vocab.itos[last_pred.cpu().numpy()[0][0]],'', end = '')\n",
    "            \n",
    "            decoder_input = torch.cat((decoder_input, last_pred))\n",
    "#             print(\"Decoder input\", decoder_input)\n",
    "#             break\n",
    "\n",
    "translate(\"append value to results .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389431042462724"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_bleu(np.array([torch.tensor([1.0]),torch.tensor([2.0])]), [1,2,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([torch.tensor([1.0]),torch.tensor([2.0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moses Multi-BLEU perl script returns 0.0 for any sentence less than 4 tokens long.\n",
    "It will be best to use a function by NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_moses_multi_bleu([\"this is a test\"], [\"this is a for\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
