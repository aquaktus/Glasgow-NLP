{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import tqdm\n",
    "from torchnlp.metrics import get_moses_multi_bleu\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
    "from io import BytesIO\n",
    "\n",
    "import linecache\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  1 17:56:47 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.40       Driver Version: 430.40       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 27%   28C    P5     6W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories already exists\n",
      "--2019-11-05 12:05:54--  https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.anno\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1382085 (1.3M) [text/plain]\n",
      "Saving to: './datasets/all.desc'\n",
      "\n",
      "./datasets/all.desc 100%[===================>]   1.32M  3.52MB/s    in 0.4s    \n",
      "\n",
      "2019-11-05 12:05:55 (3.52 MB/s) - './datasets/all.desc' saved [1382085/1382085]\n",
      "\n",
      "--2019-11-05 12:05:55--  https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.code\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 906732 (885K) [text/plain]\n",
      "Saving to: './datasets/all.code'\n",
      "\n",
      "./datasets/all.code 100%[===================>] 885.48K  4.44MB/s    in 0.2s    \n",
      "\n",
      "2019-11-05 12:05:56 (4.44 MB/s) - './datasets/all.code' saved [906732/906732]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"./datasets\")\n",
    "except FileExistsError:\n",
    "    print(\"Directories already exists\")\n",
    "\n",
    "# getting descriptions\n",
    "!wget https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.anno -O ./datasets/all.desc\n",
    "\n",
    "# getting code\n",
    "!wget https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.code -O ./datasets/all.code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a token text encoder\n",
    "An encoder will take a file and a splitting function and return an object able to encode and decode a string. It will also be able to save a vocab file and retrieve from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['append', 'rel_to', 'to', 'string', \"'\", 'ForeignKey', ',', '(', 'substitute', 'the', 'result', 'for', 'field_type', '.', ')']\n"
     ]
    }
   ],
   "source": [
    "text = \" append rel_to to string 'ForeignKey, (substitute the result for field_type.)\"\n",
    "\n",
    "# looks like code split need parenthesis to be matched in the same string, if not it gives an error...\n",
    "def code_split(s):\n",
    "    return [x.string for x in tokenize(BytesIO(s.encode('utf-8')).readline) if x.string != '' and x.string != \"\\n\" and not x.string.isspace()][1:]\n",
    "\n",
    "print(code_split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['append', 'rel', '_', 'to', 'to', 'string', \"'\", 'ForeignKey', ',', '(', 'subs', '_', '_', 'titute', 'the', 'result', \"'\", 'for', 'field', '_', 'type', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \" append rel_to to string 'ForeignKey, (subs__titute the result' for field_type.\"\n",
    "\n",
    "def string_split(s):\n",
    "    return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(_|\\W)', s))) # this will chunk all code properly by plits strings with quotes\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|_|\\W)', s))) # this keeps the strings intact\n",
    "\n",
    "print(string_split(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_array(src_fp, tgt_fp):\n",
    "    lines = []\n",
    "    with open(src_fp, \"r\") as src_file, open(tgt_fp, \"r\") as tgt_file:\n",
    "        for src, tgt in zip(src_file, tgt_file):\n",
    "            lines.append((src, tgt))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_corpus(data, max_seq_length=200, tokenizer=string_split):\n",
    "    return [(src, tgt) for src, tgt in data if len(string_split(src)) <= max_seq_length and len(string_split(tgt)) <= max_seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_dataset(samples, src_field, tgt_field):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samples: [(src_string),(tgt_string)]\n",
    "        src/tgt_tokenizer: a func that takes a string and returns an array of strings\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        src_string, tgt_string = sample\n",
    "        examples.append(torchtext.data.Example.fromdict({\"src\":src_string, \"tgt\":tgt_string}, \n",
    "                                        fields={\"src\":(\"src\",src_field), \"tgt\":(\"tgt\",tgt_field)}))\n",
    "        \n",
    "    dataset = torchtext.data.Dataset(examples,fields={\"src\":src_field, \"tgt\":tgt_field})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = corpus_to_array(\"datasets/all.desc\", \"datasets/all.code\")\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max src length: 586\n",
      "Max tgt length: 1087\n"
     ]
    }
   ],
   "source": [
    "print(\"Max src length:\", max([len(string_split(src)) for src, tgt in data]))\n",
    "print(\"Max tgt length:\", max([len(string_split(tgt)) for src, tgt in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 18805\n",
      "Limited dataset size: 18781\n"
     ]
    }
   ],
   "source": [
    "print(\"Full dataset size:\", len(data))\n",
    "max_seq_length=200\n",
    "data = filter_corpus(data, max_seq_length=200, tokenizer=string_split)\n",
    "print(\"Limited dataset size:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "TGT_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "\n",
    "dataset = samples_to_dataset(data, SRC_TEXT, TGT_TEXT)\n",
    "\n",
    "train_dataset, val_dataset = dataset.split([0.9,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging dataset\n",
    "This will be a small dataset of only 3 or 4 sentences to ensure the model can overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_data = [\n",
    "#     (\"my favourite foods are banana and toast\",\"would you like banana and toast ?\"),\n",
    "#     (\"my favourite foods are eggs and bacon and beans\",\"would you like eggs and bacon and beans ?\"),\n",
    "#     (\"my favourite food is chocolate\",\"would you like chocolate ?\"),\n",
    "#     (\"my favourite food is avocado\",\"would you like avocado ?\")\n",
    "# ]\n",
    "\n",
    "# other_data = [\n",
    "#     (\"what age is she ?\", \"she is 8 years old\"),\n",
    "#     (\"what age is he ?\", \"he is 4 years old\"),\n",
    "#     (\"how old are you ?\", \"i am 22 years old\"),\n",
    "#     (\"how old am i ?\", \"you are 28 years old\")\n",
    "# ]\n",
    "\n",
    "# SRC_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "# TGT_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "\n",
    "# train_dataset = val_dataset = samples_to_dataset(other_data, SRC_TEXT, TGT_TEXT)\n",
    "\n",
    "# # train_dataset, val_dataset = dataset.split([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(0) # choose GPU from nvidia-smi \n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if -> 15\n",
      "match -> 181\n",
      "is -> 11\n",
      "true -> 53\n",
      ", -> 6\n"
     ]
    }
   ],
   "source": [
    "SRC_TEXT.build_vocab(train_dataset)\n",
    "TGT_TEXT.build_vocab(train_dataset)\n",
    "\n",
    "\n",
    "sample = dataset[2].src\n",
    "for tok, id in zip(sample, SRC_TEXT.numericalize([sample])):\n",
    "    print(\"{} -> {}\".format(tok, id.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', 'call', 'the', 'method', 'self', '.', '_', 'render', 'with', 'an', 'argument', 'context', ',', 'return', 'the', 'result', ',', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[  2  19   7  16  10   4   5 179   9  12  20  92   6  28   7  22   6   3\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1]\n",
      "[  2  18  12   5   4 139   6  57   7   3   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_iterator = BucketIterator(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    repeat=True,\n",
    "#     shuffle=True,\n",
    "    sort_key = lambda x: len(x.src)+len(x.tgt),\n",
    "    device = device)\n",
    "\n",
    "valid_iterator = BucketIterator(val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    sort_key = lambda x: len(x.src)+len(x.tgt),\n",
    "    device = device)\n",
    "\n",
    "# The iterator generates batches with padded length for sequences with similar sizes, a batch is [seq_length, batch_size]\n",
    "\n",
    "for i, batch in enumerate(train_iterator):\n",
    "    idx = 0\n",
    "    print([SRC_TEXT.vocab.itos[id] for id in batch.src.cpu().numpy()[:,idx]])\n",
    "    print(batch.src.cpu().numpy()[:,idx])\n",
    "    print(batch.tgt.cpu().numpy()[:,idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample transformer without positional encoding, it uses the built in transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_transformer_model = nn.Transformer() # uses default hyperparameters\n",
    "src = torch.rand((10, 32, 512)) # [src_seq_length, batch_size, embedding_size]\n",
    "tgt = torch.rand((20, 32, 512)) # [tgt_seq_length, batch_size, embedding_size]\n",
    "rand_transformer_model(src, tgt).shape # [tgt_seq_length, batch_size, embedding_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, embedding_size=512, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.pos_encoder = PositionalEncoding(embedding_size, dropout)\n",
    "        self.src_encoder = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.tgt_encoder = nn.Embedding(tgt_vocab_size, embedding_size)\n",
    "        \n",
    "        self.transformer = nn.Transformer(d_model=embedding_size, nhead=8, num_encoder_layers=4, num_decoder_layers=4, dim_feedforward=1024)\n",
    "        self.decoder = nn.Linear(embedding_size, tgt_vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "        self.tgt_mask = None\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        noise_e = 0.05 if self.training else 0.0\n",
    "        noise_mask = (torch.rand(sz,sz) > noise_e).float()\n",
    "\n",
    "        mask = (torch.triu(torch.ones(sz,sz))).transpose(0, 1)\n",
    "        mask = torch.mul(mask, noise_mask)\n",
    "        v = (torch.sum(mask, dim=-1) == 0).float()\n",
    "\n",
    "        fix_mask = torch.zeros(sz,sz)\n",
    "        fix_mask[:,0] = 1.0\n",
    "        v = v.repeat(sz, 1).transpose(0,1)\n",
    "        fix_mask = torch.mul(fix_mask,v)\n",
    "\n",
    "        mask += fix_mask\n",
    "        \n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.src_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.tgt_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        self.tgt_mask = self._generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "\n",
    "        src = self.src_encoder(src) * math.sqrt(self.embedding_size)\n",
    "        src = self.pos_encoder(src)\n",
    "        \n",
    "        tgt = self.tgt_encoder(tgt) * math.sqrt(self.embedding_size)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        \n",
    "        output = self.transformer(src, tgt, tgt_mask=self.tgt_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(SRC_TEXT.vocab.itos)\n",
    "tgt_vocab_size = len(TGT_TEXT.vocab.itos)\n",
    "\n",
    "model = TransformerModel(src_vocab_size, tgt_vocab_size, dropout=0.2).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., -inf]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._generate_square_subsequent_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [-inf, 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, 0., -inf, -inf, 0., -inf, 0., -inf, -inf],\n",
       "        [0., -inf, -inf, -inf, 0., -inf, 0., -inf, 0., -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, 0., 0.]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_e = 0.5\n",
    "noise_mask = (torch.rand(10,10) > noise_e).float()\n",
    "\n",
    "mask = (torch.triu(torch.ones(10,10))).transpose(0, 1)\n",
    "mask = torch.mul(mask, noise_mask)\n",
    "v = (torch.sum(mask, dim=-1) == 0).float()\n",
    "\n",
    "fix_mask = torch.zeros(10,10)\n",
    "fix_mask[:,0] = 1.0\n",
    "v = v.repeat(10, 1).transpose(0,1)\n",
    "fix_mask = torch.mul(fix_mask,v)\n",
    "\n",
    "print(fix_mask)\n",
    "mask += fix_mask\n",
    "\n",
    "\n",
    "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [-inf, 0., 0., 0.],\n",
       "        [-inf, -inf, 0., 0.],\n",
       "        [-inf, -inf, -inf, 0.]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.generate_square_subsequent_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([float('-inf'),0])).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 8, 4207])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.randint(0, src_vocab_size, (10,8), device=device) # [src_seq_length, batch_size]\n",
    "tgt = torch.randint(0, tgt_vocab_size, (33,8), device=device) # [src_seq_length, batch_size]\n",
    "model(src, tgt).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.1908, -2.1908, -3.1908, -0.1908, -4.1908])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,4,3,6,2.0]).softmax(0).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_batch_ids(encoder_input, max_seq_length=50):\n",
    "    batch_len = encoder_input.shape[1]\n",
    "    sos_id = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "    decoder_input = torch.zeros((1, batch_len), dtype=torch.long, device=device).fill_(sos_id)\n",
    "\n",
    "    for i in range(max_seq_length):\n",
    "        output = model(encoder_input, decoder_input)\n",
    "        last_pred = output[-1:].argmax(dim=2)\n",
    "\n",
    "        decoder_input = torch.cat((decoder_input, last_pred))\n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [2., 2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1.0],\n",
    "                  [2.0]]).repeat(1,2)\n",
    "b = torch.tensor([[1.0,2.0],\n",
    "                  [1.0,2.0]])\n",
    "print(a)\n",
    "b.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 7.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[5.0,7.0,3.0],\n",
    "                  [2.0,3.0,4.0]])\n",
    "b_idx = b.argsort(1)[:,-2:]\n",
    "b.gather(1,b_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids: tensor([[   2,    2],\n",
      "        [ 271,   15],\n",
      "        [   0,  117],\n",
      "        [   3, 1518],\n",
      "        [   1,    3]])\n",
      "log_probs: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "tiled input: tensor([[   2,    2,    2,    2,    2,    2],\n",
      "        [ 271,  271,  271,   15,   15,   15],\n",
      "        [   0,    0,    0,  117,  117,  117],\n",
      "        [   3,    3,    3, 1518, 1518, 1518],\n",
      "        [   1,    1,    1,    3,    3,    3]])\n",
      "torch.Size([1, 6, 4196])\n",
      "last_pred shape: torch.Size([6, 4196])\n",
      "seq_log_probs: tensor([[-10.9749,  -8.4252, -10.7930,  ...,  -8.4562,  -8.7751,  -8.7048],\n",
      "        [ -9.2391,  -9.4896,  -8.7537,  ...,  -9.3992,  -8.6489,  -6.1317],\n",
      "        [-10.4374,  -9.0119,  -8.4563,  ...,  -9.1136, -10.5199,  -6.4578],\n",
      "        [-10.4443,  -9.5569,  -9.3474,  ...,  -8.7429, -10.6198,  -7.0008],\n",
      "        [-11.9398,  -7.6896,  -9.4280,  ...,  -7.6372, -10.3096,  -9.0570],\n",
      "        [-10.7753,  -9.1955,  -9.1317,  ...,  -9.2729, -11.1479,  -8.9438]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "seq_log_probs_positions: tensor([[ 6697, 10623,  1265],\n",
      "        [10779,   542,  6583]])\n",
      "next_ids: tensor([[2501, 2231, 1265, 2387,  542, 2387]])\n",
      "log_probs: tensor([[-4.7701],\n",
      "        [-4.7349],\n",
      "        [-4.3399],\n",
      "        [-4.4040],\n",
      "        [-4.2969],\n",
      "        [-3.6838]], grad_fn=<ViewBackward>)\n",
      "torch.Size([2, 6, 4196])\n",
      "last_pred shape: torch.Size([6, 4196])\n",
      "seq_log_probs: tensor([[-14.3618, -13.8222, -14.1566,  ..., -13.3719, -13.0708, -13.3050],\n",
      "        [-14.6221, -14.9706, -14.4076,  ..., -13.1165, -15.0555, -13.2518],\n",
      "        [-14.2188, -12.2580, -12.2811,  ..., -12.4456, -14.3353, -13.2288],\n",
      "        [-13.2009, -14.1101, -12.9069,  ..., -14.3602, -14.9344, -14.1599],\n",
      "        [-15.5427, -13.2028, -14.1095,  ..., -14.1563, -14.2546, -13.1712],\n",
      "        [-14.9194, -12.3000, -11.4901,  ..., -13.7021, -13.6924,  -8.8790]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "seq_log_probs_positions: tensor([[ 9145,  6509,  9565],\n",
      "        [ 9130,  6583, 11101]])\n",
      "next_ids: tensor([[ 753, 2313, 1173,  738, 2387, 2709]])\n",
      "log_probs: tensor([[-8.8981],\n",
      "        [-8.7516],\n",
      "        [-8.3622],\n",
      "        [-8.4273],\n",
      "        [-8.1952],\n",
      "        [-8.1347]], grad_fn=<ViewBackward>)\n",
      "torch.Size([3, 6, 4196])\n",
      "last_pred shape: torch.Size([6, 4196])\n",
      "seq_log_probs: tensor([[-17.6577, -18.5810, -18.1271,  ..., -17.2702, -18.4681, -17.3731],\n",
      "        [-18.3470, -17.6577, -16.7566,  ..., -16.0250, -17.4561, -19.5650],\n",
      "        [-18.7763, -17.3153, -17.7805,  ..., -18.1693, -18.1628, -16.2486],\n",
      "        [-19.2158, -15.7353, -16.7472,  ..., -17.5233, -17.6515, -17.4532],\n",
      "        [-17.0428, -18.0629, -17.7137,  ..., -18.5685, -17.7765, -16.0703],\n",
      "        [-18.3208, -18.1748, -18.3089,  ..., -17.0971, -18.8445, -16.5090]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "seq_log_probs_positions: tensor([[ 9576, 11051,  9077],\n",
      "        [ 6451,  2387, 10779]])\n",
      "next_ids: tensor([[1184, 2659,  685, 2255, 2387, 2387]])\n",
      "log_probs: tensor([[-13.4697],\n",
      "        [-13.3791],\n",
      "        [-12.6018],\n",
      "        [-12.8693],\n",
      "        [-12.2372],\n",
      "        [-12.1839]], grad_fn=<ViewBackward>)\n",
      "torch.Size([4, 6, 4196])\n",
      "last_pred shape: torch.Size([6, 4196])\n",
      "seq_log_probs: tensor([[-22.2028, -21.7787, -23.0362,  ..., -22.8894, -22.3342, -23.1888],\n",
      "        [-23.5649, -22.0110, -21.5560,  ..., -22.2390, -21.0840, -21.5034],\n",
      "        [-21.9414, -22.7662, -20.7369,  ..., -22.2519, -22.4958, -20.3073],\n",
      "        [-22.3965, -20.2567, -22.2948,  ..., -21.8127, -22.2231, -20.7367],\n",
      "        [-22.0022, -21.0491, -21.9454,  ..., -22.1261, -21.5252, -20.6872],\n",
      "        [-22.9640, -20.9223, -21.4211,  ..., -22.0753, -22.4617, -20.4266]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "seq_log_probs_positions: tensor([[ 3845, 11378, 10705],\n",
      "        [ 4988,  6583,  8885]])\n",
      "next_ids: tensor([[3845, 2986, 2313,  792, 2387,  493]])\n",
      "log_probs: tensor([[-17.2893],\n",
      "        [-17.2528],\n",
      "        [-16.7121],\n",
      "        [-17.0329],\n",
      "        [-16.9462],\n",
      "        [-16.9279]], grad_fn=<ViewBackward>)\n",
      "torch.Size([5, 6, 4196])\n",
      "last_pred shape: torch.Size([6, 4196])\n",
      "seq_log_probs: tensor([[-25.8543, -26.6343, -26.8584,  ..., -27.4113, -27.1792, -23.5644],\n",
      "        [-28.4390, -26.3109, -25.9419,  ..., -25.6461, -28.0712, -26.6421],\n",
      "        [-27.9527, -26.5442, -24.4066,  ..., -26.9180, -27.6399, -24.2331],\n",
      "        [-26.7350, -25.7973, -26.1867,  ..., -25.8761, -26.8943, -26.0871],\n",
      "        [-26.0252, -25.6787, -26.6788,  ..., -25.3495, -24.2620, -25.7953],\n",
      "        [-26.1944, -25.5608, -25.9324,  ..., -25.5693, -27.0709, -24.6066]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "seq_log_probs_positions: tensor([[10895,  8896, 11951],\n",
      "        [10779,  5632,  2313]])\n",
      "next_ids: tensor([[2503,  504, 3559, 2387, 1436, 2313]])\n",
      "log_probs: tensor([[-21.6836],\n",
      "        [-21.6064],\n",
      "        [-20.7711],\n",
      "        [-21.5013],\n",
      "        [-21.2426],\n",
      "        [-20.8927]], grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    2,    2,    2,    2,    2],\n",
       "        [2387, 2387,  542, 2387,  542, 2387],\n",
       "        [ 738,  738, 2387,  738, 2387, 2709],\n",
       "        [2255, 2255, 2387, 2255, 2387, 2387],\n",
       "        [2313, 2313, 2387,  792, 2387,  493],\n",
       "        [2503,  504, 3559, 2387, 1436, 2313]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def beam_search_decode_batch_ids(encoder_input, beam_size=3, max_seq_length=50):\n",
    "    batch_len = encoder_input.shape[1]\n",
    "    sos_id = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "    decoder_input = torch.zeros((1, beam_size * batch_len), dtype=torch.long, device=device).fill_(sos_id)\n",
    "    log_probs = torch.zeros((beam_size * batch_len,1))\n",
    "    print(\"log_probs:\", log_probs)\n",
    "    vocab_size = len(TGT_TEXT.vocab.itos)\n",
    "    \n",
    "    encoder_input = encoder_input.view(-1,1).repeat(1,beam_size).view(-1,beam_size * batch_len) # this tiles the input to the beam size * batch size\n",
    "    print(\"tiled input:\", encoder_input)\n",
    "    \n",
    "    for i in range(max_seq_length):\n",
    "        output = model(encoder_input, decoder_input)\n",
    "        print(output.shape)\n",
    "        last_pred = output[-1].softmax(1)\n",
    "        print(\"last_pred shape:\", last_pred.shape)\n",
    "        log_predictions = last_pred.log()\n",
    "        seq_log_probs = log_predictions + log_probs.repeat(1,vocab_size)\n",
    "        print(\"seq_log_probs:\", seq_log_probs)\n",
    "        \n",
    "        seq_log_probs_positions = seq_log_probs.view(batch_len,-1).argsort(1)[:,-beam_size:]\n",
    "        print(\"seq_log_probs_positions:\", seq_log_probs_positions)\n",
    "        next_ids = seq_log_probs_positions.reshape(1, batch_len*beam_size) % vocab_size\n",
    "        print(\"next_ids:\", next_ids)\n",
    "        log_probs = seq_log_probs.view(batch_len,-1).gather(1,seq_log_probs_positions).view(beam_size * batch_len,1)\n",
    "        print(\"log_probs:\",log_probs)\n",
    "        \n",
    "        for batch_idx in range(seq_log_probs_positions.shape[0]):\n",
    "            for seq_choice_idx in range(seq_log_probs_positions.shape[1]):\n",
    "                seq_choice = seq_log_probs_positions[batch_idx,seq_choice_idx] // vocab_size\n",
    "                decoder_input[:,batch_idx*batch_len + seq_choice_idx] = decoder_input[:,batch_idx*batch_len + seq_choice]\n",
    "        \n",
    "        decoder_input = torch.cat((decoder_input, next_ids))\n",
    "    return decoder_input\n",
    "        \n",
    "#         last_pred = output[-1].argsort(dim=1)[:,:beam_size]\n",
    "\n",
    "sent1 = [\"<sos>\"] + SRC_TEXT.preprocess(\"create array\") + [\"<eos>\"] + [\"<pad>\"]\n",
    "sent2 = [\"<sos>\"] + SRC_TEXT.preprocess(\"if exists then\") + [\"<eos>\"]\n",
    "src_ids = SRC_TEXT.numericalize([sent1, sent2], device=device)\n",
    "print(\"input ids:\", src_ids)\n",
    "beam_search_decode_batch_ids(src_ids, max_seq_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2740311596835683"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nltk_bleu(refrence, prediction):\n",
    "    \"\"\"\n",
    "    Implementation from ReCode\n",
    "    and moses multi belu script sets BLEU to 0.0 if len(toks) < 4\n",
    "    \"\"\"\n",
    "    ngram_weights = [0.25] * min(4, len(refrence))\n",
    "    return sentence_bleu([refrence], prediction, weights=ngram_weights, \n",
    "                          smoothing_function=SmoothingFunction().method3)\n",
    "\n",
    "nltk_bleu(np.array([1,2,3,4,5,6]), np.array([1,2,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        sources = []\n",
    "        results = []\n",
    "        targets = []\n",
    "        BLEU_scores = []\n",
    "        for i, batch in enumerate(valid_iterator):\n",
    "            encoder_inputs = batch.src\n",
    "            target = batch.tgt\n",
    "            predictions = greedy_decode_batch_ids(encoder_inputs, max_seq_length=20)\n",
    "            \n",
    "            sources += encoder_inputs.transpose(0,1).cpu().tolist()\n",
    "            results += predictions.transpose(0,1).cpu().tolist()\n",
    "            targets += target.transpose(0,1).cpu().tolist()\n",
    "            if i % 50 == 0:\n",
    "                print(\"| EVALUATION | {:5d}/{:5d} batches |\".format(i, len(valid_iterator)))\n",
    "        \n",
    "        for r_ids, target in zip(results, targets):\n",
    "            eos_id = TGT_TEXT.vocab.stoi[\"<eos>\"]\n",
    "            eos_index = r_ids.index(eos_id) if eos_id in r_ids else None\n",
    "            cut_ids = r_ids[:eos_index]\n",
    "            filtered_ids = [id for id in cut_ids if id not in [0,1,2,3]]\n",
    "            filtered_target_ids = [id for id in target if id not in [0,1,2,3]]\n",
    "            BLEU_scores.append(nltk_bleu(filtered_target_ids, filtered_ids))\n",
    "        \n",
    "        with open(\"out.txt\", \"w\") as out_fp:\n",
    "            for source, result, target, BLEU in zip(sources, results, targets, BLEU_scores):\n",
    "                eos_id = TGT_TEXT.vocab.stoi[\"<eos>\"]\n",
    "                eos_index = result.index(eos_id) if eos_id in result else None\n",
    "                cut_ids = result[:eos_index]\n",
    "                filtered_ids = [id for id in cut_ids if id not in [0,1,2,3]]\n",
    "                filtered_target_ids = [id for id in target if id not in [0,1,2,3]]\n",
    "                filtered_source_ids = [id for id in source if id not in [0,1,2,3]]\n",
    "                \n",
    "                out_fp.write(\"SRC  :\" + \" \".join([SRC_TEXT.vocab.itos[id] for id in filtered_source_ids]) + \"\\n\")\n",
    "                out_fp.write(\"TGT  :\" + \" \".join([TGT_TEXT.vocab.itos[id] for id in filtered_target_ids]) + \"\\n\")\n",
    "                out_fp.write(\"PRED :\" + \" \".join([TGT_TEXT.vocab.itos[id] for id in filtered_ids]) + \"\\n\")\n",
    "                out_fp.write(\"BLEU :\" + str(BLEU) + \"\\n\")\n",
    "                out_fp.write(\"\\n\")\n",
    "                \n",
    "        print(\"| EVALUATION | BLEU: {:5.2f} |\".format(np.average(BLEU_scores)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    tgt_vocab_size = len(TGT_TEXT.vocab.itos)\n",
    "    encoder_input = batch.src\n",
    "    decoder_input = batch.tgt[:-1]\n",
    "    targets = batch.tgt[1:]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(encoder_input, decoder_input)\n",
    "\n",
    "    loss = criterion(output.view(-1, tgt_vocab_size), targets.view(-1))\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "    elapsed = time.time() - start_time\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=TGT_TEXT.vocab.stoi['<pad>'])\n",
    "lr = 0.005 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   200/1000000 steps | lr 0.0002 | ms/batch 46.86 | loss  1.41 | ppl     4.09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-de448cca1a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-217-de448cca1a5b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(steps, log_interval, learning_interval, eval_interval)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-207-3990ec8c4976>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-196-ee238fd2c1da>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    119\u001b[0m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001b[1;32m    120\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                               memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    226\u001b[0m                                     \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                                     \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                                     memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[1;32m    350\u001b[0m         tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n\u001b[0;32m--> 351\u001b[0;31m                               key_padding_mask=tgt_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3195\u001b[0m     \"\"\"\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3197\u001b[0;31m     \u001b[0mqkv_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3198\u001b[0m     \u001b[0mkv_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(steps=10000, log_interval=200, learning_interval=4000, eval_interval=1000):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    step = 1\n",
    "    for batch in train_iterator:\n",
    "        loss = train_step(batch)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if step % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| {:5d}/{:5d} steps | '\n",
    "                  'lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    step, steps, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "        if step % eval_interval == 0:\n",
    "            print(\"Evaluating model\")\n",
    "            evaluate()\n",
    "            model.train()\n",
    "        \n",
    "        if step % learning_interval == 0:\n",
    "            scheduler.step()\n",
    "        \n",
    "        step += 1\n",
    "        if step >= steps:\n",
    "            print(\"Finished training\")\n",
    "            return\n",
    "\n",
    "train(steps=1000000,eval_interval=8000,log_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> substitute args for self . _ _ args . <eos>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([SRC_TEXT.vocab.itos[i] for i in [ 2,21,83,13,10, 4, 5, 5,83, 4, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> self . _'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([TGT_TEXT.vocab.itos[i] for i in [ 2,12,5,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC ids shape: tensor([[  2],\n",
      "        [ 72],\n",
      "        [ 25],\n",
      "        [ 17],\n",
      "        [301],\n",
      "        [  4],\n",
      "        [  3]], device='cuda:0')\n",
      "output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> output: tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
      "<unk> "
     ]
    }
   ],
   "source": [
    "def translate(s):\n",
    "    src_ids = SRC_TEXT.numericalize([[\"<sos>\"] + SRC_TEXT.preprocess(s) + [\"<eos>\"]], device=device)\n",
    "#     src_ids = torch.tensor([ [2],[21],[83],[13],[10], [4], [5], [5],[83], [4], [3]], device=device)\n",
    "    print(\"SRC ids shape:\",src_ids)\n",
    "    model.eval\n",
    "    with torch.no_grad():\n",
    "        sos_id = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "#         decoder_input = torch.zeros((1, 1), dtype=torch.long, device=device).fill_(sos_id)\n",
    "        decoder_input = torch.tensor(np.array([ [2]]), device=device)\n",
    "#         print(\"Decoder input shape:\", decoder_input.shape)\n",
    "        \n",
    "        for i in range(10):\n",
    "#             print(\"Decoder input\", decoder_input)\n",
    "            output = model(src_ids, decoder_input)\n",
    "#             print(model.tgt_mask)\n",
    "            print(\"output:\", output)\n",
    "#             print(\"predicted ids:\", output.argmax(dim=-1))\n",
    "            last_pred = output[-1:].argmax(dim=2)\n",
    "#             decoder_input[i+1][0] = last_pred\n",
    "#             print(\"last pred:\", TGT_TEXT.vocab.itos[last_pred.cpu().numpy()[0][0]], last_pred.cpu().numpy()[0][0])\n",
    "            print(TGT_TEXT.vocab.itos[last_pred.cpu().numpy()[0][0]],'', end = '')\n",
    "            \n",
    "            decoder_input = torch.cat((decoder_input, last_pred))\n",
    "#             print(\"Decoder input\", decoder_input)\n",
    "#             break\n",
    "\n",
    "translate(\"append value to results .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([torch.tensor([1.0]),torch.tensor([2.0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moses Multi-BLEU perl script returns 0.0 for any sentence less than 4 tokens long.\n",
    "It will be best to use a function by NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_moses_multi_bleu([\"this is a test\"], [\"this is a for\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
