{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
    "from io import BytesIO\n",
    "\n",
    "import linecache\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories already exists\n",
      "--2019-10-21 09:39:50--  https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.anno\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1382085 (1.3M) [text/plain]\n",
      "Saving to: './datasets/all.desc'\n",
      "\n",
      "./datasets/all.desc 100%[===================>]   1.32M  5.00MB/s    in 0.3s    \n",
      "\n",
      "2019-10-21 09:39:51 (5.00 MB/s) - './datasets/all.desc' saved [1382085/1382085]\n",
      "\n",
      "--2019-10-21 09:39:51--  https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.code\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 906732 (885K) [text/plain]\n",
      "Saving to: './datasets/all.code'\n",
      "\n",
      "./datasets/all.code 100%[===================>] 885.48K  4.02MB/s    in 0.2s    \n",
      "\n",
      "2019-10-21 09:39:52 (4.02 MB/s) - './datasets/all.code' saved [906732/906732]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"./datasets\")\n",
    "except FileExistsError:\n",
    "    print(\"Directories already exists\")\n",
    "\n",
    "# getting descriptions\n",
    "!wget https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.anno -O ./datasets/all.desc\n",
    "\n",
    "# getting code\n",
    "!wget https://raw.githubusercontent.com/odashi/ase15-django-dataset/master/django/all.code -O ./datasets/all.code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a token text encoder\n",
    "An encoder will take a file and a splitting function and return an object able to encode and decode a string. It will also be able to save a vocab file and retrieve from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['append', 'rel_to', 'to', 'string', \"'\", 'ForeignKey', ',', '(', 'substitute', 'the', 'result', 'for', 'field_type', '.', ')']\n"
     ]
    }
   ],
   "source": [
    "text = \" append rel_to to string 'ForeignKey, (substitute the result for field_type.)\"\n",
    "\n",
    "# looks like code split need parenthesis to be matched in the same string, if not it gives an error...\n",
    "def code_split(s):\n",
    "    return [x.string for x in tokenize(BytesIO(s.encode('utf-8')).readline) if x.string != '' and x.string != \"\\n\" and not x.string.isspace()][1:]\n",
    "\n",
    "print(code_split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['append', 'rel', '_', 'to', 'to', 'string', \"'\", 'ForeignKey', ',', '(', 'subs', '_', '_', 'titute', 'the', 'result', \"'\", 'for', 'field', '_', 'type', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \" append rel_to to string 'ForeignKey, (subs__titute the result' for field_type.\"\n",
    "\n",
    "def string_split(s):\n",
    "    return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(_|\\W)', s))) # this will chunk all code properly by plits strings with quotes\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|_|\\W)', s))) # this keeps the strings intact\n",
    "\n",
    "print(string_split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    def __init__(self, vocab_size=sys.maxsize, tokenizer=str.split, vocab=[]):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.t2id = {}\n",
    "        vocab.append(\"<UNK>\")\n",
    "        for tok in vocab:\n",
    "            self.t2id[tok] = len(self.t2id)\n",
    "        self.id2t = {v:k for k,v in self.t2id.items()}\n",
    "    \n",
    "    def encode(self,s):\n",
    "        ids = []\n",
    "        for tok in self.tokenizer(s):\n",
    "            if tok in self.t2id:\n",
    "                ids.append(self.t2id[tok])\n",
    "            else:\n",
    "                ids.append(self.t2id[\"<UNK>\"])\n",
    "        return ids\n",
    "        \n",
    "    def decode(self,arr):\n",
    "        return [self.id2t[id] for id in arr]\n",
    "    \n",
    "    def vocab_size(self):\n",
    "        return len(self.id2t)\n",
    "        \n",
    "    def build_vocab_from_corpus(self,fp):\n",
    "        from collections import Counter\n",
    "        all_toks = []\n",
    "        with open(fp, \"r\") as corpus_file:\n",
    "            for line in corpus_file.readlines():\n",
    "                for tok in self.tokenizer(line):\n",
    "                    all_toks.append(tok)\n",
    "        counter = Counter(all_toks)\n",
    "        unique_toks = [x for _,x in sorted(zip(counter.values(),counter.keys()))][::-1][:self.vocab_size]\n",
    "        for tok in unique_toks:\n",
    "            self.t2id[tok] = len(self.t2id)\n",
    "        self.id2t = {v:k for k,v in self.t2id.items()}\n",
    "        \n",
    "                \n",
    "        \n",
    "    def save_vocab(self,fp):\n",
    "        with open(fp, \"w\") as vocab_file:\n",
    "            for i in range(len(self.id2t)):\n",
    "                vocab_file.write(self.id2t[i]+\"\\n\")\n",
    "            \n",
    "        \n",
    "    def load_vocab(self,fp):\n",
    "        self.t2id = {}\n",
    "        with open(fp, \"r\") as vocab_file:\n",
    "            for line in vocab_file.readlines():\n",
    "                tok = line[:-1]\n",
    "                self.t2id[tok] = len(self.t2id)\n",
    "        self.id2t = {v:k for k,v in self.t2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(vocab=[\"<PAD>\", \"<START>\", \"<END>\"], tokenizer=string_split)\n",
    "tokenizer_code = Tokenizer(vocab=[\"<PAD>\", \"<START>\", \"<END>\"], tokenizer=string_split) # turns out this works well for code too\n",
    "\n",
    "tokenizer_en.build_vocab_from_corpus(\"./datasets/all.desc\")\n",
    "tokenizer_code.build_vocab_from_corpus(\"./datasets/all.code\")\n",
    "\n",
    "tokenizer_en.save_vocab(\"./desc_vocab.txt\")\n",
    "tokenizer_code.save_vocab(\"./code_vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[315, 34, 45, 9, 509, 894, 2183]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.encode(\"make a list with 10 random numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['make', 'a', 'list', 'with', '10', 'random', 'numbers']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.decode([315, 34, 45, 9, 509, 894, 2183])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_array(src_fp, tgt_fp):\n",
    "    lines = []\n",
    "    with open(src_fp, \"r\") as src_file, open(tgt_fp, \"r\") as tgt_file:\n",
    "        for src, tgt in zip(src_file, tgt_file):\n",
    "            lines.append((src, tgt))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_array(fp):\n",
    "    lines = []\n",
    "    with open(fp, \"r\") as file:\n",
    "        for line in file:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = corpus_to_array(\"datasets/all.desc\", \"datasets/all.code\")\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(data, batch_size):\n",
    "    return [pad_to_dense(list(t)) for t in zip(*[iter(data)]*batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fromlist() missing 1 required positional argument: 'fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9826275ae4ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msrc_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/all.desc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtgt_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/all.code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fromlist() missing 1 required positional argument: 'fields'"
     ]
    }
   ],
   "source": [
    "SRC = Field(tokenize = string_split,\n",
    "            tokenizer_language=\"desc\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>')\n",
    "\n",
    "TGT = Field(tokenize = string_split,\n",
    "            tokenizer_language=\"code\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>')\n",
    "fields = [\n",
    "    (\"desc\",SRC),\n",
    "    (\"code\",TGT)\n",
    "]\n",
    "\n",
    "src_txt = torchtext.data.Example.fromlist(file_to_array(\"datasets/all.desc\"))\n",
    "tgt_txt = torchtext.data.Example.fromlist(file_to_array(\"datasets/all.code\"))\n",
    "\n",
    "dataset = torchtext.data.Dataset(data, fields)\n",
    "train_data, valid_data = dataset.split()\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src = [tokenizer_en.encode(x[0]) for x in data[:16000]]\n",
    "train_tgt = [tokenizer_code.encode(x[1]) for x in data[:16000]]\n",
    "\n",
    "test_src = [tokenizer_en.encode(x[0]) for x in data[16000:17000]]\n",
    "test_tgt = [tokenizer_code.encode(x[1]) for x in data[16000:17000]]\n",
    "             \n",
    "val_src = [tokenizer_en.encode(x[0]) for x in data[17000:]]\n",
    "val_tgt = [tokenizer_code.encode(x[1]) for x in data[17000:]]\n",
    "\n",
    "# batch_size = 2\n",
    "\n",
    "# train_src = batch(train_src,batch_size)\n",
    "# train_tgt = batch(train_tgt,batch_size)\n",
    "\n",
    "# test_src = batch(test_src,batch_size)\n",
    "# test_tgt = batch(test_tgt,batch_size)\n",
    "          \n",
    "# val_src =  batch(val_src,batch_size)\n",
    "# val_tgt =  batch(val_tgt,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_dataset(samples, src_field, tgt_field):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samples: [(src_string),(tgt_string)]\n",
    "        src/tgt_tokenizer: a func that takes a string and returns an array of strings\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        src_string, tgt_string = sample\n",
    "        examples.append(torchtext.data.Example.fromdict({\"src\":src_string, \"tgt\":tgt_string}, \n",
    "                                        fields={\"src\":(\"src\",src_field), \"tgt\":(\"tgt\",tgt_field)}))\n",
    "        \n",
    "    dataset = torchtext.data.Dataset(examples,fields={\"src\":src_field, \"tgt\":tgt_field})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>', lower=False)\n",
    "TGT_TEXT = Field(sequential=True, init_token='<sos>',eos_token='<eos>')\n",
    "\n",
    "dataset = samples_to_dataset(data, SRC_TEXT, TGT_TEXT)\n",
    "\n",
    "train_dataset, val_dataset = dataset.split([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ -> 5\n",
      "response -> 177\n",
      "_ -> 5\n",
      "middleware -> 325\n",
      "is -> 11\n",
      "an -> 12\n",
      "empty -> 54\n",
      "list -> 45\n",
      ". -> 4\n"
     ]
    }
   ],
   "source": [
    "SRC_TEXT.build_vocab(train_dataset)\n",
    "TGT_TEXT.build_vocab(train_dataset)\n",
    "\n",
    "\n",
    "sample = dataset[0].src\n",
    "for tok, id in zip(sample, SRC_TEXT.numericalize([sample], device)):\n",
    "    print(\"{} -> {}\".format(tok, id.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 112x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 28x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 67x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 35x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 229x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 89x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 51x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 53x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 62x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 73x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 175x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 71x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 60x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 70x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 90x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 38x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 51x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 95x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 69x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 51x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 70x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 35x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 45x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 50x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 60x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 44x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 52x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 32x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 50x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 44x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 53x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 54x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 78x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 107x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 51x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 32x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 90x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 225x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 202x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 39x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 56x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 46x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 67x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 39x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 77x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 48x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 87x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 48x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 103x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 42x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 125x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 49x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 70x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 42x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 61x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 75x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 88x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 51x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 53x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 44x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 51x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 38x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 61x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 60x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 65x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 34x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 45x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 26x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 66x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 31x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 129x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 52x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 108x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 45x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 85x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 45x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 100x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 39x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 46x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 31x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 48x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 44x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 54x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 60x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 139x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 54x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 104x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 150x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 102x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 92x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 75x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 31x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 567x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 29x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 62x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 36x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 53x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 65x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 49x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 54x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 59x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 41x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 78x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 40x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 246x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 52x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 65x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 89x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 116x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 46x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 57x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 52x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 69x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 57x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 67x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 49x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 86x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 58x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 53x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 39x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 145x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 36x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 50x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 28x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 52x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 42x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 62x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 59x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 223x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 125x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 64x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 47x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 64x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 29x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 80x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 34x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 93x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 35x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 305x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 125x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 53x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 34x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 98x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 46x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 79x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 26x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 110x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 306x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 91x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 58x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 82x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 41x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 145x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 49x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 61x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 43x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 81x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 37x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 72x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 56x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 89x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 43x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 83x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 39x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 56x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 37x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 162x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 171x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 70x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 35x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 50x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 36x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 48x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 40x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 86x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 50x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 66x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 28x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 158x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 42x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 68x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 74x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 425x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 38x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 113x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 44x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 66x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 52x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 69x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 76x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 75x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 36x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 82x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 35x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 71x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 529x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 86x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 34x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 146x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 44x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 108]\n",
      "\t[.src]:[torch.LongTensor of size 163x108]\n",
      "\t[.tgt]:[torch.LongTensor of size 33x108]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 62x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 42x128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 64x128]\n",
      "\t[.tgt]:[torch.LongTensor of size 33x128]\n"
     ]
    }
   ],
   "source": [
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "    (train_dataset, val_dataset),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)\n",
    "\n",
    "for i, batch in enumerate(train_iterator):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_dense(M):\n",
    "    \"\"\"Appends the minimal required amount of zeroes at the end of each \n",
    "     array in the jagged array `M`, such that `M` looses its jagedness.\"\"\"\n",
    "\n",
    "    maxlen = max(len(r) for r in M)\n",
    "\n",
    "    Z = np.full((len(M), maxlen), 0)\n",
    "    for enu, row in enumerate(M):\n",
    "        Z[enu, :len(row)] += row \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2,3],[1]]\n",
    "pad_to_dense(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_no_padding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-325-646c6a6690e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_no_padding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpadval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_no_padding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_no_padding' is not defined"
     ]
    }
   ],
   "source": [
    "def chunk(it, size, padval=_no_padding):\n",
    "    if padval == _no_padding:\n",
    "        it = iter(it)\n",
    "        sentinel = ()\n",
    "    else:\n",
    "        it = chain(iter(it), repeat(padval))\n",
    "        sentinel = (padval,) * size\n",
    "    return iter(lambda: tuple(islice(it, size)), sentinel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, batch_size):\n",
    "    data = TEXT.numericalize([data.examples[0].text])\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_txt, batch_size)\n",
    "val_data = batchify(val_txt, eval_batch_size)\n",
    "test_data = batchify(test_txt, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
