import random
import re
import copy
import torch
from time import perf_counter
import numpy as np
import tqdm
from pytorch_lightning import seed_everything
from src.FastMCTS import FastMCTS
from torch.utils.data import Dataset, DataLoader
from pytorch_lightning import Trainer, Callback, seed_everything
import string

class Environment():
    def step(self):
        pass
    
    def random_states(self, num_states):
        pass
    
    def to_sting(self):
        pass

class Scratch_Pad_Environment():
    def __init__(self, tokenizer, device='cpu'):
        self.tokenizer = tokenizer
        self.device=device
        self.action_size = len(self.tokenizer.get_vocab())
        
        self.max_token_length = 25
        
        self.EXEC_id = self.tokenizer.get_vocab()['>>>']
        self.NL_id = self.tokenizer.get_vocab()['[NL]']
        self.SP_id = self.tokenizer.get_vocab()['[SP]']
        self.ESP_id = self.tokenizer.get_vocab()['[ESP]']
        self.VALUE_id = self.tokenizer.get_vocab()['[VALUE]']
        self.MASK_id = self.tokenizer.get_vocab()['[MASK]']
        self.EOS_id = self.tokenizer.get_vocab()['[EOS]']
        self.PAD_id = self.tokenizer.get_vocab()['[PAD]']
        
    def getActionSize(self):
        return self.action_size
    
    def validActions(self, current_states):
        N = current_states.shape[0]
        if not hasattr(self, 'pad_vocab_mask'):
            self.pad_vocab_mask = torch.ones(self.action_size, dtype=torch.bool)
            self.pad_vocab_mask[self.PAD_id] = False
        return self.pad_vocab_mask.repeat(N,1)
        
    def step(self, current_states, target_strings, actions):
        '''
        Call to the environment to apply an action to the current states
        
        current_states: tensor([N, seq_len])
        target_states: list of target string states: [N]
        actions: action taken: Long tensor: [N,1]
        
        returns: 
            next_states: long_tensor([N, seq_len])
            rewards: float_tensor([N])
            terminated: bool_tensor([N]), True for terminated states
        '''
        next_states = self.batchNextStates(current_states, actions)
        rewards = self.batchGameEnded(next_states, target_strings)
        terminated = ~(rewards == 0)
        return next_states, rewards, terminated
        
        
    def scratchPadMask(self, current_states):
        N = current_states.shape[0]
        is_SP_start_tok = current_states == self.SP_id
        is_SP_end_tok = current_states == self.ESP_id
        is_SP_end_tok = torch.cat((torch.tensor([[False]]*N, device=self.device), is_SP_end_tok[:,:-1]), dim=1)
        
        SP_toks = is_SP_start_tok + is_SP_end_tok
        SP_mask = torch.cumsum(SP_toks.to(torch.int), dim=1) % 2 == 1
        return SP_mask
    
    def singleAutoGeneratedMask(self, current_state):
        state_len = current_state.shape[0]
        is_auto_gen_start_tok = current_state == self.EXEC_id
        is_auto_gen_start_tok = torch.cat((torch.tensor([False], device=self.device), is_auto_gen_start_tok[:-1]))
        
        is_auto_gen_end_tok = current_state == self.NL_id
        is_auto_gen_end_tok = torch.cat((torch.tensor([False], device=self.device), is_auto_gen_end_tok[:-1]))
        
        SP_toks = is_auto_gen_start_tok + is_auto_gen_end_tok
        SP_mask = torch.cumsum(SP_toks.to(torch.int), dim=0) % 2 == 1
        return SP_mask
    
    def batchAutoGeneratedMask(self, current_states):
        N = current_states.shape[0]
        is_auto_gen_start_tok = current_states == self.EXEC_id
        is_auto_gen_start_tok = torch.cat((torch.tensor([[False]]*N, device=self.device), is_auto_gen_start_tok[:,:-1]), dim=1)
        
        is_auto_gen_end_tok = current_states == self.NL_id
        is_auto_gen_end_tok = torch.cat((torch.tensor([[False]]*N, device=self.device), is_auto_gen_end_tok[:,:-1]), dim=1)
        
        SP_toks = is_auto_gen_start_tok + is_auto_gen_end_tok
        SP_mask = torch.cumsum(SP_toks.to(torch.int), dim=1) % 2 == 1
        return SP_mask
    
    def scratch_pad_exec(self, code):
        if not code:
            return ''
        try:
            prior_code, _, last_line = code.rpartition('\n')
            exec(f'{prior_code}\nglobal __i__; __i__ = {last_line}')
            global __i__
            return str(__i__)
        except Exception as e:
            if hasattr(e,'msg'):
                return "ERROR: " + e.msg
            return "ERROR: " + str(e)
        
    def batchGameEnded(self, states, example_objects):
        '''
        states: Long tensor: [N, seq_len]
        target_states: list of functions to check if a state is valid: [N]
        reutrns: Long tensor: [N]
        '''
        N = states.shape[0]
        SP_mask = self.scratchPadMask(states) # scratchPad tokens are True
        pad_mask = states==self.PAD_id # pad tokens are True
        true_token_mask = ~(SP_mask | pad_mask) # scratchPad and pad tokens are False
        
        game_states = ((states!=self.PAD_id).sum(dim=1)<self.max_token_length).to(torch.float)-1
        # value 0 game states  means they are not terminated
        state_strings = self.to_hash(states)
        for i in torch.arange(N)[game_states==0]:
            answer_string = example_objects[i]['answer']
            game_states[i] = example_objects[i]['match_fn'](state_strings[i], answer_string)
            
        return game_states
    
    def batchNextStates(self, current_states, actions):
        """
        Input:
            current_states: Long tensor: [N, seq_len]
            actions: action taken: Long tensor: [N,1]
        Returns:
            nextState: state after applying action: torch.tensor([1,2,3,4])
        """
        assert current_states.shape[0] == actions.shape[0], f"number of states doesn't match number of actions {current_states.shape[0]} != {actions.shape[0]}"
        new_states = []
        for current_state, action in zip(current_states, actions):
            in_sp_mask = self.scratchPadMask(current_state.unsqueeze(0)).squeeze(0) # True means in sp token, False means out
            if action != self.EXEC_id or not in_sp_mask[-1] == True:
                new_state = torch.cat((current_state, action))
                new_states.append(new_state)
                continue
                
            # this means we are in an execution situation 
            sequence = self.tokenizer.decode(torch.cat((current_state, action)).tolist(), skip_special_tokens=False)
            prior_scratch_pad_sequence, _, last_scratch_pad_sequence = sequence.rpartition('[SP]')
            prior_scratch_pad_sequences = re.findall(r'\[SP\]([^.]*)\[ESP\]', prior_scratch_pad_sequence)
            all_statements = ''.join(prior_scratch_pad_sequences + [last_scratch_pad_sequence])
            individual_statements = re.split(r'>>>.*\[NL\]|>>>', all_statements)
            code = '\n'.join([s for s in individual_statements if s])
            stmnt_out = self.scratch_pad_exec(code)
            tokenized_stmnt_out = torch.tensor(self.tokenizer.encode(stmnt_out + '[NL]').ids, device=self.device)
            new_state = torch.cat((current_state, action.reshape(1), tokenized_stmnt_out))
            new_states.append(new_state)
        
        next_states = torch.nn.utils.rnn.pad_sequence([new_state.flip(0) for new_state in new_states], 
                                                 padding_value=self.PAD_id, batch_first=True).flip(1)
        return next_states
    
    def strings_to_state(self, current_strings):
        '''
        Tokenizes a list of strings into a state tensor.
        returns: tensor([N, seq_len])
        '''
        current_states = [ex.ids for ex in self.tokenizer.encode_batch(current_strings)]
        tensor_current_states = torch.tensor(current_states, device=self.device)
        return tensor_current_states
        
    def random_states(self, num_states, prompt_type, seed=None):
        '''
        Create a batch representation of multiple states and their targets.
        
        returns: current_states, target_strings
        '''
        pairs = self.customPromptsAndAnswers(prompt_type, num_states, seed=seed)
        starting_strings = [ex['prompt'] for ex in pairs]
        target_strings = [ex['gold'] for ex in pairs]
        starting_states = [ex.ids for ex in self.tokenizer.encode_batch(starting_strings)]
        tensor_starting_states = torch.tensor(starting_states, device=self.device)
        return tensor_starting_states, target_strings
    
    def remove_ScratchPad(self, current_string):
        return re.sub(r'\[SP\]([^.]*)\[ESP\]', '',current_string)
    
    def ends_with_EOS(self, current_string):
        return current_string[-5:] == '[EOS]'
    
    def match_no_SP_fn(self, current_string, answer_string):
                    no_SP_string = self.remove_ScratchPad(current_string)
                    if no_SP_string == answer_string:
                        return 1
                    if self.ends_with_EOS(current_string):
                        return -1
                    return 0
        
    def customPromptsAndAnswers(self, prompt_type, n=100, seed=None):
        '''
        Generate n prompt-answer pairs of type prompt_type.
        prompt_type: str: 'simple_addition'

        returns: [(str: prompt string, str: prompt and answer string)]
        '''
        seed_everything(seed)
        repetition_cache = set()
        if prompt_type == 'variable_span_copying':
            char_pool = string.ascii_uppercase + string.ascii_lowercase + string.digits
            samples = []
            for i in range(n):
                sent_size = random.randrange(0,40)
                rand_sent = ''.join(random.choices(char_pool, k=sent_size))
                sample = {}
                sample['prompt'] = f'[BOS]Copy "{rand_sent}":'
                sample['gold'] = f'[BOS]Copy "{rand_sent}":{rand_sent}[EOS]'
                sample['valid_fn'] = lambda s: s == f'[BOS]Copy "{rand_sent}":{rand_sent}[EOS]'
                if sample['prompt'] not in repetition_cache:
                    samples.append(sample)
                    repetition_cache.add(sample['prompt'])
            return samples
        if prompt_type == 'simple_addition':
            samples = []
            for i in range(n):
                a = random.randrange(0,5)
                b = random.randrange(0,5)
                sample = {}
                sample['prompt'] = f'[BOS]What is {a}+{b}?'
                sample['gold'] = f'[BOS]What is {a}+{b}?[SP]{a}+{b}>>>{a+b}[NL][ESP]{a+b}[EOS]'
                sample['answer'] = f'[BOS]What is {a}+{b}?{a+b}[EOS]'
                
                sample['match_fn'] = self.match_no_SP_fn
                assert sample['match_fn'](sample['gold'], sample['answer']) == 1
                if sample['prompt'] not in repetition_cache:
                    samples.append(sample)
                    repetition_cache.add(sample['prompt'])
            return samples
        if prompt_type == 'simple_addition_solution':
            pairs = []
            for i in range(n):
                a = random.randrange(0,300)
                b = random.randrange(0,300)
                prompt = f'[BOS]What is {a}+{b}?[SP]{a}+{b}>>>{a+b}[NL][ESP]{a+b}[EOS]'
                target = f'[BOS]What is {a}+{b}?{a+b}[EOS]'
                pairs.append((prompt, target))
            return pairs
        if prompt_type == 'simple_subtraction_solution':
            pairs = []
            for i in range(n):
                a = random.randrange(0,300)
                b = random.randrange(0,300)
                prompt = f'[BOS]What is {a}-{b}?[SP]{a}-{b}>>>{a-b}[NL][ESP]{a-b}[EOS]'
                target = f'[BOS]What is {a}-{b}?{a-b}[EOS]'
                pairs.append((prompt, target))
            return pairs
        else:
            raise f'{prompt_type} not recognised'
            
    def to_hash(self, current_states):
        """
        Input:
            current_states: torch.tensor([N, seq_len])
        Returns:
            boardString: a quick conversion of board to a string format.
                         Required by MCTS for hashing.
        """
        states_list = current_states.tolist()
        no_pad_states_list = [[i for i in s if i != self.PAD_id] for s in states_list]
        return self.tokenizer.decode_batch(no_pad_states_list, skip_special_tokens=False)
            
    def to_string(self, current_states):
        """
        Input:
            current_states: torch.tensor([N, seq_len])
        Returns:
            boardString: a quick conversion of board to a string format.
                         Required by MCTS for hashing.
        """
        return self.tokenizer.decode_batch(current_states.tolist())