{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-graph N-beddings\n",
    "![Drag Racing](images/HyperGraph_Nbedding.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.modules.activation import MultiheadAttention\n",
    "from torch.nn.modules.linear import Linear\n",
    "import torch.nn as nn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.rand((3,8))\n",
    "edges = torch.tensor([[0,1,0],\n",
    "                      [0,0,0],\n",
    "                      [2,2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge_Attention(Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.Wq = Linear(embed_dim,embed_dim)\n",
    "        self.Wk = Linear(embed_dim,embed_dim)\n",
    "        self.Wv = Linear(embed_dim,embed_dim)\n",
    "        \n",
    "        self.edge_embedding = nn.Embedding(3, embed_dim)\n",
    "\n",
    "    def forward(self, queries, keys, values, edge_matrix):\n",
    "        # edge_matrix [L,L]\n",
    "        seq_len = queries.shape[0]\n",
    "        Q = self.Wq(queries) # [L,E]\n",
    "        K = self.Wk(keys) # [L,E]\n",
    "        V = self.Wv(values) # [L,E]\n",
    "        \n",
    "        attention_matrix = torch.zeros((seq_len,seq_len)) # [L,L]\n",
    "        for i in range(seq_len):\n",
    "            for j in range(seq_len):\n",
    "                edge_ij_emb = self.edge_embedding(edge_matrix[i,j])\n",
    "                attention_matrix[i,j] = torch.dot(Q[i]+edge_ij_emb, K[j]+edge_ij_emb)\n",
    "                \n",
    "        attention_matrix = torch.softmax(attention_matrix, dim=-1)\n",
    "        output = torch.matmul(attention_matrix, V)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0125,  0.1365,  0.0868, -0.0329,  0.0552, -0.2522,  0.0808,  0.0194],\n",
      "        [-0.1271,  0.0905,  0.0298, -0.0840,  0.1488, -0.2664,  0.2652, -0.0683],\n",
      "        [-0.0094,  0.1227,  0.0752, -0.0388,  0.0496, -0.2534,  0.0653,  0.0209]],\n",
      "       grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "ea = Edge_Attention(8)\n",
    "ea(src,src,src,edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch_Edge_Attention(Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        '''\n",
    "        Edge attation computation, provides structured information to the attention computation. \n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.Wq = Linear(embed_dim,embed_dim)\n",
    "        self.Wk = Linear(embed_dim,embed_dim)\n",
    "        self.Wv = Linear(embed_dim,embed_dim)\n",
    "        \n",
    "        self.edge_embedding = nn.Embedding(3, embed_dim)\n",
    "\n",
    "    def forward(self, queries, keys, values, edge_matrix):\n",
    "        '''\n",
    "        L sequence length, N Batch size, E embeding dim\n",
    "        queries: [L,N,E]\n",
    "        keys: [L,N,E]\n",
    "        values: [L,N,E]\n",
    "        edge_matrix: [N,L,L]\n",
    "        \n",
    "        returns: [L,N,E]\n",
    "        >>> src = torch.rand((2,3,8))\n",
    "        >>> edges = torch.tensor([[[0,1,0],\n",
    "                                   [0,0,0],\n",
    "                                   [2,2,0]],\n",
    "                                  [[0,0,0],\n",
    "                                   [1,0,0],\n",
    "                                   [2,2,0]]])\n",
    "        >>> ea = Batch_Edge_Attention(8)\n",
    "        >>> ea(src,src,src,edges).shape\n",
    "        '''\n",
    "        queries = queries.permute(1,0,2)\n",
    "        keys = keys.permute(1,0,2)\n",
    "        values = values.permute(1,0,2)\n",
    "        batch_size = edge_matrix.shape[0]\n",
    "        seq_len = queries.shape[1]\n",
    "        Q = self.Wq(queries) # [N,L,E]\n",
    "        K = self.Wk(keys) # [N,L,E]\n",
    "        V = self.Wv(values) # [N,L,E]\n",
    "        \n",
    "        attention_matrix = torch.zeros((batch_size,seq_len,seq_len)) # [N,L,L]\n",
    "        for i in range(seq_len):\n",
    "            for j in range(seq_len):\n",
    "                edge_ij_emb = self.edge_embedding(edge_matrix[:,i,j])\n",
    "                A = Q[:,i]+edge_ij_emb\n",
    "                B = K[:,j]+edge_ij_emb\n",
    "                attention_matrix[:,i,j] = torch.bmm(A.unsqueeze(dim=1), B.unsqueeze(dim=2)).squeeze()\n",
    "                \n",
    "        attention_matrix = torch.softmax(attention_matrix, dim=-1)\n",
    "        output = torch.bmm(attention_matrix, V)\n",
    "        output = output.permute(1,0,2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 128])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 3\n",
    "embed_dim = 128\n",
    "device = \"cpu\"\n",
    "src = torch.rand((seq_len,2,embed_dim), device=device)\n",
    "edges = torch.tensor([[[0,1,0],\n",
    "                       [0,0,0],\n",
    "                       [2,2,0]],\n",
    "                      \n",
    "                      [[0,0,0],\n",
    "                       [1,0,0],\n",
    "                       [2,2,0]]], device=device)\n",
    "# edges = torch.randint(0,3,(2,embed_dim,embed_dim), device=device)\n",
    "ea = Batch_Edge_Attention(embed_dim).to(device)\n",
    "ea(src,src,src,edges).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 389 ms, sys: 4.92 ms, total: 394 ms\n",
      "Wall time: 25.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2, 128])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time ea(src,src,src,edges).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attn = MultiheadAttention(embed_dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 740 ms, sys: 4.06 ms, total: 744 ms\n",
      "Wall time: 49.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 2, 128])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time self_attn(src, src, src)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving speed with scatter and sparce matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fast_Edge_Attention(Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        '''\n",
    "        Edge attation computation, provides structured information to the attention computation. \n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.Wq = Linear(embed_dim,embed_dim, bias=False)\n",
    "        self.Wk = Linear(embed_dim,embed_dim, bias=False)\n",
    "        self.Wv = Linear(embed_dim,embed_dim, bias=False)\n",
    "        \n",
    "        self.edge_embedding = nn.Embedding(3, embed_dim)\n",
    "\n",
    "    def forward(self, queries, keys, values, edge_matrix):\n",
    "        '''\n",
    "        L sequence length, N Batch size, E embeding dim\n",
    "        queries: [L,N,E]\n",
    "        keys: [L,N,E]\n",
    "        values: [L,N,E]\n",
    "        edge_matrix: [N,L,L]\n",
    "        \n",
    "        returns: [L,N,E]\n",
    "        >>> src = torch.rand((2,3,8))\n",
    "        >>> edges = torch.tensor([[[0,1,0],\n",
    "                                   [0,0,0],\n",
    "                                   [2,2,0]],\n",
    "                                  [[0,0,0],\n",
    "                                   [1,0,0],\n",
    "                                   [2,2,0]]])\n",
    "        >>> ea = Batch_Edge_Attention(8)\n",
    "        >>> ea(src,src,src,edges).shape\n",
    "        '''\n",
    "        \n",
    "        queries = queries.permute(1,0,2)\n",
    "        keys = keys.permute(1,0,2)\n",
    "        values = values.permute(1,0,2)\n",
    "        batch_size = edge_matrix.shape[0]\n",
    "        seq_len = queries.shape[1]\n",
    "        Q = self.Wq(queries) # [N,L,E]\n",
    "        K = self.Wk(keys) # [N,L,E]\n",
    "        V = self.Wv(values) # [N,L,E]\n",
    "        \n",
    "        attention_matrix = torch.bmm(Q,K.permute(0,2,1))\n",
    "        \n",
    "        sparse_edges = edges.to_sparse()\n",
    "        sparse_edges_indices = sparse_edges.indices()\n",
    "        query_indices = sparse_edges_indices[[True, True, False]]\n",
    "        key_indices = sparse_edges_indices[[True, False, True]]\n",
    "        \n",
    "        query_edge_vectors = Q[query_indices[0],query_indices[1]]\n",
    "        key_edge_vectors = Q[key_indices[0],key_indices[1]]\n",
    "        \n",
    "        indexed_edge_embeddings = self.edge_embedding(sparse_edges.values())\n",
    "        query_edge_vectors += indexed_edge_embeddings\n",
    "        key_edge_vectors += indexed_edge_embeddings\n",
    "        \n",
    "        edge_attention_values = torch.bmm(query_edge_vectors.unsqueeze(1),key_edge_vectors.unsqueeze(2)).squeeze()\n",
    "        attention_matrix[sparse_edges_indices[0],sparse_edges_indices[1],sparse_edges_indices[2]] = edge_attention_values\n",
    "        print(attention_matrix)\n",
    "                \n",
    "        attention_matrix = torch.softmax(attention_matrix, dim=-1)\n",
    "        output = torch.bmm(attention_matrix, V)\n",
    "        output = output.permute(1,0,2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [4., 4., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [4., 4., 0.]]], grad_fn=<IndexPutBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 128])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 3\n",
    "embed_dim = 128\n",
    "device = \"cpu\"\n",
    "src = torch.zeros((seq_len,2,embed_dim), device=device)\n",
    "edges = torch.tensor([[[0,1,0],\n",
    "                       [0,0,0],\n",
    "                       [2,2,0]],\n",
    "                      \n",
    "                      [[0,0,0],\n",
    "                       [1,0,0],\n",
    "                       [2,2,0]]], device=device)\n",
    "# edges = torch.randint(0,3,(2,embed_dim,embed_dim), device=device)\n",
    "fea = Fast_Edge_Attention(embed_dim).to(device)\n",
    "fea.edge_embedding.weight.data = torch.zeros(3,128)\n",
    "fea.edge_embedding.weight.data[[1],[0]] = 1\n",
    "fea.edge_embedding.weight.data[[2],[0]] = 2\n",
    "fea(src,src,src,edges).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 21836])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.to_sparse().indices().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 660 ms, sys: 213 ms, total: 872 ms\n",
      "Wall time: 64.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 2, 128])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fea(src,src,src,edges).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the Pen Treebank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treebank\n",
    "train_data = treebank.penn['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memote'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.datasets import penn_treebank_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = penn_treebank_dataset(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aer',\n",
       " 'banknote',\n",
       " 'berlitz',\n",
       " 'calloway',\n",
       " 'centrust',\n",
       " 'cluett',\n",
       " 'fromstein',\n",
       " 'gitano',\n",
       " 'guterman',\n",
       " 'hydro-quebec',\n",
       " 'ipo',\n",
       " 'kia',\n",
       " 'memotec',\n",
       " 'mlx',\n",
       " 'nahb',\n",
       " 'punts',\n",
       " 'rake',\n",
       " 'regatta',\n",
       " 'rubens',\n",
       " 'sim',\n",
       " 'snack-food',\n",
       " 'ssangyong',\n",
       " 'swapo',\n",
       " 'wachter',\n",
       " '</s>',\n",
       " 'pierre',\n",
       " '<unk>',\n",
       " 'N',\n",
       " 'years',\n",
       " 'old',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'nov.',\n",
       " 'N',\n",
       " '</s>',\n",
       " 'mr.',\n",
       " '<unk>',\n",
       " 'is',\n",
       " 'chairman',\n",
       " 'of',\n",
       " '<unk>',\n",
       " 'n.v.',\n",
       " 'the',\n",
       " 'dutch',\n",
       " 'publishing',\n",
       " 'group',\n",
       " '</s>',\n",
       " 'rudolph',\n",
       " '<unk>',\n",
       " 'N',\n",
       " 'years',\n",
       " 'old',\n",
       " 'and',\n",
       " 'former',\n",
       " 'chairman',\n",
       " 'of',\n",
       " 'consolidated',\n",
       " 'gold',\n",
       " 'fields',\n",
       " 'plc',\n",
       " 'was',\n",
       " 'named',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'of',\n",
       " 'this',\n",
       " 'british',\n",
       " 'industrial',\n",
       " 'conglomerate',\n",
       " '</s>',\n",
       " 'a',\n",
       " 'form',\n",
       " 'of',\n",
       " 'asbestos',\n",
       " 'once',\n",
       " 'used',\n",
       " 'to',\n",
       " 'make',\n",
       " 'kent',\n",
       " 'cigarette',\n",
       " 'filters',\n",
       " 'has',\n",
       " 'caused',\n",
       " 'a',\n",
       " 'high',\n",
       " 'percentage',\n",
       " 'of',\n",
       " 'cancer',\n",
       " 'deaths',\n",
       " 'among',\n",
       " 'a',\n",
       " 'group',\n",
       " 'of']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
