{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy-Generator Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from queue import PriorityQueue\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import tqdm\n",
    "from torchnlp.metrics import get_moses_multi_bleu\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
    "from io import BytesIO\n",
    "\n",
    "import linecache\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import operator\n",
    "import collections\n",
    "import json\n",
    "from dotmap import DotMap\n",
    "\n",
    "from base_transformer import TransformerModel, PositionalEncoding\n",
    "from copy_gen_transformer import Transformer, TransformerDecoderLayer, TransformerDecoder\n",
    "import beam_search\n",
    "from IPython.core.debugger import set_trace as tr\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CONFIG'] = \"config_copy_gen_vcb1600_maxlen200.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config_fp = os.environ['CONFIG']\n",
    "except:\n",
    "    config_fp = \"config.json\"\n",
    "    \n",
    "with open(config_fp) as config_file:\n",
    "    config = json.loads(config_file.read())\n",
    "    config = DotMap(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env CONFIG: config_copy_gen_vcb1600_maxlen200.json\n",
      "DotMap(max_seq_length=200, vocab_size=1600, log_file_name='logs_copy_gen_vcb1600_maxlen2000.txt', out_file_name='out_copy_gen_vcb1600_maxlen2000.txt', train_steps=1000000, train_learning_rate=0.005, src_file='./datasets/all-fixed.desc', tgt_file='./datasets/all.code', eval_interval=10000, log_interval=400, eval_beam_size=1, train_batch_size=32, eval_batch_size=32, model_layers=4, model_att_heads=8, model_embed_dim=512, model_dim_feedforward=1024, model_att_mask_noise=0.0)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def super_print(filename):\n",
    "    '''filename is the file where output will be written'''\n",
    "    def wrap(func):\n",
    "        '''func is the function you are \"overriding\", i.e. wrapping'''\n",
    "        def wrapped_func(*args,**kwargs):\n",
    "            '''*args and **kwargs are the arguments supplied \n",
    "            to the overridden function'''\n",
    "            #use with statement to open, write to, and close the file safely\n",
    "            with open(filename,'a', encoding=\"utf-8\") as outputfile:\n",
    "                now = datetime.now()\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                outputfile.write(\"[{}] \".format(dt_string))\n",
    "                outputfile.write(\" \".join(str(x) for x in args))\n",
    "                outputfile.write(\"\\n\")\n",
    "            #now original function executed with its arguments as normal\n",
    "            return func(*args,**kwargs)\n",
    "        return wrapped_func\n",
    "    return wrap\n",
    "\n",
    "print = super_print(config.log_file_name)(print)\n",
    "print(\"env CONFIG:\",config_fp)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.set_device(0) # choose GPU from nvidia-smi \n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['create', 'variable', 'student_names', 'with', 'string', \"'foo bar baz'\"]\n"
     ]
    }
   ],
   "source": [
    "text = \"create variable student_names with string 'foo bar baz'\"\n",
    "\n",
    "def string_split(s):\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(_|\\W)', s))) # this will chunk all code properly by plits strings with quotes\n",
    "#     return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|_|\\W)', s))) # this keeps the strings intact\n",
    "    return list(filter(lambda x: x != '' and x != \"\\n\" and not x.isspace(), re.split('(\\\\\\'.*?\\\\\\'|\\\\\\\".*?\\\\\\\"|\\W)', s)))\n",
    "\n",
    "print(string_split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_array(src_fp, tgt_fp):\n",
    "    lines = []\n",
    "    with open(src_fp, \"r\", encoding=\"utf-8\") as src_file, open(tgt_fp, \"r\", encoding=\"utf-8\") as tgt_file:\n",
    "        for src, tgt in zip(src_file, tgt_file):\n",
    "            lines.append((src, tgt))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_corpus(data, max_seq_length=200, tokenizer=string_split):\n",
    "    return [(src, tgt) for src, tgt in data if len(string_split(src)) <= max_seq_length and len(string_split(tgt)) <= max_seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_dataset(samples):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samples: [(src_string),(tgt_string)]\n",
    "        src/tgt_tokenizer: a func that takes a string and returns an array of strings\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    TEXT_FIELD = Field(sequential=True, use_vocab=False, init_token='<sos>',eos_token='<eos>')\n",
    "    \n",
    "    for sample in samples:\n",
    "        src_string, tgt_string = sample\n",
    "        examples.append(torchtext.data.Example.fromdict({\"src\":src_string, \"tgt\":tgt_string}, \n",
    "                                        fields={\"src\":(\"src\",TEXT_FIELD), \"tgt\":(\"tgt\",TEXT_FIELD)}))\n",
    "        \n",
    "    dataset = torchtext.data.Dataset(examples,fields={\"src\":src_field, \"tgt\":tgt_field})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max src length: 557\n",
      "Max tgt length: 527\n",
      "Full dataset size: 18805\n",
      "Limited dataset size: 18797\n"
     ]
    }
   ],
   "source": [
    "data = corpus_to_array(config.src_file, config.tgt_file)\n",
    "# data = corpus_to_array(\"datasets/all.desc\", \"datasets/all.code\")\n",
    "random.shuffle(data)\n",
    "print(\"Max src length:\", max([len(string_split(src)) for src, tgt in data]))\n",
    "print(\"Max tgt length:\", max([len(string_split(tgt)) for src, tgt in data]))\n",
    "\n",
    "print(\"Full dataset size:\", len(data))\n",
    "max_seq_length=config.max_seq_length\n",
    "data = filter_corpus(data, max_seq_length=max_seq_length, tokenizer=string_split)\n",
    "print(\"Limited dataset size:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "          \"my favourite foods are banana and toast\",\n",
    "          \"my favourite foods are eggs and bacon and beans\",\n",
    "          \"my favourite food is chocolate\",\n",
    "          \"my favourite food is avocado\"\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "           \"would you like banana and toast ?\",\n",
    "           \"would you like eggs and bacon and beans ?\",\n",
    "           \"would you like chocolate ?\",\n",
    "           \"would you like avocado ?\"\n",
    "]\n",
    "# max_seq_length = 9\n",
    "# data = list(zip(inputs, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {\"<unk>\":0, \"<sos>\":1, \"<eos>\":2, \"<pad>\":3}\n",
    "max_vocab = config.vocab_size - len(stoi)\n",
    "\n",
    "all_toks = []\n",
    "for (src, tgt) in data:\n",
    "    all_toks += string_split(src)\n",
    "    all_toks += string_split(tgt)\n",
    "\n",
    "most_freq = collections.Counter(all_toks).most_common(max_vocab)\n",
    "\n",
    "for tok, count in most_freq:\n",
    "    stoi[tok] = len(stoi)\n",
    "    \n",
    "itos = [k for k,v in sorted(stoi.items(), key=lambda kv: kv[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(string):\n",
    "    OOVs = []\n",
    "    IDs = []\n",
    "    words = string_split(string)\n",
    "    for word in words:\n",
    "        try:\n",
    "            id = stoi[word]\n",
    "            IDs.append(id)\n",
    "        except KeyError as e:\n",
    "            # word is OOV\n",
    "            IDs.append(len(stoi) + len(OOVs))\n",
    "            OOVs.append(word)\n",
    "    return IDs, OOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(string, OOVs):\n",
    "    IDs = []\n",
    "    words = string_split(string)\n",
    "    for word in words:\n",
    "        try:\n",
    "            id = stoi[word]\n",
    "            IDs.append(id)\n",
    "        except KeyError as e:\n",
    "            # word is OOV\n",
    "            try:\n",
    "                IDs.append(len(stoi) + OOVs.index(word))\n",
    "            except ValueError as e:\n",
    "                IDs.append(stoi[\"<unk>\"])\n",
    "    return IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids, OOVs):\n",
    "    extended_itos = itos.copy()\n",
    "    extended_itos += [OOV+\"(COPY)\" for OOV in OOVs]\n",
    "    return \" \".join([extended_itos[id] for id in ids if id<len(extended_itos)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = Field(sequential=True, use_vocab=False, unk_token=0, init_token=1,eos_token=2, pad_token=3)\n",
    "OOV_TEXT_FIELD = Field(sequential=True, use_vocab=False, pad_token=3)\n",
    "\n",
    "OOV_stoi = {}\n",
    "OOV_itos = {}\n",
    "OOV_starter_count = 30000\n",
    "OOV_count = OOV_starter_count\n",
    "\n",
    "examples = []\n",
    "\n",
    "for (src, tgt) in data:\n",
    "    src_ids, OOVs = encode_input(src)\n",
    "    tgt_ids = encode_output(tgt, OOVs)\n",
    "    OOV_ids = []\n",
    "    \n",
    "    for OOV in OOVs:\n",
    "        try:\n",
    "            idx = OOV_stoi[OOV]\n",
    "            OOV_ids.append(idx)\n",
    "        except KeyError as e:\n",
    "            OOV_count += 1\n",
    "            OOV_stoi[OOV] = OOV_count\n",
    "            OOV_itos[OOV_count] = OOV\n",
    "            OOV_ids.append(OOV_count)\n",
    "            \n",
    "    examples.append(torchtext.data.Example.fromdict({\"src\":src_ids, \"tgt\":tgt_ids, \"OOVs\":OOV_ids}, \n",
    "                                                    fields={\"src\":(\"src\",TEXT_FIELD), \"tgt\":(\"tgt\",TEXT_FIELD), \"OOVs\":(\"OOVs\", OOV_TEXT_FIELD)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Hearthstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = corpus_to_array(config.eval_src_file, config.eval_tgt_file)\n",
    "test_data = filter_corpus(test_data, max_seq_length=max_seq_length, tokenizer=string_split)\n",
    "\n",
    "test_examples = []\n",
    "\n",
    "for (src, tgt) in test_data:\n",
    "    src_ids, OOVs = encode_input(src)\n",
    "    tgt_ids = encode_output(tgt, OOVs)\n",
    "    OOV_ids = []\n",
    "    \n",
    "    for OOV in OOVs:\n",
    "        try:\n",
    "            idx = OOV_stoi[OOV]\n",
    "            OOV_ids.append(idx)\n",
    "        except KeyError as e:\n",
    "            OOV_count += 1\n",
    "            OOV_stoi[OOV] = OOV_count\n",
    "            OOV_itos[OOV_count] = OOV\n",
    "            OOV_ids.append(OOV_count)\n",
    "            \n",
    "    test_examples.append(torchtext.data.Example.fromdict({\"src\":src_ids, \"tgt\":tgt_ids, \"OOVs\":OOV_ids}, \n",
    "                                                    fields={\"src\":(\"src\",TEXT_FIELD), \"tgt\":(\"tgt\",TEXT_FIELD), \"OOVs\":(\"OOVs\", OOV_TEXT_FIELD)}))\n",
    "\n",
    "val_dataset = torchtext.data.Dataset(test_examples,fields={\"src\":TEXT_FIELD, \"tgt\":TEXT_FIELD, \"OOVs\":OOV_TEXT_FIELD})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchtext.data.Dataset(examples,fields={\"src\":TEXT_FIELD, \"tgt\":TEXT_FIELD, \"OOVs\":OOV_TEXT_FIELD})\n",
    "train_dataset, val_dataset = dataset.split([0.9,0.1])\n",
    "# train_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43, 32])\n",
      "torch.Size([24, 32])\n",
      "SOURCE: <sos> if not , <eos>\n",
      "\n",
      "TARGET: <sos> else : <eos>\n"
     ]
    }
   ],
   "source": [
    "batch_size = config.train_batch_size\n",
    "\n",
    "train_iterator = BucketIterator(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    repeat=True,\n",
    "    shuffle=True,\n",
    "    sort_key = lambda x: len(x.src)+len(x.tgt),\n",
    "    device = device)\n",
    "\n",
    "# The iterator generates batches with padded length for sequences with similar sizes, a batch is [seq_length, batch_size]\n",
    "\n",
    "for i, batch in enumerate(train_iterator):\n",
    "    idx = 3\n",
    "#     print([SRC_TEXT.vocab.itos[id] for id in batch.src.cpu().numpy()[:,idx]])\n",
    "    OOVs = [OOV_itos[OOV] for OOV in batch.OOVs.cpu()[:,idx].tolist() if OOV != 3] # 3 is the <pad> token\n",
    "    src_ids = batch.src.cpu()[:,idx].tolist()\n",
    "    src_ids = src_ids[:src_ids.index(2)+1]\n",
    "    tgt_ids = batch.tgt.cpu()[:,idx].tolist()\n",
    "    tgt_ids = tgt_ids[:tgt_ids.index(2)+1]\n",
    "    \n",
    "    print(batch.src.shape)\n",
    "    print(batch.tgt.shape)\n",
    "    \n",
    "    print(\"SOURCE:\",decode(src_ids, OOVs))\n",
    "    print()\n",
    "    print(\"TARGET:\",decode(tgt_ids, OOVs))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# foo bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, dropout=0.5):\n",
    "        super(CopyModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.embedding_size = config.model_embed_dim\n",
    "        self.pos_encoder = PositionalEncoding(self.embedding_size, dropout)\n",
    "        self.src_encoder = nn.Embedding(src_vocab_size, self.embedding_size)\n",
    "        self.tgt_encoder = nn.Embedding(tgt_vocab_size, self.embedding_size)\n",
    "        \n",
    "        self.transformer = Transformer(d_model=config.model_embed_dim, \n",
    "                                       nhead=config.model_att_heads, \n",
    "                                       num_encoder_layers=config.model_layers, \n",
    "                                       num_decoder_layers=config.model_layers, \n",
    "                                       dim_feedforward=config.model_dim_feedforward)\n",
    "        self.decoder = nn.Linear(self.embedding_size, tgt_vocab_size)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.p_generator = nn.Linear(config.model_embed_dim,1)\n",
    "\n",
    "        self.init_weights()\n",
    "        self.tgt_mask = None\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.src_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.tgt_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "#         noise_e = 0.05 if self.training else 0.0 # this is code to add noise to the decoding process during training\n",
    "        noise_e = config.model_att_mask_noise if self.training else 0.0\n",
    "        noise_mask = (torch.rand(sz,sz) > noise_e).float()\n",
    "\n",
    "        mask = (torch.triu(torch.ones(sz,sz))).transpose(0, 1)\n",
    "        mask = torch.mul(mask, noise_mask)\n",
    "        v = (torch.sum(mask, dim=-1) == 0).float()\n",
    "\n",
    "        fix_mask = torch.zeros(sz,sz)\n",
    "        fix_mask[:,0] = 1.0\n",
    "        v = v.repeat(sz, 1).transpose(0,1)\n",
    "        fix_mask = torch.mul(fix_mask,v)\n",
    "\n",
    "        mask += fix_mask\n",
    "        \n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        self.tgt_mask = self._generate_square_subsequent_mask(len(tgt)).to(self.device)\n",
    "        \n",
    "\n",
    "        src_emb = self.src_encoder(src) * math.sqrt(self.embedding_size)\n",
    "        src_emb = self.pos_encoder(src_emb)\n",
    "        \n",
    "        tgt_emb = self.tgt_encoder(tgt) * math.sqrt(self.embedding_size)\n",
    "        tgt_emb = self.pos_encoder(tgt_emb)\n",
    "        \n",
    "        output, atts = self.transformer(src_emb, tgt_emb, tgt_mask=self.tgt_mask)\n",
    "        \n",
    "        \n",
    "        src_scat = src.transpose(0,1)\n",
    "        src_scat = src_scat.unsqueeze(0)\n",
    "        src_scat = torch.repeat_interleave(src_scat, tgt.shape[0], dim=0)\n",
    "#         print(\"src_scat.shqape\", src_scat.shape)\n",
    "        \n",
    "        p_gens = self.p_generator(output).sigmoid()\n",
    "        atts = atts.transpose(0,1)\n",
    "#         print(\"att.shqape\", atts.shape)\n",
    "        atts = atts * (1 - p_gens)\n",
    "                \n",
    "        output = self.decoder(output)\n",
    "#         output[:,:,12:] = -np.inf\n",
    "        output = output.softmax(-1)\n",
    "        output = output * p_gens\n",
    "        \n",
    "        output = output.scatter_add_(2,src_scat,atts)\n",
    "        output = output\n",
    "        \n",
    "        return output.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 1800])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos) + max_seq_length\n",
    "\n",
    "model = CopyModel(vocab_size,vocab_size).to(device) \n",
    "src = torch.randint(0, vocab_size, (3,2)).to(device)\n",
    "tgt = torch.randint(0, vocab_size, (5,2)).to(device)\n",
    "\n",
    "out = model(src, tgt)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_bleu(refrence, prediction):\n",
    "    \"\"\"\n",
    "    Implementation from ReCode\n",
    "    and moses multi belu script sets BLEU to 0.0 if len(toks) < 4\n",
    "    \"\"\"\n",
    "    ngram_weights = [0.25] * min(4, len(refrence))\n",
    "    return sentence_bleu([refrence], prediction, weights=ngram_weights, \n",
    "                          smoothing_function=SmoothingFunction().method3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iterator = BucketIterator(val_dataset,\n",
    "    batch_size = config.eval_batch_size,\n",
    "    sort_key = lambda x: len(x.src)+len(x.tgt),\n",
    "    device = device)\n",
    "\n",
    "def batch_filter_ids(batch_list):\n",
    "    return [[id for id in l if id not in [1,2,3]] for l in batch_list]\n",
    "\n",
    "def evaluate(beam_size=1, log=False):\n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    with torch.no_grad(), open(config.out_file_name, \"w\", encoding=\"utf-8\") as out_fp:\n",
    "        BLEU_scores = []\n",
    "        for i, batch in enumerate(valid_iterator):\n",
    "            batch_size = batch.src.shape[1]\n",
    "            \n",
    "            encoder_inputs = batch.src\n",
    "            predictions = beam_search.beam_search_decode(model,\n",
    "                              batch_encoder_ids=encoder_inputs,\n",
    "                              SOS_token=stoi[\"<sos>\"],\n",
    "                              EOS_token=stoi[\"<eos>\"],\n",
    "                              PAD_token=stoi[\"<pad>\"],\n",
    "                              beam_size=beam_size,\n",
    "                              max_length=30,\n",
    "                              num_out=1)\n",
    "            \n",
    "            sources = encoder_inputs.transpose(0,1).cpu().tolist()\n",
    "            sources = batch_filter_ids(sources)\n",
    "            \n",
    "            predictions = [t[0].view(-1).cpu().tolist() for t in predictions]\n",
    "            predictions = batch_filter_ids(predictions)\n",
    "            \n",
    "            targets = batch.tgt.transpose(0,1).cpu().tolist()\n",
    "            targets = batch_filter_ids(targets)\n",
    "            \n",
    "#             print(batch.tgt)\n",
    "            \n",
    "            OOVss = [[OOV_itos[OOV] for OOV in batch.OOVs.cpu()[:,idx].tolist() if OOV != 3] for idx in range(batch_size)]\n",
    "            \n",
    "            if i % int(len(valid_iterator)/3) == 0:\n",
    "                print(\"| EVALUATION | {:5d}/{:5d} batches |\".format(i, len(valid_iterator)))\n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                BLEU = nltk_bleu(targets[j], predictions[j])\n",
    "                BLEU_scores.append(BLEU)\n",
    "                \n",
    "                out_fp.write(\"SRC  :\" + decode(sources[j], OOVss[j]) + \"\\n\")\n",
    "                out_fp.write(\"TGT  :\" + decode(targets[j], OOVss[j]) + \"\\n\")\n",
    "                out_fp.write(\"PRED :\" + decode(predictions[j], OOVss[j]) + \"\\n\")\n",
    "                out_fp.write(\"BLEU :\" + str(BLEU) + \"\\n\")\n",
    "                out_fp.write(\"\\n\")\n",
    "                \n",
    "                if log:\n",
    "                    print(\"SRC  :\" + decode(sources[j], OOVss[j]))\n",
    "                    print(\"TGT  :\" + decode(targets[j], OOVss[j]))\n",
    "                    print(\"PRED :\" + decode(predictions[j], OOVss[j]))\n",
    "                    print(\"BLEU :\" + str(BLEU))\n",
    "                    print()\n",
    "        out_fp.write(\"\\n\\n| EVALUATION | BLEU: {:5.2f} |\\n\".format(np.average(BLEU_scores)))\n",
    "        print(\"| EVALUATION | BLEU: {:5.3f} |\".format(np.average(BLEU_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.002 |\n"
     ]
    }
   ],
   "source": [
    "evaluate(beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    tgt_vocab_size = len(itos) + max_seq_length\n",
    "    encoder_input = batch.src\n",
    "    decoder_input = batch.tgt[:-1]\n",
    "    targets = batch.tgt[1:]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(encoder_input, decoder_input)\n",
    "\n",
    "    loss = criterion(output.view(-1, tgt_vocab_size), targets.view(-1))\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "    elapsed = time.time() - start_time\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi['<pad>'])\n",
    "lr = config.train_learning_rate # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   400/1000000 steps | lr 0.0050 | ms/batch 35.83 | loss  3.30 | ppl    27.23\n",
      "|   800/1000000 steps | lr 0.0050 | ms/batch 36.13 | loss  3.21 | ppl    24.78\n",
      "|  1200/1000000 steps | lr 0.0050 | ms/batch 35.99 | loss  3.11 | ppl    22.41\n",
      "|  1600/1000000 steps | lr 0.0050 | ms/batch 36.19 | loss  3.04 | ppl    20.89\n",
      "|  2000/1000000 steps | lr 0.0050 | ms/batch 35.77 | loss  2.97 | ppl    19.53\n",
      "|  2400/1000000 steps | lr 0.0050 | ms/batch 36.25 | loss  2.91 | ppl    18.42\n",
      "|  2800/1000000 steps | lr 0.0050 | ms/batch 36.08 | loss  2.87 | ppl    17.59\n",
      "|  3200/1000000 steps | lr 0.0050 | ms/batch 35.84 | loss  2.81 | ppl    16.60\n",
      "|  3600/1000000 steps | lr 0.0050 | ms/batch 36.37 | loss  2.78 | ppl    16.04\n",
      "|  4000/1000000 steps | lr 0.0050 | ms/batch 36.27 | loss  2.74 | ppl    15.44\n",
      "|  4400/1000000 steps | lr 0.0050 | ms/batch 37.16 | loss  2.68 | ppl    14.57\n",
      "|  4800/1000000 steps | lr 0.0050 | ms/batch 37.01 | loss  2.65 | ppl    14.15\n",
      "|  5200/1000000 steps | lr 0.0050 | ms/batch 36.40 | loss  2.61 | ppl    13.66\n",
      "|  5600/1000000 steps | lr 0.0050 | ms/batch 36.22 | loss  2.59 | ppl    13.27\n",
      "|  6000/1000000 steps | lr 0.0050 | ms/batch 36.14 | loss  2.55 | ppl    12.77\n",
      "|  6400/1000000 steps | lr 0.0050 | ms/batch 36.09 | loss  2.52 | ppl    12.43\n",
      "|  6800/1000000 steps | lr 0.0050 | ms/batch 36.01 | loss  2.48 | ppl    11.91\n",
      "|  7200/1000000 steps | lr 0.0050 | ms/batch 35.77 | loss  2.43 | ppl    11.38\n",
      "|  7600/1000000 steps | lr 0.0050 | ms/batch 35.02 | loss  2.42 | ppl    11.24\n",
      "|  8000/1000000 steps | lr 0.0050 | ms/batch 37.46 | loss  2.38 | ppl    10.82\n",
      "|  8400/1000000 steps | lr 0.0049 | ms/batch 35.73 | loss  2.34 | ppl    10.42\n",
      "|  8800/1000000 steps | lr 0.0049 | ms/batch 36.17 | loss  2.32 | ppl    10.21\n",
      "|  9200/1000000 steps | lr 0.0049 | ms/batch 36.54 | loss  2.30 | ppl     9.93\n",
      "|  9600/1000000 steps | lr 0.0049 | ms/batch 36.13 | loss  2.26 | ppl     9.60\n",
      "| 10000/1000000 steps | lr 0.0049 | ms/batch 36.36 | loss  2.23 | ppl     9.32\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.265 |\n",
      "| 10400/1000000 steps | lr 0.0049 | ms/batch 140.39 | loss  2.21 | ppl     9.15\n",
      "| 10800/1000000 steps | lr 0.0049 | ms/batch 35.68 | loss  2.18 | ppl     8.80\n",
      "| 11200/1000000 steps | lr 0.0049 | ms/batch 35.68 | loss  2.16 | ppl     8.69\n",
      "| 11600/1000000 steps | lr 0.0049 | ms/batch 35.78 | loss  2.12 | ppl     8.37\n",
      "| 12000/1000000 steps | lr 0.0049 | ms/batch 36.23 | loss  2.11 | ppl     8.25\n",
      "| 12400/1000000 steps | lr 0.0049 | ms/batch 36.62 | loss  2.10 | ppl     8.17\n",
      "| 12800/1000000 steps | lr 0.0049 | ms/batch 35.91 | loss  2.06 | ppl     7.82\n",
      "| 13200/1000000 steps | lr 0.0049 | ms/batch 36.21 | loss  2.05 | ppl     7.79\n",
      "| 13600/1000000 steps | lr 0.0049 | ms/batch 36.44 | loss  2.01 | ppl     7.50\n",
      "| 14000/1000000 steps | lr 0.0049 | ms/batch 36.04 | loss  2.02 | ppl     7.52\n",
      "| 14400/1000000 steps | lr 0.0049 | ms/batch 35.95 | loss  1.99 | ppl     7.31\n",
      "| 14800/1000000 steps | lr 0.0049 | ms/batch 36.05 | loss  1.97 | ppl     7.20\n",
      "| 15200/1000000 steps | lr 0.0049 | ms/batch 36.21 | loss  1.94 | ppl     6.98\n",
      "| 15600/1000000 steps | lr 0.0049 | ms/batch 36.26 | loss  1.95 | ppl     7.00\n",
      "| 16000/1000000 steps | lr 0.0049 | ms/batch 36.95 | loss  1.92 | ppl     6.83\n",
      "| 16400/1000000 steps | lr 0.0048 | ms/batch 36.93 | loss  1.92 | ppl     6.79\n",
      "| 16800/1000000 steps | lr 0.0048 | ms/batch 36.50 | loss  1.89 | ppl     6.64\n",
      "| 17200/1000000 steps | lr 0.0048 | ms/batch 36.23 | loss  1.88 | ppl     6.52\n",
      "| 17600/1000000 steps | lr 0.0048 | ms/batch 35.61 | loss  1.86 | ppl     6.45\n",
      "| 18000/1000000 steps | lr 0.0048 | ms/batch 36.50 | loss  1.85 | ppl     6.39\n",
      "| 18400/1000000 steps | lr 0.0048 | ms/batch 36.30 | loss  1.83 | ppl     6.26\n",
      "| 18800/1000000 steps | lr 0.0048 | ms/batch 35.71 | loss  1.81 | ppl     6.12\n",
      "| 19200/1000000 steps | lr 0.0048 | ms/batch 36.97 | loss  1.83 | ppl     6.23\n",
      "| 19600/1000000 steps | lr 0.0048 | ms/batch 35.97 | loss  1.79 | ppl     5.99\n",
      "| 20000/1000000 steps | lr 0.0048 | ms/batch 35.43 | loss  1.78 | ppl     5.93\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.340 |\n",
      "| 20400/1000000 steps | lr 0.0048 | ms/batch 137.10 | loss  1.78 | ppl     5.96\n",
      "| 20800/1000000 steps | lr 0.0048 | ms/batch 35.84 | loss  1.75 | ppl     5.77\n",
      "| 21200/1000000 steps | lr 0.0048 | ms/batch 36.12 | loss  1.75 | ppl     5.73\n",
      "| 21600/1000000 steps | lr 0.0048 | ms/batch 36.09 | loss  1.74 | ppl     5.71\n",
      "| 22000/1000000 steps | lr 0.0048 | ms/batch 36.23 | loss  1.73 | ppl     5.63\n",
      "| 22400/1000000 steps | lr 0.0048 | ms/batch 35.20 | loss  1.71 | ppl     5.52\n",
      "| 22800/1000000 steps | lr 0.0048 | ms/batch 36.24 | loss  1.71 | ppl     5.51\n",
      "| 23200/1000000 steps | lr 0.0048 | ms/batch 36.96 | loss  1.71 | ppl     5.51\n",
      "| 23600/1000000 steps | lr 0.0048 | ms/batch 35.89 | loss  1.66 | ppl     5.28\n",
      "| 24000/1000000 steps | lr 0.0048 | ms/batch 36.64 | loss  1.68 | ppl     5.35\n",
      "| 24400/1000000 steps | lr 0.0047 | ms/batch 37.01 | loss  1.67 | ppl     5.30\n",
      "| 24800/1000000 steps | lr 0.0047 | ms/batch 36.22 | loss  1.66 | ppl     5.27\n",
      "| 25200/1000000 steps | lr 0.0047 | ms/batch 35.79 | loss  1.65 | ppl     5.19\n",
      "| 25600/1000000 steps | lr 0.0047 | ms/batch 36.12 | loss  1.65 | ppl     5.18\n",
      "| 26000/1000000 steps | lr 0.0047 | ms/batch 36.73 | loss  1.63 | ppl     5.08\n",
      "| 26400/1000000 steps | lr 0.0047 | ms/batch 36.00 | loss  1.62 | ppl     5.07\n",
      "| 26800/1000000 steps | lr 0.0047 | ms/batch 35.82 | loss  1.61 | ppl     5.01\n",
      "| 27200/1000000 steps | lr 0.0047 | ms/batch 36.10 | loss  1.60 | ppl     4.97\n",
      "| 27600/1000000 steps | lr 0.0047 | ms/batch 36.42 | loss  1.60 | ppl     4.97\n",
      "| 28000/1000000 steps | lr 0.0047 | ms/batch 36.05 | loss  1.59 | ppl     4.91\n",
      "| 28400/1000000 steps | lr 0.0047 | ms/batch 36.31 | loss  1.59 | ppl     4.90\n",
      "| 28800/1000000 steps | lr 0.0047 | ms/batch 35.91 | loss  1.58 | ppl     4.84\n",
      "| 29200/1000000 steps | lr 0.0047 | ms/batch 36.82 | loss  1.58 | ppl     4.84\n",
      "| 29600/1000000 steps | lr 0.0047 | ms/batch 36.02 | loss  1.56 | ppl     4.75\n",
      "| 30000/1000000 steps | lr 0.0047 | ms/batch 36.21 | loss  1.55 | ppl     4.72\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.426 |\n",
      "| 30400/1000000 steps | lr 0.0047 | ms/batch 117.37 | loss  1.55 | ppl     4.71\n",
      "| 30800/1000000 steps | lr 0.0047 | ms/batch 35.90 | loss  1.53 | ppl     4.63\n",
      "| 31200/1000000 steps | lr 0.0047 | ms/batch 36.36 | loss  1.55 | ppl     4.71\n",
      "| 31600/1000000 steps | lr 0.0047 | ms/batch 36.52 | loss  1.55 | ppl     4.69\n",
      "| 32000/1000000 steps | lr 0.0047 | ms/batch 36.03 | loss  1.51 | ppl     4.52\n",
      "| 32400/1000000 steps | lr 0.0046 | ms/batch 35.62 | loss  1.52 | ppl     4.57\n",
      "| 32800/1000000 steps | lr 0.0046 | ms/batch 36.32 | loss  1.51 | ppl     4.53\n",
      "| 33200/1000000 steps | lr 0.0046 | ms/batch 35.99 | loss  1.50 | ppl     4.48\n",
      "| 33600/1000000 steps | lr 0.0046 | ms/batch 36.87 | loss  1.50 | ppl     4.48\n",
      "| 34000/1000000 steps | lr 0.0046 | ms/batch 37.15 | loss  1.49 | ppl     4.43\n",
      "| 34400/1000000 steps | lr 0.0046 | ms/batch 35.99 | loss  1.49 | ppl     4.45\n",
      "| 34800/1000000 steps | lr 0.0046 | ms/batch 35.95 | loss  1.49 | ppl     4.42\n",
      "| 35200/1000000 steps | lr 0.0046 | ms/batch 36.51 | loss  1.47 | ppl     4.35\n",
      "| 35600/1000000 steps | lr 0.0046 | ms/batch 35.76 | loss  1.47 | ppl     4.34\n",
      "| 36000/1000000 steps | lr 0.0046 | ms/batch 36.41 | loss  1.47 | ppl     4.34\n",
      "| 36400/1000000 steps | lr 0.0046 | ms/batch 37.73 | loss  1.46 | ppl     4.32\n",
      "| 36800/1000000 steps | lr 0.0046 | ms/batch 36.25 | loss  1.46 | ppl     4.29\n",
      "| 37200/1000000 steps | lr 0.0046 | ms/batch 35.66 | loss  1.45 | ppl     4.25\n",
      "| 37600/1000000 steps | lr 0.0046 | ms/batch 36.20 | loss  1.45 | ppl     4.24\n",
      "| 38000/1000000 steps | lr 0.0046 | ms/batch 36.50 | loss  1.45 | ppl     4.25\n",
      "| 38400/1000000 steps | lr 0.0046 | ms/batch 35.71 | loss  1.43 | ppl     4.17\n",
      "| 38800/1000000 steps | lr 0.0046 | ms/batch 36.96 | loss  1.42 | ppl     4.15\n",
      "| 39200/1000000 steps | lr 0.0046 | ms/batch 36.37 | loss  1.43 | ppl     4.17\n",
      "| 39600/1000000 steps | lr 0.0046 | ms/batch 36.12 | loss  1.42 | ppl     4.14\n",
      "| 40000/1000000 steps | lr 0.0046 | ms/batch 36.13 | loss  1.41 | ppl     4.09\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.480 |\n",
      "| 40400/1000000 steps | lr 0.0045 | ms/batch 123.08 | loss  1.40 | ppl     4.07\n",
      "| 40800/1000000 steps | lr 0.0045 | ms/batch 36.40 | loss  1.41 | ppl     4.08\n",
      "| 41200/1000000 steps | lr 0.0045 | ms/batch 36.11 | loss  1.41 | ppl     4.09\n",
      "| 41600/1000000 steps | lr 0.0045 | ms/batch 36.82 | loss  1.41 | ppl     4.09\n",
      "| 42000/1000000 steps | lr 0.0045 | ms/batch 36.63 | loss  1.38 | ppl     3.97\n",
      "| 42400/1000000 steps | lr 0.0045 | ms/batch 36.43 | loss  1.39 | ppl     4.01\n",
      "| 42800/1000000 steps | lr 0.0045 | ms/batch 35.91 | loss  1.38 | ppl     3.96\n",
      "| 43200/1000000 steps | lr 0.0045 | ms/batch 36.06 | loss  1.38 | ppl     3.97\n",
      "| 43600/1000000 steps | lr 0.0045 | ms/batch 36.46 | loss  1.38 | ppl     3.97\n",
      "| 44000/1000000 steps | lr 0.0045 | ms/batch 36.28 | loss  1.36 | ppl     3.91\n",
      "| 44400/1000000 steps | lr 0.0045 | ms/batch 35.86 | loss  1.36 | ppl     3.88\n",
      "| 44800/1000000 steps | lr 0.0045 | ms/batch 37.26 | loss  1.36 | ppl     3.89\n",
      "| 45200/1000000 steps | lr 0.0045 | ms/batch 35.80 | loss  1.35 | ppl     3.86\n",
      "| 45600/1000000 steps | lr 0.0045 | ms/batch 35.94 | loss  1.36 | ppl     3.89\n",
      "| 46000/1000000 steps | lr 0.0045 | ms/batch 36.01 | loss  1.35 | ppl     3.85\n",
      "| 46400/1000000 steps | lr 0.0045 | ms/batch 36.00 | loss  1.35 | ppl     3.84\n",
      "| 46800/1000000 steps | lr 0.0045 | ms/batch 36.03 | loss  1.33 | ppl     3.79\n",
      "| 47200/1000000 steps | lr 0.0045 | ms/batch 37.32 | loss  1.33 | ppl     3.78\n",
      "| 47600/1000000 steps | lr 0.0045 | ms/batch 36.21 | loss  1.33 | ppl     3.79\n",
      "| 48000/1000000 steps | lr 0.0045 | ms/batch 36.54 | loss  1.33 | ppl     3.78\n",
      "| 48400/1000000 steps | lr 0.0044 | ms/batch 35.47 | loss  1.31 | ppl     3.71\n",
      "| 48800/1000000 steps | lr 0.0044 | ms/batch 35.58 | loss  1.32 | ppl     3.76\n",
      "| 49200/1000000 steps | lr 0.0044 | ms/batch 35.91 | loss  1.31 | ppl     3.72\n",
      "| 49600/1000000 steps | lr 0.0044 | ms/batch 35.57 | loss  1.31 | ppl     3.70\n",
      "| 50000/1000000 steps | lr 0.0044 | ms/batch 35.72 | loss  1.30 | ppl     3.66\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.521 |\n",
      "| 50400/1000000 steps | lr 0.0044 | ms/batch 128.08 | loss  1.30 | ppl     3.68\n",
      "| 50800/1000000 steps | lr 0.0044 | ms/batch 35.86 | loss  1.30 | ppl     3.66\n",
      "| 51200/1000000 steps | lr 0.0044 | ms/batch 36.41 | loss  1.29 | ppl     3.65\n",
      "| 51600/1000000 steps | lr 0.0044 | ms/batch 35.39 | loss  1.29 | ppl     3.64\n",
      "| 52000/1000000 steps | lr 0.0044 | ms/batch 35.42 | loss  1.27 | ppl     3.57\n",
      "| 52400/1000000 steps | lr 0.0044 | ms/batch 36.25 | loss  1.30 | ppl     3.67\n",
      "| 52800/1000000 steps | lr 0.0044 | ms/batch 35.85 | loss  1.30 | ppl     3.65\n",
      "| 53200/1000000 steps | lr 0.0044 | ms/batch 36.57 | loss  1.26 | ppl     3.52\n",
      "| 53600/1000000 steps | lr 0.0044 | ms/batch 36.29 | loss  1.28 | ppl     3.61\n",
      "| 54000/1000000 steps | lr 0.0044 | ms/batch 35.57 | loss  1.27 | ppl     3.55\n",
      "| 54400/1000000 steps | lr 0.0044 | ms/batch 36.16 | loss  1.26 | ppl     3.54\n",
      "| 54800/1000000 steps | lr 0.0044 | ms/batch 36.15 | loss  1.27 | ppl     3.57\n",
      "| 55200/1000000 steps | lr 0.0044 | ms/batch 35.70 | loss  1.25 | ppl     3.49\n",
      "| 55600/1000000 steps | lr 0.0044 | ms/batch 36.12 | loss  1.26 | ppl     3.53\n",
      "| 56000/1000000 steps | lr 0.0044 | ms/batch 35.94 | loss  1.26 | ppl     3.52\n",
      "| 56400/1000000 steps | lr 0.0043 | ms/batch 36.27 | loss  1.26 | ppl     3.52\n",
      "| 56800/1000000 steps | lr 0.0043 | ms/batch 36.47 | loss  1.24 | ppl     3.45\n",
      "| 57200/1000000 steps | lr 0.0043 | ms/batch 35.93 | loss  1.24 | ppl     3.47\n",
      "| 57600/1000000 steps | lr 0.0043 | ms/batch 36.01 | loss  1.24 | ppl     3.46\n",
      "| 58000/1000000 steps | lr 0.0043 | ms/batch 36.02 | loss  1.23 | ppl     3.41\n",
      "| 58400/1000000 steps | lr 0.0043 | ms/batch 36.14 | loss  1.22 | ppl     3.40\n",
      "| 58800/1000000 steps | lr 0.0043 | ms/batch 35.97 | loss  1.23 | ppl     3.42\n",
      "| 59200/1000000 steps | lr 0.0043 | ms/batch 35.83 | loss  1.23 | ppl     3.41\n",
      "| 59600/1000000 steps | lr 0.0043 | ms/batch 35.88 | loss  1.22 | ppl     3.39\n",
      "| 60000/1000000 steps | lr 0.0043 | ms/batch 37.14 | loss  1.23 | ppl     3.42\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.548 |\n",
      "| 60400/1000000 steps | lr 0.0043 | ms/batch 129.51 | loss  1.21 | ppl     3.34\n",
      "| 60800/1000000 steps | lr 0.0043 | ms/batch 36.39 | loss  1.21 | ppl     3.37\n",
      "| 61200/1000000 steps | lr 0.0043 | ms/batch 35.97 | loss  1.22 | ppl     3.40\n",
      "| 61600/1000000 steps | lr 0.0043 | ms/batch 35.66 | loss  1.20 | ppl     3.33\n",
      "| 62000/1000000 steps | lr 0.0043 | ms/batch 35.72 | loss  1.20 | ppl     3.32\n",
      "| 62400/1000000 steps | lr 0.0043 | ms/batch 35.81 | loss  1.20 | ppl     3.33\n",
      "| 62800/1000000 steps | lr 0.0043 | ms/batch 36.05 | loss  1.20 | ppl     3.32\n",
      "| 63200/1000000 steps | lr 0.0043 | ms/batch 36.29 | loss  1.19 | ppl     3.30\n",
      "| 63600/1000000 steps | lr 0.0043 | ms/batch 37.18 | loss  1.20 | ppl     3.33\n",
      "| 64000/1000000 steps | lr 0.0043 | ms/batch 35.54 | loss  1.18 | ppl     3.26\n",
      "| 64400/1000000 steps | lr 0.0043 | ms/batch 35.81 | loss  1.19 | ppl     3.27\n",
      "| 64800/1000000 steps | lr 0.0043 | ms/batch 36.78 | loss  1.20 | ppl     3.32\n",
      "| 65200/1000000 steps | lr 0.0043 | ms/batch 35.71 | loss  1.17 | ppl     3.21\n",
      "| 65600/1000000 steps | lr 0.0043 | ms/batch 35.80 | loss  1.17 | ppl     3.23\n",
      "| 66000/1000000 steps | lr 0.0043 | ms/batch 36.49 | loss  1.17 | ppl     3.22\n",
      "| 66400/1000000 steps | lr 0.0043 | ms/batch 35.87 | loss  1.18 | ppl     3.24\n",
      "| 66800/1000000 steps | lr 0.0043 | ms/batch 36.36 | loss  1.17 | ppl     3.22\n",
      "| 67200/1000000 steps | lr 0.0043 | ms/batch 35.93 | loss  1.17 | ppl     3.22\n",
      "| 67600/1000000 steps | lr 0.0043 | ms/batch 35.96 | loss  1.16 | ppl     3.19\n",
      "| 68000/1000000 steps | lr 0.0043 | ms/batch 36.52 | loss  1.16 | ppl     3.19\n",
      "| 68400/1000000 steps | lr 0.0042 | ms/batch 35.49 | loss  1.16 | ppl     3.20\n",
      "| 68800/1000000 steps | lr 0.0042 | ms/batch 37.03 | loss  1.16 | ppl     3.18\n",
      "| 69200/1000000 steps | lr 0.0042 | ms/batch 36.38 | loss  1.16 | ppl     3.19\n",
      "| 69600/1000000 steps | lr 0.0042 | ms/batch 35.97 | loss  1.15 | ppl     3.14\n",
      "| 70000/1000000 steps | lr 0.0042 | ms/batch 36.13 | loss  1.15 | ppl     3.15\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.573 |\n",
      "| 70400/1000000 steps | lr 0.0042 | ms/batch 127.28 | loss  1.14 | ppl     3.14\n",
      "| 70800/1000000 steps | lr 0.0042 | ms/batch 36.02 | loss  1.15 | ppl     3.15\n",
      "| 71200/1000000 steps | lr 0.0042 | ms/batch 36.68 | loss  1.13 | ppl     3.09\n",
      "| 71600/1000000 steps | lr 0.0042 | ms/batch 36.43 | loss  1.15 | ppl     3.15\n",
      "| 72000/1000000 steps | lr 0.0042 | ms/batch 35.92 | loss  1.14 | ppl     3.13\n",
      "| 72400/1000000 steps | lr 0.0042 | ms/batch 35.59 | loss  1.13 | ppl     3.11\n",
      "| 72800/1000000 steps | lr 0.0042 | ms/batch 35.82 | loss  1.11 | ppl     3.05\n",
      "| 73200/1000000 steps | lr 0.0042 | ms/batch 36.33 | loss  1.13 | ppl     3.11\n",
      "| 73600/1000000 steps | lr 0.0042 | ms/batch 36.09 | loss  1.13 | ppl     3.08\n",
      "| 74000/1000000 steps | lr 0.0042 | ms/batch 36.34 | loss  1.12 | ppl     3.07\n",
      "| 74400/1000000 steps | lr 0.0042 | ms/batch 36.25 | loss  1.12 | ppl     3.07\n",
      "| 74800/1000000 steps | lr 0.0042 | ms/batch 36.32 | loss  1.13 | ppl     3.09\n",
      "| 75200/1000000 steps | lr 0.0042 | ms/batch 36.12 | loss  1.11 | ppl     3.03\n",
      "| 75600/1000000 steps | lr 0.0042 | ms/batch 36.87 | loss  1.12 | ppl     3.07\n",
      "| 76000/1000000 steps | lr 0.0042 | ms/batch 35.88 | loss  1.11 | ppl     3.03\n",
      "| 76400/1000000 steps | lr 0.0041 | ms/batch 36.04 | loss  1.11 | ppl     3.04\n",
      "| 76800/1000000 steps | lr 0.0041 | ms/batch 36.16 | loss  1.11 | ppl     3.03\n",
      "| 77200/1000000 steps | lr 0.0041 | ms/batch 36.03 | loss  1.10 | ppl     3.02\n",
      "| 77600/1000000 steps | lr 0.0041 | ms/batch 35.81 | loss  1.10 | ppl     3.01\n",
      "| 78000/1000000 steps | lr 0.0041 | ms/batch 36.91 | loss  1.10 | ppl     2.99\n",
      "| 78400/1000000 steps | lr 0.0041 | ms/batch 35.45 | loss  1.10 | ppl     3.01\n",
      "| 78800/1000000 steps | lr 0.0041 | ms/batch 35.85 | loss  1.10 | ppl     3.00\n",
      "| 79200/1000000 steps | lr 0.0041 | ms/batch 35.84 | loss  1.09 | ppl     2.97\n",
      "| 79600/1000000 steps | lr 0.0041 | ms/batch 35.58 | loss  1.08 | ppl     2.95\n",
      "| 80000/1000000 steps | lr 0.0041 | ms/batch 35.94 | loss  1.10 | ppl     3.00\n",
      "Evaluating model\n",
      "| EVALUATION |     0/   59 batches |\n",
      "| EVALUATION |    19/   59 batches |\n",
      "| EVALUATION |    38/   59 batches |\n",
      "| EVALUATION |    57/   59 batches |\n",
      "| EVALUATION | BLEU: 0.599 |\n",
      "| 80400/1000000 steps | lr 0.0041 | ms/batch 124.02 | loss  1.09 | ppl     2.98\n",
      "| 80800/1000000 steps | lr 0.0041 | ms/batch 35.65 | loss  1.08 | ppl     2.96\n",
      "| 81200/1000000 steps | lr 0.0041 | ms/batch 35.57 | loss  1.08 | ppl     2.94\n",
      "| 81600/1000000 steps | lr 0.0041 | ms/batch 35.38 | loss  1.09 | ppl     2.96\n",
      "| 82000/1000000 steps | lr 0.0041 | ms/batch 35.70 | loss  1.08 | ppl     2.94\n",
      "| 82400/1000000 steps | lr 0.0041 | ms/batch 36.68 | loss  1.08 | ppl     2.95\n",
      "| 82800/1000000 steps | lr 0.0041 | ms/batch 37.13 | loss  1.09 | ppl     2.96\n",
      "| 83200/1000000 steps | lr 0.0041 | ms/batch 35.16 | loss  1.07 | ppl     2.90\n",
      "| 83600/1000000 steps | lr 0.0041 | ms/batch 36.38 | loss  1.07 | ppl     2.92\n",
      "| 84000/1000000 steps | lr 0.0041 | ms/batch 35.71 | loss  1.07 | ppl     2.92\n",
      "| 84400/1000000 steps | lr 0.0040 | ms/batch 36.34 | loss  1.07 | ppl     2.90\n",
      "| 84800/1000000 steps | lr 0.0040 | ms/batch 35.61 | loss  1.06 | ppl     2.90\n",
      "| 85200/1000000 steps | lr 0.0040 | ms/batch 35.69 | loss  1.07 | ppl     2.90\n",
      "| 85600/1000000 steps | lr 0.0040 | ms/batch 36.99 | loss  1.06 | ppl     2.89\n",
      "| 86000/1000000 steps | lr 0.0040 | ms/batch 35.63 | loss  1.06 | ppl     2.89\n",
      "| 86400/1000000 steps | lr 0.0040 | ms/batch 36.03 | loss  1.05 | ppl     2.84\n"
     ]
    }
   ],
   "source": [
    "def train(steps=10000, log_interval=200, learning_interval=4000, eval_interval=1000):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    step = 1\n",
    "    for batch in train_iterator:\n",
    "        loss = train_step(batch)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if step % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| {:5d}/{:5d} steps | '\n",
    "                  'lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    step, steps, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "        if step % eval_interval == 0:\n",
    "            print(\"Evaluating model\")\n",
    "            evaluate()\n",
    "            model.train()\n",
    "        \n",
    "        if step % learning_interval == 0:\n",
    "            scheduler.step()\n",
    "        \n",
    "        step += 1\n",
    "        if step >= steps:\n",
    "            print(\"Finished training\")\n",
    "\n",
    "\n",
    "\n",
    "            return\n",
    "\n",
    "train(steps=config.train_steps,eval_interval=config.eval_interval,log_interval=config.log_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((model, optimizer, scheduler, stoi, itos), \"./saved_copy_gen_DJANGO_vcb1600_maxSeq500_79BLEU.pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
