{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Facebook AI's adaptive span transformer to model code\n",
    "This implementation of the transformer uses a smaller context window for the attention. The ooriginal model is trained on characters on the traditional language modeling task.\n",
    "\n",
    "I'm using a huggingface bytePairEncoding tokenizer to make word peices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"src/external_repos/adaptive_span\")\n",
    "from config import PARAMS_CONFIG\n",
    "from data import get_train_val_test_data, Corpus, _get_train_val_test_data\n",
    "from models import TransformerSeq\n",
    "from trainer import train_iteration, full_eval\n",
    "from utils import (\n",
    "    get_params,\n",
    "    set_up_env,\n",
    "    get_optimizer_and_scheduler,\n",
    "    load_checkpoint,\n",
    "    save_checkpoint,\n",
    "    Logger)\n",
    "from main import launch\n",
    "import tqdm.notebook as tqdm \n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training a custom tokenizer\n",
    "```python\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train(files=[\"code_corpus_train.txt\"], vocab_size=32_000, min_frequency=2)\n",
    "tokenizer.save(\".\", \"code_bpe_hugging_32k\")\n",
    "tokenizer = ByteLevelBPETokenizer(\"code_bpe_hugging_32k-vocab.json\",\"code_bpe_hugging_32k-merges.txt\",)\n",
    "\n",
    "sent = \"print('hello world!')\"\n",
    "ids = tokenizer.encode(sent).ids\n",
    "print(\"token ids: \",ids)\n",
    "print(\"token ids: \",tokenizer.encode(sent).tokens)\n",
    "tokenizer.decode(ids)\n",
    "```\n",
    "\n",
    "## Tokenising already existing files into a format understood by the scripts\n",
    "```python\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\"datasets/code_search_net/code_bpe_hugging_32k-vocab.json\",\"datasets/code_search_net/code_bpe_hugging_32k-merges.txt\",)\n",
    "\n",
    "train_fps = (\"datasets/code_search_net/code_corpus_train.txt\", \"train.txt\")\n",
    "valid_fps = (\"datasets/code_search_net/code_corpus_valid.txt\", \"valid.txt\")\n",
    "test_fps = (\"datasets/code_search_net/code_corpus_test.txt\", \"test.txt\")\n",
    "\n",
    "for source_file, target_file in [train_fps, valid_fps, test_fps]:\n",
    "    with open(source_file, \"r\") as src_fp:\n",
    "        file_len = sum(1 for line in (src_fp))\n",
    "    with open(source_file, \"r\") as src_fp, open(target_file, \"w\") as tgt_fp:\n",
    "        pbar = tqdm.tqdm(src_fp, total=file_len)\n",
    "        for line in pbar:\n",
    "            ids = tokenizer.encode(line).ids\n",
    "            tgt_fp.write(' '.join(str(x) for x in ids)+\"\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'env_params': {'distributed': False, 'local_rank': 0}, \n",
    "                'data_params': {'data_path': 'datasets/code_search_net/tokenised'}, \n",
    "                'model_params': {'hidden_size': 256, \n",
    "                                 'inner_hidden_size': 1024, \n",
    "                                 'nb_layers': 8, \n",
    "                                 'block_size': 64, \n",
    "                                 'nb_heads': 4, \n",
    "                                 'attn_span': 1024, \n",
    "                                 'dropout': 0.2}, \n",
    "                'optim_params': {'lr': 0.00, \n",
    "                                 'momentum': 0, \n",
    "                                 'optim': 'adagrad', \n",
    "                                 'lr_warmup': 8000, \n",
    "                                 'grad_clip': 0.03}, \n",
    "                'trainer_params': {'batch_size': 128, \n",
    "                                   'batch_split': 1, \n",
    "                                   'nb_batches_per_iter': 1000, \n",
    "                                   'nb_iter': 150, \n",
    "                                   'checkpoint_path': 'code_adaptive_transformer_save', \n",
    "                                   'full_eval_mode': False}, \n",
    "                'adapt_span_params': {'adapt_span_enabled': True, \n",
    "                                      'adapt_span_loss': 0.000002, \n",
    "                                      'adapt_span_ramp': 32, \n",
    "                                      'adapt_span_init': 4, \n",
    "                                      'adapt_span_cache': True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_params:\t {'hidden_size': 256, 'inner_hidden_size': 1024, 'nb_layers': 8, 'block_size': 64, 'nb_heads': 4, 'attn_span': 32, 'dropout': 0.2}\n",
      "optim_params:\t {'lr': 0.0, 'momentum': 0, 'optim': 'adagrad', 'lr_warmup': 8000, 'grad_clip': 0.03}\n",
      "data_params:\t {'data_path': 'datasets/code_search_net/tokenised'}\n",
      "trainer_params:\t {'batch_size': 128, 'batch_split': 1, 'nb_batches_per_iter': 1000, 'nb_iter': 150, 'checkpoint_path': 'code_adaptive_transformer_save', 'full_eval_mode': False}\n",
      "adapt_span_params:\t {'adapt_span_enabled': True, 'adapt_span_loss': 2e-06, 'adapt_span_ramp': 32, 'adapt_span_init': 4, 'adapt_span_cache': True}\n",
      "Loading an existing corpus file from datasets/code_search_net/tokenised/corpus.pt\n",
      "nb_parameters=22.67M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-88c4a0191397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nfs/phd_by_carlos/notebooks/src/external_repos/adaptive_span/main.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(env_params, model_params, adapt_span_params, optim_params, data_params, trainer_params)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_batches_per_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'block_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             trainer_params['batch_split'])\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_sta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnb_batches_per_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/phd_by_carlos/notebooks/src/external_repos/adaptive_span/trainer.py\u001b[0m in \u001b[0;36mtrain_iteration\u001b[0;34m(model, optimizer, scheduler, data, nb_batches_per_iter, block_size, eval_only, train_pos, h_cache, batch_split)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mh_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0meval_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             batch_split=batch_split)\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mloss_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtrain_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/phd_by_carlos/notebooks/src/external_repos/adaptive_span/trainer.py\u001b[0m in \u001b[0;36m_train_batch\u001b[0;34m(model, optimizer, scheduler, X, Y, h_cache, eval_only, batch_split)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_split\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# process a batch in a single step (default behaviour)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# split a batch into multiple pieces that each can fit in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/phd_by_carlos/notebooks/src/external_repos/adaptive_span/trainer.py\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(model, X, Y, h_cache, eval_only, loss_div)\u001b[0m\n\u001b[1;32m     29\u001b[0m                         for layer in model.module.layers)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mloss_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "launch(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_state = torch.load(\"./saved_models/code_adaptive_span_sved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSeq(vocab_size=31886, **params[\"model_params\"],adapt_span_params=params[\"adapt_span_params\"])\n",
    "model = torch.nn.DataParallel(model).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module.key_pe',\n",
       "              tensor([[[-0.5509,  0.4127,  0.4396,  ...,  1.1414,  0.0569,  2.2597],\n",
       "                       [ 1.5849,  2.3193,  0.9480,  ..., -0.3057, -0.5050, -1.2480],\n",
       "                       [ 0.6352,  2.1086,  1.8249,  ..., -0.1262, -0.9029, -1.6015],\n",
       "                       ...,\n",
       "                       [-2.4559, -1.6373, -1.0293,  ...,  0.5551,  1.0159,  1.1841],\n",
       "                       [ 0.8418, -0.6450,  0.4996,  ..., -0.1534, -0.4597, -0.4217],\n",
       "                       [ 1.4326,  0.5642,  1.4460,  ...,  0.7697,  0.1855, -0.1256]]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.in_emb.weight',\n",
       "              tensor([[ 1.2830,  1.1185, -0.1138,  ..., -1.8475, -0.7691,  0.6811],\n",
       "                      [ 1.0629, -1.6809,  0.9716,  ..., -0.3081,  2.0924,  0.7215],\n",
       "                      [-0.3928,  1.0188,  0.7129,  ..., -0.2347, -0.4224,  1.1415],\n",
       "                      ...,\n",
       "                      [-1.0662,  0.2969,  0.5476,  ..., -1.3524,  0.2323, -0.7668],\n",
       "                      [-0.5106,  0.4777, -0.2542,  ..., -1.3966, -1.5912, -0.1213],\n",
       "                      [-0.0165, -0.0321,  1.4957,  ..., -1.8334,  0.3707,  0.8851]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.out_emb.weight',\n",
       "              tensor([[ 0.0656, -0.0455, -0.0196,  ..., -0.0432,  0.0119,  0.0973],\n",
       "                      [ 0.0234,  0.0494,  0.0062,  ..., -0.0038, -0.0100, -0.0449],\n",
       "                      [ 0.0696, -0.0210, -0.0250,  ...,  0.0478,  0.0161,  0.0541],\n",
       "                      ...,\n",
       "                      [ 0.0225, -0.0136, -0.0007,  ..., -0.0272,  0.0471, -0.0519],\n",
       "                      [-0.0406,  0.0598,  0.0465,  ..., -0.0320,  0.0279, -0.0617],\n",
       "                      [ 0.0168,  0.0103,  0.0403,  ..., -0.0286,  0.0401,  0.0183]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.out_emb.bias',\n",
       "              tensor([ 0.1869, -0.0295,  0.2851,  ..., -0.3246, -0.3071, -0.3366],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.0.attn.attn.adaptive_span._mask.current_val',\n",
       "              tensor([[[0.0301]],\n",
       "              \n",
       "                      [[0.0133]],\n",
       "              \n",
       "                      [[0.0593]],\n",
       "              \n",
       "                      [[0.0808]]], device='cuda:0')),\n",
       "             ('module.layers.0.attn.attn.adaptive_span._mask.mask_template',\n",
       "              tensor([-1.0230e+03, -1.0220e+03, -1.0210e+03,  ..., -2.0000e+00,\n",
       "                      -1.0000e+00,  0.0000e+00], device='cuda:0')),\n",
       "             ('module.layers.0.attn.proj_query.weight',\n",
       "              tensor([[-0.0960,  0.0389,  0.0642,  ...,  0.0394,  0.0182, -0.0026],\n",
       "                      [-0.0165, -0.0619, -0.0203,  ...,  0.1227, -0.0421,  0.0217],\n",
       "                      [ 0.0009, -0.0755, -0.0639,  ..., -0.0500,  0.0599,  0.0186],\n",
       "                      ...,\n",
       "                      [-0.0338,  0.0626,  0.0408,  ..., -0.0794,  0.0422,  0.0173],\n",
       "                      [ 0.1296,  0.0605, -0.1064,  ..., -0.0261, -0.0965, -0.0589],\n",
       "                      [-0.0117, -0.0895,  0.0451,  ...,  0.1001,  0.0764, -0.0740]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.0.attn.proj_out.weight',\n",
       "              tensor([[-0.0466,  0.0159,  0.0288,  ..., -0.0019, -0.0160,  0.0009],\n",
       "                      [ 0.0431, -0.0969,  0.0627,  ..., -0.0409,  0.0718,  0.0782],\n",
       "                      [ 0.0660, -0.0636,  0.0270,  ..., -0.0082, -0.0476,  0.0429],\n",
       "                      ...,\n",
       "                      [ 0.0033, -0.0763,  0.0426,  ..., -0.0405, -0.0572,  0.0066],\n",
       "                      [ 0.0225,  0.0035, -0.0017,  ..., -0.0293,  0.0216,  0.0413],\n",
       "                      [ 0.0197,  0.0178, -0.0666,  ...,  0.0463,  0.0944, -0.1225]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.0.attn.proj_val.weight',\n",
       "              tensor([[-0.0712, -0.0808,  0.0894,  ..., -0.0333, -0.0685, -0.0368],\n",
       "                      [-0.0251, -0.0970, -0.0694,  ..., -0.0344, -0.0329, -0.0391],\n",
       "                      [ 0.0283,  0.0421, -0.0036,  ...,  0.0603,  0.0882, -0.0315],\n",
       "                      ...,\n",
       "                      [-0.0002,  0.0332, -0.0189,  ..., -0.0386,  0.0714, -0.0050],\n",
       "                      [ 0.0842,  0.0258, -0.0420,  ...,  0.0257, -0.0044,  0.0318],\n",
       "                      [-0.1053, -0.0456,  0.0436,  ..., -0.0512, -0.0491,  0.0562]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.0.attn.proj_key.weight',\n",
       "              tensor([[ 0.1188, -0.0633, -0.2012,  ..., -0.0242,  0.0100, -0.1305],\n",
       "                      [-0.0031,  0.1223, -0.0607,  ..., -0.0354,  0.1826,  0.0706],\n",
       "                      [ 0.0574,  0.0501, -0.0433,  ...,  0.1134,  0.0144, -0.0094],\n",
       "                      ...,\n",
       "                      [-0.0861,  0.1148,  0.0422,  ...,  0.0817, -0.0059,  0.0159],\n",
       "                      [-0.0421,  0.0078,  0.0305,  ..., -0.0088,  0.0362,  0.0125],\n",
       "                      [ 0.0160,  0.0416,  0.0540,  ...,  0.0308,  0.0023,  0.1477]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.0.ff.fc1.weight',\n",
       "              tensor([[ 0.0002,  0.0387,  0.0125,  ..., -0.0161, -0.0408,  0.0735],\n",
       "                      [ 0.0549, -0.1290,  0.0248,  ...,  0.1358, -0.0627,  0.1088],\n",
       "                      [ 0.0868, -0.1040, -0.0288,  ...,  0.0022, -0.0029,  0.0120],\n",
       "                      ...,\n",
       "                      [-0.1169, -0.0396,  0.0019,  ...,  0.0825, -0.0831,  0.0383],\n",
       "                      [-0.0776, -0.0320,  0.1286,  ..., -0.1636, -0.0014, -0.0542],\n",
       "                      [-0.0295, -0.0360,  0.0223,  ...,  0.1198, -0.1183,  0.0034]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.0.ff.fc1.bias',\n",
       "              tensor([-0.0915, -0.0048, -0.1333,  ..., -0.2447, -0.1637, -0.1708],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.0.ff.fc2.weight',\n",
       "              tensor([[ 2.4786e-02, -3.2994e-02, -4.2951e-02,  ...,  3.0459e-02,\n",
       "                       -4.7985e-02, -4.7685e-03],\n",
       "                      [-5.3751e-03, -2.2904e-02,  3.1046e-03,  ...,  4.4974e-02,\n",
       "                       -4.8359e-02,  4.6401e-02],\n",
       "                      [ 1.6753e-02, -9.0478e-03,  2.7715e-02,  ...,  4.3946e-02,\n",
       "                       -2.9846e-02,  4.5810e-02],\n",
       "                      ...,\n",
       "                      [ 2.4803e-02,  1.0811e-02,  4.2276e-02,  ..., -2.1260e-02,\n",
       "                       -8.0551e-02,  3.5048e-02],\n",
       "                      [-3.0550e-02, -6.2673e-05,  1.8018e-02,  ...,  3.5582e-02,\n",
       "                       -6.6574e-02,  2.2132e-02],\n",
       "                      [-2.4729e-02,  2.8066e-02,  7.4720e-02,  ..., -3.9394e-02,\n",
       "                       -2.1703e-04,  1.3770e-02]], device='cuda:0')),\n",
       "             ('module.layers.0.ff.fc2.bias',\n",
       "              tensor([-5.6685e-02, -1.5705e-02, -5.2708e-03, -7.2852e-03, -1.7760e-02,\n",
       "                       1.1121e-03,  9.4506e-03,  7.9538e-02, -3.4313e-02,  2.2490e-02,\n",
       "                       1.4183e-02,  5.1643e-03, -1.6894e-02, -3.7229e-04,  2.0675e-02,\n",
       "                      -2.7740e-02,  2.2965e-02,  2.0310e-02, -1.4555e-02,  1.8328e-02,\n",
       "                       3.8636e-02,  9.0544e-02,  1.6826e-03, -6.5723e-03, -1.7529e-02,\n",
       "                       1.4960e-02, -1.8636e-02,  4.2467e-02, -2.3186e-02, -6.8118e-03,\n",
       "                      -3.6564e-02, -4.6577e-02, -3.4878e-02,  2.2691e-02,  2.4880e-02,\n",
       "                      -5.6732e-02, -4.9741e-02,  2.4832e-02, -7.8882e-03,  3.3545e-02,\n",
       "                       6.7871e-03,  7.4053e-03, -7.9719e-03, -3.6200e-02,  4.3674e-02,\n",
       "                       5.4752e-02, -4.6432e-02,  7.1573e-03,  1.5629e-02,  3.5213e-02,\n",
       "                       8.6024e-03,  1.1654e-02,  4.4544e-02, -2.8345e-02,  1.4529e-01,\n",
       "                      -1.2352e-03, -1.8158e-02,  4.1301e-02, -4.3143e-03, -2.1787e-02,\n",
       "                      -4.3220e-02, -7.2990e-03, -6.8558e-03,  2.3216e-02, -6.0576e-03,\n",
       "                      -5.8053e-03, -2.4137e-02, -5.0960e-02,  4.3203e-02, -6.1981e-02,\n",
       "                       7.3809e-02, -9.8217e-03,  4.3757e-02, -8.0052e-02,  1.6535e-04,\n",
       "                      -1.4137e-02,  1.2775e-02,  2.2918e-02,  7.3325e-02,  9.0362e-02,\n",
       "                       1.5073e-02,  3.1522e-02,  2.5775e-02, -5.2042e-02, -2.6333e-02,\n",
       "                      -5.4573e-02, -4.8074e-02,  2.3584e-03,  1.0138e-02, -3.7344e-02,\n",
       "                      -3.8334e-02,  3.7602e-02, -6.3043e-03, -1.0770e-02, -4.9947e-02,\n",
       "                      -6.2418e-02, -1.8641e-02, -6.1804e-02,  3.7951e-02,  2.4453e-02,\n",
       "                      -3.6730e-02,  6.8496e-04,  1.5553e-02, -2.5048e-02, -1.3044e-03,\n",
       "                      -2.8638e-04,  4.0317e-03,  9.6594e-03, -8.5093e-02, -1.9429e-02,\n",
       "                      -5.2026e-03,  2.0761e-02, -3.6662e-02,  8.8454e-02,  6.5284e-03,\n",
       "                      -5.1236e-02, -1.7767e-02, -2.9441e-02,  1.9117e-02, -6.8897e-02,\n",
       "                       2.6329e-02,  4.2838e-03, -1.3177e-02,  1.2404e-02,  4.6031e-02,\n",
       "                      -3.0956e-02,  2.5965e-02,  6.4674e-03,  2.2535e-02, -5.9486e-02,\n",
       "                      -3.2972e-02,  3.2241e-02,  4.5869e-03, -1.6059e-02,  5.0654e-02,\n",
       "                      -1.2263e-02, -2.9558e-02,  4.0117e-02,  1.2016e-02, -5.0688e-02,\n",
       "                       2.8236e-02, -3.3622e-03,  1.5056e-02,  5.2832e-02, -2.0823e-02,\n",
       "                       2.3282e-02,  5.6874e-02, -2.6417e-02,  1.5654e-02, -2.7508e-02,\n",
       "                       2.1313e-02, -1.5746e-02, -1.5526e-02, -3.3457e-02, -6.5922e-02,\n",
       "                       5.9696e-02,  1.6449e-02, -1.0220e-02,  1.5078e-02,  4.2916e-02,\n",
       "                      -3.3135e-02,  4.5013e-02,  1.5842e-02,  3.3667e-02,  3.8978e-02,\n",
       "                      -3.8666e-02, -1.6442e-02,  4.6010e-02, -2.9157e-02,  3.5551e-02,\n",
       "                      -4.4586e-03,  5.8612e-03, -5.7782e-02,  3.2381e-02,  2.6839e-03,\n",
       "                      -4.2039e-02, -9.4864e-02,  4.9374e-02, -6.1794e-02,  1.7110e-02,\n",
       "                      -3.1816e-03, -1.3814e-02, -3.6440e-02, -5.2075e-02, -4.4249e-03,\n",
       "                      -7.1304e-03, -5.1271e-02,  4.4906e-02, -6.5066e-03,  5.2320e-02,\n",
       "                       3.9863e-03,  2.8412e-02,  1.0523e-01,  2.2444e-05, -4.2932e-02,\n",
       "                      -2.1198e-02,  1.6763e-02, -3.2331e-02, -3.1667e-02,  1.1869e-02,\n",
       "                       4.8366e-02, -1.1964e-02, -1.3922e-02, -1.2475e-03, -1.2518e-02,\n",
       "                      -6.6728e-03, -5.0484e-01, -6.1992e-02,  2.8249e-02, -7.0198e-03,\n",
       "                      -1.1391e-02, -6.8164e-02,  2.1892e-02, -1.7961e-03,  5.3048e-02,\n",
       "                       5.1718e-03,  1.0094e-02, -3.6609e-02, -2.0005e-02, -3.0705e-03,\n",
       "                       5.0841e-02,  1.5795e-02, -4.4938e-02, -6.7743e-02, -6.3824e-02,\n",
       "                      -8.9162e-02, -6.6878e-02,  2.0089e-02, -2.8621e-02,  5.2407e-02,\n",
       "                       9.8054e-03, -2.3818e-02, -8.0776e-02, -1.4830e-02, -3.5568e-02,\n",
       "                       7.3092e-03,  5.0187e-02,  6.7442e-02, -2.5070e-02,  7.4624e-02,\n",
       "                      -2.6685e-02,  3.9838e-02,  7.4872e-02, -1.2714e-02,  4.5863e-02,\n",
       "                      -7.7296e-03,  2.0595e-02,  3.7152e-02,  1.2570e-02, -3.2373e-02,\n",
       "                       1.0609e-01,  3.0737e-02, -1.2236e-02, -4.0435e-03,  7.6030e-02,\n",
       "                      -3.6992e-02], device='cuda:0')),\n",
       "             ('module.layers.0.norm1.weight',\n",
       "              tensor([0.8852, 0.9532, 0.9442, 1.0441, 0.9619, 1.0850, 1.0034, 0.9251, 1.0308,\n",
       "                      0.8997, 0.9896, 0.9545, 0.9785, 1.1606, 1.0065, 1.0056, 1.0658, 0.9689,\n",
       "                      1.0857, 1.2840, 0.9624, 1.1740, 1.0206, 0.9493, 0.9583, 0.9564, 0.9475,\n",
       "                      0.9613, 0.9931, 1.0091, 1.1506, 0.9977, 1.0097, 1.0000, 0.9820, 0.9465,\n",
       "                      1.0377, 0.9595, 0.9993, 0.9417, 0.9516, 0.9862, 1.0720, 1.0844, 1.0195,\n",
       "                      0.9659, 1.0422, 1.0107, 0.9837, 0.9613, 0.9503, 1.0072, 0.9649, 0.9832,\n",
       "                      1.2986, 0.9969, 0.9531, 0.9699, 1.1123, 1.0773, 0.9204, 0.9598, 0.9770,\n",
       "                      1.0256, 0.9548, 1.0416, 1.0333, 0.9622, 0.9575, 1.0594, 0.9702, 0.9586,\n",
       "                      0.9579, 0.9568, 0.9717, 1.0070, 1.0191, 1.0386, 1.0297, 1.0171, 1.0212,\n",
       "                      0.9556, 0.9545, 0.9737, 1.0783, 1.1696, 0.9959, 0.9620, 1.0129, 0.9746,\n",
       "                      1.1078, 1.0081, 1.0521, 0.9334, 1.0433, 0.9841, 1.0125, 1.0282, 0.9850,\n",
       "                      0.9398, 0.9538, 0.9873, 1.0671, 0.9772, 0.9457, 0.9577, 0.9894, 0.9279,\n",
       "                      0.9996, 0.9972, 1.0215, 1.0304, 1.0379, 1.0074, 1.0574, 0.9699, 1.0069,\n",
       "                      0.9505, 1.0302, 0.9750, 0.9931, 0.9850, 1.0707, 0.9388, 1.0357, 0.9974,\n",
       "                      0.9452, 0.9613, 0.9939, 1.0570, 0.9948, 1.0045, 1.0732, 1.0205, 0.9693,\n",
       "                      1.0242, 1.0348, 1.0137, 0.9557, 1.0023, 1.0179, 1.0449, 1.0650, 1.0320,\n",
       "                      1.1165, 0.9660, 1.0368, 1.0261, 1.0111, 0.9951, 1.0029, 0.9869, 0.9728,\n",
       "                      1.0332, 1.0139, 1.0183, 1.0344, 0.9710, 0.9610, 0.9533, 1.0164, 0.9468,\n",
       "                      1.4153, 1.0145, 1.0326, 1.0841, 0.9902, 1.0089, 0.9716, 0.9517, 0.9736,\n",
       "                      1.0002, 0.9341, 1.0159, 0.9867, 0.9906, 1.1848, 1.0683, 0.9145, 1.0698,\n",
       "                      1.0379, 0.9719, 0.9375, 0.9511, 1.1182, 1.0002, 0.9669, 1.0086, 0.9765,\n",
       "                      0.9297, 1.0003, 0.9798, 1.0307, 1.0238, 0.9411, 1.0380, 0.9875, 1.0394,\n",
       "                      0.9134, 0.9397, 1.0158, 0.9914, 0.9134, 1.0033, 0.9891, 0.9864, 1.8173,\n",
       "                      0.9984, 1.0401, 0.9668, 1.0741, 0.9647, 0.9781, 1.0870, 0.9925, 0.9411,\n",
       "                      1.0759, 0.9783, 1.0061, 1.0134, 0.9632, 1.0020, 0.9678, 0.9662, 0.9925,\n",
       "                      1.2278, 0.9526, 0.9722, 0.9180, 1.0775, 0.9764, 1.0144, 0.9924, 0.9523,\n",
       "                      1.0005, 0.9708, 1.0224, 0.9399, 0.9833, 0.9217, 0.9943, 1.0188, 0.9623,\n",
       "                      1.0230, 0.9442, 1.0009, 0.9520, 1.1062, 1.0195, 0.9383, 0.9933, 1.0796,\n",
       "                      1.0027, 1.0533, 1.0329, 1.0062], device='cuda:0')),\n",
       "             ('module.layers.0.norm1.bias',\n",
       "              tensor([ 3.8084e-02,  8.3809e-02, -1.7955e-02, -2.6431e-02, -2.3339e-02,\n",
       "                      -1.4128e-01, -2.2074e-02,  3.7500e-04,  2.5331e-02,  9.1616e-02,\n",
       "                       5.8907e-02,  4.1586e-02, -5.3783e-02,  1.2312e-01, -5.9481e-03,\n",
       "                       7.8363e-02,  2.3716e-02,  2.5455e-03, -7.5075e-02,  2.5670e-02,\n",
       "                      -9.4587e-02,  8.8428e-02,  1.5890e-02,  5.1693e-03, -9.1522e-02,\n",
       "                      -4.6489e-02,  5.3481e-02, -8.0518e-02, -9.3044e-02,  7.1113e-02,\n",
       "                      -1.7989e-01,  1.6415e-02,  5.3918e-02,  4.7034e-02, -7.2947e-02,\n",
       "                      -4.1970e-02, -1.6003e-02, -1.7200e-01, -1.7492e-02,  1.0610e-01,\n",
       "                       6.3686e-03,  1.6724e-01, -1.3624e-01,  3.9379e-02, -7.4504e-03,\n",
       "                       6.9135e-02,  4.2714e-02, -8.8354e-02, -1.6870e-02,  1.0422e-02,\n",
       "                      -5.9338e-03,  6.8204e-02,  1.7744e-02, -5.3395e-02,  1.5381e-01,\n",
       "                       8.5651e-02,  1.0290e-01,  1.8825e-02, -5.6148e-02, -1.4455e-01,\n",
       "                       3.5042e-02, -6.6112e-02, -2.7973e-02, -1.9388e-01, -2.3551e-02,\n",
       "                       1.3240e-01, -1.0777e-01,  7.0292e-02,  7.9816e-02,  1.3909e-01,\n",
       "                      -9.2725e-02, -3.4680e-02, -7.3630e-02, -1.9102e-02, -9.5831e-02,\n",
       "                       3.9535e-02, -4.6479e-02,  2.6145e-02,  1.0455e-01, -8.2598e-02,\n",
       "                      -1.0569e-01,  3.4762e-03, -2.5623e-02,  2.4847e-02,  8.1146e-02,\n",
       "                      -1.5878e-01, -7.0273e-02,  1.0352e-01,  3.1001e-02, -1.3407e-02,\n",
       "                       4.5884e-02, -5.9135e-04,  5.2349e-02,  7.1847e-02,  1.0634e-01,\n",
       "                       6.3640e-02,  3.1493e-02, -7.0110e-02, -6.5582e-02,  5.1907e-03,\n",
       "                       2.9119e-02, -1.3706e-01, -2.2520e-01,  7.4670e-02, -9.0960e-03,\n",
       "                       9.0814e-03, -5.2688e-02, -3.7247e-02, -1.1407e-01,  7.6995e-02,\n",
       "                       6.8974e-02,  3.0915e-02,  1.9639e-02,  9.7305e-02, -2.0465e-02,\n",
       "                       1.1106e-02,  5.3915e-02, -2.8726e-02,  2.7425e-02, -8.5798e-02,\n",
       "                       1.8122e-01, -2.3000e-02,  6.2223e-05, -3.7812e-02,  5.8065e-02,\n",
       "                       1.3331e-01, -3.4003e-02, -7.8996e-02,  5.9192e-02,  2.0349e-02,\n",
       "                       4.3417e-02,  1.0199e-02,  5.5125e-02, -6.1681e-03,  2.1345e-02,\n",
       "                       5.6187e-02, -1.5089e-01,  5.7374e-02,  9.9431e-02,  3.2648e-02,\n",
       "                       1.2781e-01, -8.4278e-02,  7.6839e-02, -6.3873e-03,  1.2855e-05,\n",
       "                      -1.2250e-01,  2.2387e-02,  7.9532e-02,  1.0041e-01,  1.0235e-01,\n",
       "                      -4.6562e-03,  3.8830e-02,  2.2525e-02,  7.7688e-03,  1.4909e-02,\n",
       "                      -5.1001e-03, -6.8713e-02, -2.6759e-02,  7.2855e-02, -3.1162e-02,\n",
       "                       3.3661e-02,  3.3700e-02,  6.7304e-02, -6.2206e-02, -2.2862e-01,\n",
       "                       7.1349e-02,  9.3525e-02, -6.6315e-02,  2.1890e-02,  1.5860e-02,\n",
       "                       4.3622e-03,  7.3324e-02, -1.8379e-02,  8.8856e-02,  1.1697e-02,\n",
       "                       1.5844e-02,  3.2518e-02, -1.5267e-01, -5.6912e-03,  3.4635e-02,\n",
       "                      -7.5376e-02, -3.9420e-02,  6.6841e-02, -1.7025e-02, -2.7870e-02,\n",
       "                       1.1462e-01,  5.9988e-02, -1.7926e-01, -1.7973e-02, -1.3495e-01,\n",
       "                      -6.1042e-02, -1.0008e-01, -9.2386e-03,  9.0096e-03, -1.8252e-02,\n",
       "                      -9.5259e-02, -3.2740e-03, -6.8006e-02, -1.3318e-01,  8.3198e-02,\n",
       "                      -1.6236e-01,  4.2067e-02, -3.6555e-02,  2.5414e-03, -1.1753e-01,\n",
       "                       7.7116e-02, -2.6260e-01, -1.4300e-01, -4.7720e-03,  1.1527e-01,\n",
       "                       1.3760e-01,  8.0458e-02, -4.7734e-02, -6.5335e-02, -1.0618e-02,\n",
       "                      -1.4791e-01,  8.9405e-02, -2.5850e-02,  2.1257e-02,  1.2705e-01,\n",
       "                       1.6187e-02, -1.2372e-01, -9.8365e-02,  1.3552e-02,  4.9810e-02,\n",
       "                      -8.8656e-02,  2.5119e-02,  1.1054e-01, -6.1956e-02,  1.2657e-01,\n",
       "                      -4.7001e-02, -9.5119e-03,  8.8305e-04,  1.9164e-02,  4.9826e-02,\n",
       "                       6.8212e-02,  1.0227e-01,  4.0275e-02, -3.3449e-02,  5.8371e-02,\n",
       "                       6.7616e-02, -3.1867e-02, -4.3804e-02, -4.2296e-02, -3.2985e-03,\n",
       "                       9.0067e-02,  4.9679e-02,  5.8451e-02, -1.2353e-01,  1.0001e-01,\n",
       "                      -1.2412e-02,  2.3216e-02, -3.8592e-02, -7.1743e-02, -9.2784e-02,\n",
       "                      -1.3672e-02], device='cuda:0')),\n",
       "             ('module.layers.0.norm2.weight',\n",
       "              tensor([0.9684, 0.9144, 0.9757, 0.7711, 0.9002, 0.7911, 0.8819, 0.9701, 0.8752,\n",
       "                      0.8788, 0.9600, 0.9492, 0.9532, 0.7238, 0.9523, 0.8906, 0.7640, 0.9634,\n",
       "                      0.8875, 0.4530, 0.9292, 0.5729, 0.8625, 0.9878, 0.9530, 0.9615, 1.0149,\n",
       "                      0.9474, 0.9338, 0.8474, 0.5920, 0.9639, 0.8361, 0.9755, 0.9241, 0.9616,\n",
       "                      0.7729, 0.9599, 0.8260, 0.9928, 0.9989, 0.9386, 0.8937, 0.8026, 0.8461,\n",
       "                      0.9525, 0.8963, 0.8414, 0.9772, 0.9046, 0.8859, 0.9321, 0.8833, 0.9404,\n",
       "                      0.5397, 0.8895, 0.8678, 0.9190, 0.7956, 0.7455, 0.9852, 0.9630, 0.8508,\n",
       "                      0.8662, 0.9599, 0.8112, 0.9962, 0.9199, 0.9498, 0.8481, 0.8860, 0.8241,\n",
       "                      0.9288, 0.9701, 0.9683, 0.9506, 0.8310, 0.7982, 0.9319, 0.8994, 0.9670,\n",
       "                      1.0002, 0.8788, 0.9263, 0.9568, 0.6798, 0.9327, 0.8882, 0.8973, 0.9293,\n",
       "                      0.7340, 0.9017, 0.8374, 0.9199, 0.8547, 0.9463, 0.8808, 0.9064, 0.8832,\n",
       "                      0.9233, 0.9909, 0.8322, 0.7732, 0.9634, 0.9043, 0.9321, 0.9342, 0.9099,\n",
       "                      0.8542, 0.8519, 0.9112, 0.8854, 0.9016, 0.8976, 0.9030, 0.9230, 0.8185,\n",
       "                      0.9387, 0.8064, 0.9573, 0.8821, 0.9541, 0.6858, 0.9518, 0.8954, 0.9696,\n",
       "                      0.9916, 0.9911, 0.9837, 0.7640, 0.9553, 0.9023, 0.6921, 0.9760, 0.9693,\n",
       "                      0.8511, 0.8239, 0.9073, 1.0168, 0.9328, 0.8756, 0.9105, 0.8159, 0.8926,\n",
       "                      0.8538, 0.9378, 0.8327, 0.8502, 0.9379, 0.9796, 0.9477, 0.8502, 0.8505,\n",
       "                      0.9090, 1.0134, 0.8771, 0.9819, 1.0100, 0.9465, 0.9009, 0.9549, 0.9021,\n",
       "                      0.4181, 0.8908, 0.8795, 0.7791, 1.0046, 0.7938, 0.9345, 0.8990, 0.9546,\n",
       "                      0.9179, 0.9453, 0.8614, 0.9085, 0.9010, 0.6522, 0.8164, 0.9811, 0.7095,\n",
       "                      0.9238, 0.9485, 0.8599, 0.9016, 0.7579, 0.9771, 0.9420, 0.9354, 0.9646,\n",
       "                      0.9721, 0.8791, 0.9109, 0.8984, 0.9920, 0.9624, 0.9443, 1.0026, 0.9177,\n",
       "                      0.9249, 0.9220, 0.8739, 0.9849, 0.9344, 0.9765, 0.9758, 0.8752, 0.3690,\n",
       "                      0.8432, 0.9163, 0.8804, 0.9077, 0.9020, 0.9636, 0.7529, 0.9736, 0.9385,\n",
       "                      0.7794, 0.8853, 0.9610, 0.8247, 0.9404, 0.8625, 0.9024, 0.9617, 0.9212,\n",
       "                      0.5849, 0.9404, 0.9275, 0.9580, 0.7596, 1.0294, 0.8023, 0.8154, 0.9185,\n",
       "                      0.8650, 0.9255, 0.8386, 1.0212, 1.0028, 0.9306, 0.9225, 0.8838, 0.9139,\n",
       "                      0.9042, 0.9750, 0.8920, 1.0051, 0.8022, 0.9186, 0.9579, 0.9378, 0.8019,\n",
       "                      0.9628, 0.9419, 0.9095, 0.9940], device='cuda:0')),\n",
       "             ('module.layers.0.norm2.bias',\n",
       "              tensor([-0.0344,  0.0086, -0.0303,  0.1461, -0.0045,  0.1033, -0.0623,  0.0775,\n",
       "                       0.0045, -0.0427,  0.0229,  0.0140,  0.0028, -0.1827,  0.0309, -0.0968,\n",
       "                       0.0003,  0.0880,  0.0009, -0.1224,  0.0950, -0.0765, -0.0801, -0.0522,\n",
       "                      -0.0543, -0.0033, -0.0124,  0.0848, -0.0105, -0.1366,  0.2906, -0.0323,\n",
       "                      -0.0938,  0.0407, -0.0039, -0.0980, -0.0488,  0.0195, -0.0728,  0.0164,\n",
       "                       0.0050, -0.0263, -0.0539, -0.0806,  0.0735,  0.0412, -0.0757,  0.1339,\n",
       "                       0.0210,  0.0615,  0.0715,  0.0343, -0.0200,  0.0518, -0.1195, -0.0934,\n",
       "                      -0.0920,  0.0430, -0.1008,  0.0833, -0.0085,  0.0696,  0.0474,  0.0938,\n",
       "                      -0.0101, -0.1867, -0.0675, -0.0907,  0.0793, -0.1147,  0.1522,  0.1007,\n",
       "                       0.0395, -0.1025, -0.0382,  0.0446,  0.0267,  0.0106,  0.0363,  0.1431,\n",
       "                       0.0840,  0.0443, -0.1121, -0.0185,  0.0241,  0.1452, -0.0370, -0.0446,\n",
       "                      -0.0261, -0.0036, -0.1050,  0.0490,  0.0074,  0.0052, -0.0890, -0.1153,\n",
       "                      -0.1060, -0.0260,  0.0988,  0.0835, -0.0699,  0.1224,  0.1914,  0.0154,\n",
       "                       0.0864, -0.0516, -0.0109,  0.0271,  0.0826, -0.0673, -0.1154, -0.0595,\n",
       "                       0.0431,  0.0714,  0.0358, -0.0315, -0.0096, -0.0314,  0.0140, -0.0514,\n",
       "                       0.0228, -0.0084,  0.1828,  0.0051,  0.1886, -0.0540, -0.0385,  0.0495,\n",
       "                       0.0059,  0.0678, -0.0343,  0.0358,  0.0109,  0.0508,  0.0596, -0.1277,\n",
       "                       0.1121,  0.0025, -0.0158, -0.0930, -0.0342,  0.0374,  0.0966,  0.0627,\n",
       "                       0.0145,  0.0727, -0.0862,  0.0016,  0.0443, -0.0476,  0.0758, -0.0835,\n",
       "                      -0.0795, -0.0101, -0.0799,  0.0571,  0.0145, -0.0118,  0.0050,  0.0685,\n",
       "                      -0.0618, -0.0383, -0.1107, -0.0258,  0.1152, -0.1479, -0.0090,  0.1457,\n",
       "                       0.0093,  0.0352, -0.0269, -0.0470, -0.0039,  0.0996,  0.0371,  0.0112,\n",
       "                       0.1413,  0.1275, -0.0037, -0.1244,  0.0334,  0.0779, -0.0940,  0.0025,\n",
       "                       0.0212,  0.0070, -0.0506,  0.1310, -0.0557,  0.0906, -0.0380,  0.1129,\n",
       "                       0.1428, -0.0366, -0.0374,  0.0005, -0.0121, -0.0886, -0.0050,  0.0658,\n",
       "                       0.1288, -0.0305,  0.0208,  0.0147, -0.0104, -0.0848, -0.0659,  0.0603,\n",
       "                       0.1335, -0.0835,  0.0358, -0.0586,  0.0222,  0.0705,  0.0194,  0.0528,\n",
       "                      -0.0726, -0.0072,  0.0136, -0.0656,  0.0482,  0.0619, -0.0227, -0.1076,\n",
       "                      -0.1104,  0.2392, -0.0530,  0.0152, -0.1046, -0.1353,  0.0796,  0.1378,\n",
       "                      -0.1137,  0.0156, -0.0430, -0.0249, -0.0073,  0.0336, -0.0233,  0.0708,\n",
       "                      -0.0509,  0.1499,  0.0859, -0.0216,  0.0294,  0.0414,  0.0245, -0.0081,\n",
       "                       0.0049, -0.0629,  0.1250,  0.0056, -0.0182,  0.0108,  0.1008, -0.0280],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.attn.attn.adaptive_span._mask.current_val',\n",
       "              tensor([[[9.2327e-03]],\n",
       "              \n",
       "                      [[2.8718e-02]],\n",
       "              \n",
       "                      [[6.4089e-02]],\n",
       "              \n",
       "                      [[4.7840e-05]]], device='cuda:0')),\n",
       "             ('module.layers.1.attn.attn.adaptive_span._mask.mask_template',\n",
       "              tensor([-1.0230e+03, -1.0220e+03, -1.0210e+03,  ..., -2.0000e+00,\n",
       "                      -1.0000e+00,  0.0000e+00], device='cuda:0')),\n",
       "             ('module.layers.1.attn.proj_query.weight',\n",
       "              tensor([[-0.0185,  0.1211,  0.0203,  ...,  0.0243,  0.0033, -0.0072],\n",
       "                      [ 0.0982, -0.0201,  0.0190,  ...,  0.0606,  0.0145,  0.0482],\n",
       "                      [-0.0247,  0.0530,  0.1406,  ..., -0.0155,  0.0647, -0.0379],\n",
       "                      ...,\n",
       "                      [ 0.0530,  0.0215, -0.0400,  ..., -0.0786, -0.0279,  0.0973],\n",
       "                      [ 0.1068, -0.0481, -0.0127,  ...,  0.0200,  0.0406, -0.0622],\n",
       "                      [ 0.0173, -0.0247, -0.0074,  ..., -0.0742,  0.0500, -0.2003]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.attn.proj_out.weight',\n",
       "              tensor([[ 0.0515,  0.1540, -0.0193,  ..., -0.0413, -0.0433, -0.0253],\n",
       "                      [-0.0327, -0.0428, -0.1213,  ..., -0.0113, -0.0185,  0.0050],\n",
       "                      [-0.0747,  0.0098, -0.1589,  ..., -0.0098,  0.0732, -0.0284],\n",
       "                      ...,\n",
       "                      [ 0.0558,  0.0514,  0.0340,  ...,  0.0356,  0.0078, -0.0308],\n",
       "                      [-0.0616,  0.0142, -0.0040,  ..., -0.0339, -0.0361,  0.0943],\n",
       "                      [ 0.0263,  0.0358,  0.0162,  ...,  0.0313,  0.0358,  0.0049]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.attn.proj_val.weight',\n",
       "              tensor([[-0.0322,  0.0168, -0.0415,  ...,  0.0926,  0.0606, -0.0099],\n",
       "                      [-0.0116,  0.0774, -0.0201,  ...,  0.0628,  0.0526, -0.0206],\n",
       "                      [ 0.0240,  0.0269, -0.0619,  ..., -0.1426,  0.0597, -0.0278],\n",
       "                      ...,\n",
       "                      [-0.0867,  0.0257, -0.0348,  ..., -0.0181,  0.0772, -0.0339],\n",
       "                      [ 0.0920, -0.0601, -0.0381,  ..., -0.0473, -0.0380, -0.0788],\n",
       "                      [ 0.0145, -0.0498,  0.0397,  ...,  0.0152,  0.0276,  0.0011]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.attn.proj_key.weight',\n",
       "              tensor([[ 7.5399e-03, -2.3627e-01, -6.5638e-02,  ..., -7.9426e-02,\n",
       "                       -5.4651e-02, -6.1826e-02],\n",
       "                      [-1.2828e-02, -2.0609e-02, -3.9345e-02,  ...,  1.4178e-01,\n",
       "                       -2.7050e-02,  8.9503e-02],\n",
       "                      [-3.5844e-02, -1.1818e-02, -2.3440e-02,  ..., -9.1163e-02,\n",
       "                       -3.0535e-05, -1.0624e-01],\n",
       "                      ...,\n",
       "                      [-1.5122e-01, -3.5261e-02, -1.6105e-01,  ..., -1.1789e-01,\n",
       "                       -7.0186e-02,  5.4093e-02],\n",
       "                      [ 6.7494e-02,  7.8635e-02, -7.5285e-02,  ...,  2.1035e-01,\n",
       "                        4.4704e-02,  7.2949e-02],\n",
       "                      [ 2.2911e-02, -2.7092e-02, -1.6729e-01,  ...,  1.7651e-01,\n",
       "                        2.4537e-02,  4.3376e-02]], device='cuda:0')),\n",
       "             ('module.layers.1.ff.fc1.weight',\n",
       "              tensor([[ 0.0313, -0.0928, -0.0088,  ..., -0.1060,  0.1605, -0.0159],\n",
       "                      [-0.0221, -0.0101,  0.0866,  ...,  0.0068, -0.0486, -0.0072],\n",
       "                      [ 0.0085, -0.2106, -0.1151,  ...,  0.0369,  0.0967, -0.0055],\n",
       "                      ...,\n",
       "                      [ 0.0635, -0.0034, -0.0698,  ..., -0.0467, -0.1935, -0.1296],\n",
       "                      [-0.0506, -0.0768, -0.1562,  ...,  0.0333,  0.0967,  0.0243],\n",
       "                      [ 0.0975, -0.0103, -0.0710,  ..., -0.0089, -0.0773, -0.0454]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.ff.fc1.bias',\n",
       "              tensor([-0.0387, -0.1018, -0.0866,  ...,  0.0506, -0.1092, -0.1099],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.ff.fc2.weight',\n",
       "              tensor([[-0.0549,  0.0362,  0.0265,  ..., -0.0311,  0.0090,  0.0141],\n",
       "                      [-0.0782,  0.0380, -0.0053,  ..., -0.0389, -0.0565,  0.0280],\n",
       "                      [ 0.0303,  0.0295, -0.0407,  ..., -0.0113, -0.0128,  0.0135],\n",
       "                      ...,\n",
       "                      [-0.0516,  0.0683, -0.0072,  ...,  0.0195,  0.0618, -0.0022],\n",
       "                      [ 0.0419,  0.0339, -0.0316,  ...,  0.0566,  0.1041,  0.0040],\n",
       "                      [ 0.0328, -0.0839, -0.0084,  ...,  0.0728, -0.0670,  0.0269]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.ff.fc2.bias',\n",
       "              tensor([-0.0247, -0.0635,  0.0367,  0.0550,  0.0565,  0.0201, -0.0400,  0.0901,\n",
       "                      -0.0519, -0.0278, -0.0101, -0.0411, -0.0425, -0.0904,  0.0829, -0.0077,\n",
       "                       0.0202,  0.0725,  0.0862,  0.0130,  0.0234, -0.0020, -0.0763, -0.0219,\n",
       "                       0.0439,  0.0437, -0.0719,  0.0014, -0.0166,  0.0106,  0.1124, -0.0873,\n",
       "                      -0.0484,  0.0082,  0.0243, -0.0503, -0.0427, -0.0008, -0.0971, -0.0544,\n",
       "                       0.0108, -0.0140,  0.0025,  0.0031,  0.0340, -0.0644, -0.0815,  0.0503,\n",
       "                      -0.0022,  0.0494,  0.0942, -0.0303,  0.0568, -0.0728, -0.0309, -0.0178,\n",
       "                      -0.0424, -0.0626, -0.0323, -0.0481, -0.0317,  0.0018,  0.0618, -0.0162,\n",
       "                       0.0136, -0.0678, -0.0281, -0.0827,  0.0152, -0.1114,  0.0861,  0.0424,\n",
       "                      -0.0461, -0.1006, -0.0858,  0.0252,  0.0655, -0.0010,  0.0474,  0.1267,\n",
       "                       0.0122, -0.0153, -0.0580, -0.0911, -0.0724,  0.0214, -0.0358, -0.0367,\n",
       "                       0.0063, -0.0407, -0.0950,  0.1032,  0.0286,  0.0305, -0.0488,  0.0266,\n",
       "                      -0.0261, -0.0946,  0.0016, -0.0439, -0.0073,  0.0785,  0.0840, -0.0872,\n",
       "                      -0.0111,  0.0276,  0.0332, -0.0174,  0.0443, -0.0347, -0.0239, -0.0663,\n",
       "                      -0.0054,  0.1112,  0.0155, -0.0620,  0.0539, -0.0470,  0.0069,  0.0151,\n",
       "                       0.0051, -0.0287, -0.0115,  0.0021,  0.0451, -0.0527,  0.0531,  0.0009,\n",
       "                       0.0259, -0.0072, -0.0121, -0.0095, -0.0048,  0.0456,  0.0842, -0.0695,\n",
       "                       0.0052,  0.0092, -0.0591, -0.0617, -0.0427, -0.0316,  0.0373,  0.0438,\n",
       "                       0.0843,  0.0197,  0.0572, -0.0234,  0.0429, -0.0428, -0.0309, -0.0208,\n",
       "                      -0.0057, -0.0803, -0.0377,  0.0789, -0.0464,  0.0545,  0.0032,  0.0578,\n",
       "                       0.0184,  0.0798, -0.0225,  0.0118,  0.1080, -0.1414,  0.0348,  0.0657,\n",
       "                       0.0017, -0.0024,  0.0465, -0.0077, -0.0253, -0.0047,  0.0180, -0.0454,\n",
       "                       0.0433, -0.0184, -0.0638,  0.0044,  0.0352,  0.0732, -0.0099, -0.0925,\n",
       "                       0.0779, -0.0494, -0.0138,  0.0516,  0.0657,  0.0404,  0.0618,  0.0708,\n",
       "                       0.0404, -0.0810, -0.0813,  0.0455,  0.0077, -0.0103,  0.0677, -0.0053,\n",
       "                       0.0091,  0.0182, -0.0093, -0.0489,  0.0417, -0.0153, -0.5003, -0.0400,\n",
       "                       0.0123, -0.0231,  0.0719, -0.0470,  0.0243, -0.0172,  0.0750,  0.0447,\n",
       "                      -0.0208, -0.0131,  0.0187, -0.0592,  0.0218,  0.0447,  0.0241, -0.0277,\n",
       "                      -0.0998,  0.0630, -0.0884, -0.0351, -0.0539, -0.0304, -0.0182, -0.0091,\n",
       "                      -0.0158, -0.0091, -0.0037,  0.0411, -0.0186,  0.0744, -0.0056,  0.0130,\n",
       "                      -0.0059,  0.0131,  0.0631,  0.0105,  0.0502,  0.0352,  0.0585,  0.0039,\n",
       "                       0.0455, -0.0727,  0.0564,  0.0393, -0.0120,  0.0954,  0.0862,  0.0333],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.norm1.weight',\n",
       "              tensor([1.0073, 1.0215, 0.9766, 0.9706, 1.0463, 1.1711, 0.9929, 1.0424, 0.9957,\n",
       "                      0.9398, 0.9876, 1.0178, 0.9987, 1.1060, 1.0331, 0.9519, 1.0491, 0.9920,\n",
       "                      1.0774, 1.1250, 1.0026, 1.1443, 1.1015, 0.9862, 0.9666, 0.9931, 1.0214,\n",
       "                      0.9396, 1.0168, 0.9935, 1.0447, 1.0097, 0.9734, 0.9670, 0.9441, 0.9553,\n",
       "                      0.9714, 1.0369, 0.9744, 1.0475, 1.0418, 0.9395, 1.0233, 1.0572, 1.0167,\n",
       "                      1.0779, 1.0809, 1.0386, 1.0045, 0.9888, 0.9944, 0.9955, 0.9715, 0.9744,\n",
       "                      1.0913, 1.0794, 0.9972, 0.9783, 0.9909, 1.1165, 1.0072, 0.9902, 0.9587,\n",
       "                      1.0090, 0.9873, 1.0256, 1.0099, 0.9693, 1.0064, 1.0056, 0.9757, 0.9827,\n",
       "                      0.9958, 0.9836, 0.9816, 1.0734, 1.0807, 0.9992, 1.0758, 1.0827, 1.0173,\n",
       "                      0.9756, 1.0162, 1.0025, 1.1031, 1.0824, 0.9701, 0.8993, 1.0196, 0.9877,\n",
       "                      1.1839, 0.9814, 0.9694, 0.9324, 1.0112, 1.0865, 1.0093, 1.0006, 1.0065,\n",
       "                      0.9529, 1.0204, 1.0371, 1.0709, 1.0499, 0.9862, 0.9864, 0.9916, 0.9885,\n",
       "                      0.9940, 0.9542, 1.0242, 1.0031, 0.9876, 1.0132, 1.0502, 0.9739, 1.0195,\n",
       "                      1.0069, 1.0024, 0.9755, 1.1057, 0.9599, 1.0898, 1.0139, 0.9815, 1.0124,\n",
       "                      0.9266, 0.9939, 0.9739, 1.1258, 1.0534, 0.9928, 0.8844, 1.0285, 1.0154,\n",
       "                      1.0181, 1.0473, 1.0022, 0.9967, 1.0156, 1.0455, 1.1222, 1.0316, 1.0273,\n",
       "                      1.0567, 1.0205, 1.0132, 1.0044, 1.0218, 0.9591, 1.0142, 1.0232, 0.9714,\n",
       "                      0.9770, 0.9960, 0.9855, 1.0683, 0.9803, 0.9553, 1.0124, 1.0445, 0.9807,\n",
       "                      1.2358, 1.0036, 1.0045, 1.0324, 0.9743, 0.9802, 1.0342, 0.9781, 1.0276,\n",
       "                      0.9758, 0.9936, 0.9628, 0.9519, 0.9989, 1.0703, 1.0025, 0.9354, 1.0834,\n",
       "                      1.0352, 1.0322, 0.9803, 0.9367, 1.0075, 1.0153, 0.9039, 1.1090, 1.0245,\n",
       "                      0.9398, 1.0231, 1.0141, 1.0240, 1.0433, 1.0304, 1.0784, 0.9856, 1.0432,\n",
       "                      0.9622, 1.0072, 1.0056, 0.9908, 0.9923, 0.9796, 1.0156, 0.9923, 1.8785,\n",
       "                      0.9971, 0.9945, 0.9702, 1.0180, 1.0104, 1.0054, 1.0685, 0.9232, 0.9765,\n",
       "                      1.0121, 0.9830, 0.9823, 0.9575, 0.9434, 1.0123, 0.9547, 0.9684, 0.9789,\n",
       "                      1.0982, 1.0213, 1.0256, 0.9941, 1.0364, 0.9943, 1.0113, 0.9638, 1.0101,\n",
       "                      0.9817, 1.0713, 0.9873, 0.9852, 0.9645, 0.9831, 0.9661, 0.9650, 0.9688,\n",
       "                      1.0276, 0.9273, 1.0885, 0.9875, 1.0486, 1.0460, 0.9651, 1.0022, 1.0746,\n",
       "                      1.0296, 1.0209, 1.0396, 1.0460], device='cuda:0')),\n",
       "             ('module.layers.1.norm1.bias',\n",
       "              tensor([-0.0071,  0.1377,  0.0344, -0.1035,  0.0165, -0.1648,  0.0613, -0.1408,\n",
       "                      -0.0343, -0.0218,  0.0858,  0.0633, -0.0510,  0.0741, -0.0306,  0.0722,\n",
       "                      -0.0856, -0.0473, -0.1049, -0.0664, -0.1020,  0.1344,  0.0984, -0.0885,\n",
       "                      -0.0618, -0.0545, -0.0371, -0.0972, -0.0555,  0.0143, -0.0334, -0.0264,\n",
       "                       0.0823,  0.0503,  0.0125,  0.1036, -0.0369, -0.0721, -0.0215,  0.0226,\n",
       "                       0.1265,  0.0057,  0.0090,  0.1102, -0.0045,  0.1586, -0.0004, -0.0976,\n",
       "                       0.0645,  0.0076,  0.0472,  0.0338,  0.0336, -0.0343,  0.0344,  0.1293,\n",
       "                       0.0477, -0.0850,  0.0881, -0.1386, -0.0065,  0.0282,  0.0088, -0.1679,\n",
       "                       0.0291,  0.1152,  0.0203,  0.0234,  0.0658,  0.0784, -0.0171, -0.0402,\n",
       "                      -0.1251, -0.0366, -0.0324, -0.0601,  0.0631, -0.0060,  0.0434, -0.1129,\n",
       "                      -0.0378,  0.0355,  0.0862,  0.0298,  0.0534, -0.0963, -0.0062,  0.0093,\n",
       "                       0.1153,  0.0142,  0.0399,  0.0100, -0.0492,  0.1485,  0.0906,  0.0739,\n",
       "                       0.0206, -0.0683, -0.0828, -0.0630,  0.0891, -0.0897, -0.1083,  0.0529,\n",
       "                       0.0437, -0.0208, -0.0069, -0.1009, -0.1198,  0.0128, -0.0517,  0.0223,\n",
       "                      -0.0111,  0.1273, -0.1405,  0.0565,  0.0187,  0.0285, -0.0029, -0.0655,\n",
       "                       0.1750, -0.0752, -0.1398,  0.0348,  0.0182,  0.1195,  0.0440, -0.0762,\n",
       "                      -0.0062, -0.1167, -0.1301, -0.0053,  0.0206,  0.0565, -0.0356,  0.0574,\n",
       "                      -0.1888,  0.0495,  0.0602, -0.0314,  0.1112, -0.0366, -0.0771, -0.0681,\n",
       "                      -0.1012, -0.1729,  0.0033,  0.1444,  0.0399,  0.0703, -0.0381,  0.1285,\n",
       "                       0.0298, -0.0300, -0.0650, -0.0197,  0.0637,  0.0336,  0.0008,  0.1964,\n",
       "                       0.0312, -0.0187,  0.0778, -0.0558, -0.1425,  0.0187,  0.0810, -0.0088,\n",
       "                       0.0530, -0.0331, -0.0259,  0.1135, -0.0833,  0.0362,  0.0089,  0.0878,\n",
       "                      -0.0154, -0.0781,  0.0225,  0.0931, -0.1316, -0.1311,  0.0855, -0.0006,\n",
       "                      -0.0058,  0.0781, -0.0774, -0.2039,  0.0416, -0.0284, -0.1692, -0.1093,\n",
       "                      -0.0663,  0.0390,  0.1472, -0.0625, -0.0547,  0.0030, -0.1376,  0.0364,\n",
       "                      -0.0133,  0.0009, -0.0039, -0.0955, -0.0535,  0.0758, -0.1328, -0.1598,\n",
       "                      -0.0245,  0.1028,  0.0194,  0.0287, -0.0457,  0.0111, -0.0343, -0.0193,\n",
       "                       0.0666, -0.0435,  0.0118,  0.0179,  0.0128, -0.2000, -0.0494,  0.0597,\n",
       "                       0.0381, -0.0711,  0.0035,  0.1290,  0.0012,  0.0806,  0.0576, -0.0053,\n",
       "                       0.0524,  0.0370, -0.0834,  0.0730,  0.0096, -0.0107, -0.0257,  0.1396,\n",
       "                       0.0222, -0.0296, -0.0311, -0.0750,  0.0386,  0.0248,  0.0046,  0.0430,\n",
       "                      -0.1226, -0.0036,  0.0826,  0.0203, -0.0389, -0.0619, -0.0989, -0.0373],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.1.norm2.weight',\n",
       "              tensor([0.8699, 0.8406, 0.9207, 0.8897, 0.8552, 0.7646, 0.8533, 0.8489, 0.8374,\n",
       "                      0.9411, 0.9192, 0.9470, 0.8880, 0.7713, 0.8104, 0.9400, 0.7547, 0.8628,\n",
       "                      0.7423, 0.8237, 0.8819, 0.6176, 0.8023, 0.8630, 0.9117, 0.9187, 0.9350,\n",
       "                      0.8868, 0.8981, 0.8885, 0.8325, 0.8732, 0.8370, 0.9375, 0.9640, 0.8901,\n",
       "                      0.9309, 0.8801, 0.8187, 0.8897, 0.9095, 0.9448, 0.8217, 0.8333, 0.8692,\n",
       "                      0.8236, 0.7987, 0.8198, 0.9051, 0.9338, 0.8379, 0.8348, 0.9085, 0.9392,\n",
       "                      0.8125, 0.7640, 0.9154, 1.0183, 0.8339, 0.6870, 0.9309, 0.8467, 0.8289,\n",
       "                      0.8178, 0.9094, 0.8582, 0.9018, 0.9222, 0.8502, 0.7944, 0.8564, 0.8306,\n",
       "                      0.9533, 0.9333, 0.9218, 0.8384, 0.8070, 0.9235, 0.7936, 0.8259, 0.8540,\n",
       "                      0.9733, 0.8858, 0.8916, 0.7521, 0.8789, 0.8651, 0.9680, 0.8721, 0.8936,\n",
       "                      0.6021, 0.8554, 0.9270, 0.9514, 0.8619, 0.8545, 0.8828, 0.8732, 0.8737,\n",
       "                      0.8969, 0.9337, 0.8352, 0.8663, 0.8422, 0.8316, 0.9108, 0.8564, 0.8952,\n",
       "                      0.8647, 0.9381, 0.8610, 0.8455, 0.8427, 0.8469, 0.8586, 0.8611, 0.8549,\n",
       "                      0.8844, 0.8324, 0.8782, 0.7769, 0.8600, 0.7919, 0.9181, 0.8030, 0.8870,\n",
       "                      0.9586, 0.9571, 0.8672, 0.6441, 0.8312, 0.8399, 0.9025, 0.8427, 0.8885,\n",
       "                      0.8082, 0.8277, 0.9134, 0.9388, 0.8175, 0.8600, 0.8235, 0.9013, 0.8605,\n",
       "                      0.7823, 1.0319, 0.8846, 0.8299, 0.8608, 1.0059, 0.8361, 0.8391, 0.8518,\n",
       "                      0.9165, 0.9111, 0.8708, 0.8835, 0.9233, 0.9206, 0.8873, 0.8862, 0.9037,\n",
       "                      0.6710, 0.8344, 0.9149, 0.8294, 0.9471, 0.8815, 0.8292, 0.8951, 0.7983,\n",
       "                      0.8401, 0.8810, 0.8626, 0.8825, 0.8189, 0.8186, 0.9162, 0.9671, 0.8888,\n",
       "                      0.8391, 0.8734, 0.9412, 0.8819, 0.8256, 0.8856, 0.8990, 0.7740, 0.8633,\n",
       "                      0.9603, 0.8456, 0.9007, 0.8768, 0.8551, 0.8411, 0.8486, 0.8538, 0.8346,\n",
       "                      0.8701, 0.8691, 0.8273, 0.8444, 0.8668, 0.8198, 0.9147, 0.9006, 0.3335,\n",
       "                      0.9635, 0.9116, 0.8442, 0.8836, 0.8673, 0.9696, 0.7822, 0.9363, 0.9855,\n",
       "                      0.8622, 0.9272, 0.9644, 0.8986, 0.9417, 0.8099, 0.9023, 0.9406, 0.8811,\n",
       "                      0.8320, 0.8733, 0.8919, 0.9307, 0.8538, 0.8645, 0.7758, 0.9176, 0.8725,\n",
       "                      0.8425, 0.8180, 0.8092, 0.9950, 0.9258, 0.8604, 0.9517, 0.8981, 0.8565,\n",
       "                      0.8727, 0.9215, 0.8214, 0.9106, 0.8085, 0.8525, 0.9134, 0.8528, 0.8569,\n",
       "                      0.8857, 0.8847, 0.8529, 0.8317], device='cuda:0')),\n",
       "             ('module.layers.1.norm2.bias',\n",
       "              tensor([-2.7726e-03, -6.5792e-02,  1.9621e-02,  4.5853e-02,  3.7755e-02,\n",
       "                       1.0366e-01, -1.4089e-03,  5.7416e-02,  5.5805e-04,  4.0735e-04,\n",
       "                       8.6047e-02,  1.1431e-02, -1.8988e-02, -1.4007e-01,  5.1143e-02,\n",
       "                       7.3009e-02,  3.8608e-02, -5.6237e-03,  1.2706e-01, -4.8530e-02,\n",
       "                       7.5535e-02, -1.8376e-02, -1.3297e-01,  5.7422e-03, -3.3488e-02,\n",
       "                       6.4120e-02, -1.2458e-01,  1.6970e-02,  2.6977e-02, -6.5920e-02,\n",
       "                       1.7368e-01, -4.6480e-02, -2.1638e-02,  7.6905e-05, -1.9707e-02,\n",
       "                      -2.8182e-02,  5.0426e-02,  6.1422e-02, -3.5053e-02, -7.1319e-02,\n",
       "                       2.0453e-02, -3.0901e-02,  4.1249e-02, -8.7627e-02,  6.3506e-02,\n",
       "                      -7.4056e-02, -1.0270e-01,  1.4834e-01,  1.6469e-02,  2.7657e-02,\n",
       "                       1.2145e-01,  1.0018e-02,  2.5057e-02, -2.0061e-02, -1.1117e-02,\n",
       "                      -1.1176e-01, -1.0390e-02,  2.5842e-02, -3.7458e-02,  1.2814e-01,\n",
       "                      -7.1684e-03, -4.5677e-03,  3.7776e-02,  9.2672e-03,  3.1519e-02,\n",
       "                      -8.3011e-02, -1.2540e-01, -3.1724e-02, -2.6240e-02, -1.1058e-01,\n",
       "                       9.3483e-02,  7.2979e-02, -2.1954e-02, -9.4762e-02, -5.0740e-02,\n",
       "                       1.5868e-01, -7.6671e-03,  9.3621e-02,  3.0337e-02,  1.3956e-01,\n",
       "                       3.1506e-02, -1.7434e-02, -3.1162e-02, -4.8888e-02,  1.4486e-02,\n",
       "                       5.2026e-02,  2.3270e-02,  1.4780e-02, -4.9233e-03,  3.0025e-02,\n",
       "                      -1.6410e-01,  1.2231e-01,  1.4216e-02,  2.8907e-02, -1.0136e-01,\n",
       "                      -1.7713e-03, -6.2012e-02,  8.9517e-03,  3.8949e-02,  2.0809e-02,\n",
       "                      -6.4592e-03,  9.6425e-02,  1.3597e-01, -8.1598e-03,  7.4290e-02,\n",
       "                       4.0444e-02,  2.0044e-02, -3.3150e-03,  1.8451e-03, -2.6303e-02,\n",
       "                      -1.8827e-02, -8.6898e-02,  5.8808e-02,  7.7301e-02,  7.0612e-02,\n",
       "                      -2.9070e-02,  6.1532e-02, -3.0230e-02,  3.2887e-02,  3.5186e-03,\n",
       "                       5.4363e-02,  4.5819e-02,  9.6152e-02, -1.7525e-02,  1.0432e-01,\n",
       "                       4.5367e-03,  1.2431e-02,  6.1485e-03,  7.5833e-02,  1.4664e-01,\n",
       "                       6.8079e-02,  2.6202e-02,  3.2193e-02,  3.5458e-02,  1.1116e-01,\n",
       "                      -9.1750e-02,  6.6042e-02, -1.1228e-02,  6.8854e-03, -6.6366e-02,\n",
       "                      -2.6611e-02, -7.2350e-03,  1.7140e-01, -3.1797e-03,  8.6888e-02,\n",
       "                       1.5386e-02,  5.2323e-02,  3.0408e-02,  3.6569e-02, -3.6970e-02,\n",
       "                       4.1679e-02, -1.2829e-02, -6.0999e-03,  5.0007e-03, -4.4616e-02,\n",
       "                       4.7138e-02, -1.9202e-02, -7.7426e-03,  1.9356e-02,  2.6783e-02,\n",
       "                      -3.0734e-02,  6.4078e-02, -1.2354e-01,  1.9153e-02,  1.1746e-01,\n",
       "                      -1.2350e-01, -5.6333e-03,  2.5125e-02,  2.5509e-02, -5.4159e-02,\n",
       "                      -1.1986e-03, -4.3183e-02, -1.2588e-02,  1.9000e-02,  5.4470e-02,\n",
       "                      -1.0718e-01,  1.6027e-01,  9.1094e-03, -2.3572e-02, -2.4756e-02,\n",
       "                       1.0641e-01,  1.0464e-01, -6.9495e-02,  1.4938e-02,  4.5748e-02,\n",
       "                       5.9402e-02,  3.0816e-02,  1.8135e-01,  9.0406e-02,  4.4493e-02,\n",
       "                       7.7721e-02,  9.5093e-02,  5.6111e-02,  2.7494e-02, -3.1598e-02,\n",
       "                      -6.8040e-03, -1.1052e-02, -4.2296e-02,  4.2908e-02, -1.9821e-02,\n",
       "                      -2.9627e-02,  5.2377e-02,  3.6156e-02, -2.3290e-02,  2.8519e-02,\n",
       "                      -6.1013e-02, -1.6065e-01, -9.9635e-02,  7.6549e-02, -4.8024e-02,\n",
       "                       8.3091e-02, -3.1989e-02, -3.9355e-02,  1.6129e-02,  3.2839e-03,\n",
       "                       5.2673e-02,  3.1642e-03, -2.8804e-02,  9.2396e-02, -5.0423e-02,\n",
       "                       5.8700e-02,  6.1780e-02,  5.7243e-03, -3.6337e-02, -4.8933e-02,\n",
       "                       8.7276e-02, -6.3339e-02, -1.3322e-01, -5.0798e-02, -8.9425e-02,\n",
       "                       5.7642e-02,  6.0326e-02,  2.3675e-02,  2.8121e-02,  5.6779e-02,\n",
       "                       1.0208e-01,  8.0578e-03,  2.4711e-02,  3.8986e-02, -3.9102e-02,\n",
       "                       1.0614e-02,  8.7981e-02,  8.3877e-02,  7.9481e-03,  6.5678e-02,\n",
       "                       6.1404e-02,  5.0117e-02, -4.5875e-02,  6.2301e-02, -6.2708e-02,\n",
       "                       8.2046e-02,  5.5925e-02,  4.1089e-02,  1.0504e-01,  7.2470e-02,\n",
       "                       1.7143e-02], device='cuda:0')),\n",
       "             ('module.layers.2.attn.attn.adaptive_span._mask.current_val',\n",
       "              tensor([[[0.0646]],\n",
       "              \n",
       "                      [[0.1629]],\n",
       "              \n",
       "                      [[0.4360]],\n",
       "              \n",
       "                      [[0.0991]]], device='cuda:0')),\n",
       "             ('module.layers.2.attn.attn.adaptive_span._mask.mask_template',\n",
       "              tensor([-1.0230e+03, -1.0220e+03, -1.0210e+03,  ..., -2.0000e+00,\n",
       "                      -1.0000e+00,  0.0000e+00], device='cuda:0')),\n",
       "             ('module.layers.2.attn.proj_query.weight',\n",
       "              tensor([[ 0.0279,  0.0238,  0.0200,  ..., -0.0618,  0.0310,  0.0403],\n",
       "                      [-0.0785, -0.0635, -0.0371,  ...,  0.0394,  0.0197,  0.0269],\n",
       "                      [-0.1048, -0.0774, -0.0617,  ..., -0.1187, -0.0802, -0.1288],\n",
       "                      ...,\n",
       "                      [ 0.0531,  0.0234, -0.0110,  ...,  0.0176, -0.0756,  0.0868],\n",
       "                      [ 0.0106, -0.0290,  0.0282,  ...,  0.1959,  0.1072,  0.0519],\n",
       "                      [ 0.1509,  0.0122,  0.1073,  ...,  0.0780,  0.1166,  0.0126]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.2.attn.proj_out.weight',\n",
       "              tensor([[ 0.0734,  0.0316, -0.0671,  ..., -0.1466, -0.1389,  0.0077],\n",
       "                      [ 0.0156, -0.0330, -0.0753,  ...,  0.0839,  0.0859, -0.0033],\n",
       "                      [-0.0429, -0.0164,  0.0065,  ...,  0.0193,  0.0347,  0.0277],\n",
       "                      ...,\n",
       "                      [ 0.0706,  0.0127,  0.0521,  ...,  0.0751,  0.0063,  0.0106],\n",
       "                      [ 0.0621, -0.1092, -0.0090,  ..., -0.0377,  0.0065, -0.0959],\n",
       "                      [-0.0199, -0.0794,  0.0358,  ..., -0.0181, -0.0336, -0.0115]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.2.attn.proj_val.weight',\n",
       "              tensor([[ 0.0399,  0.0293,  0.0376,  ...,  0.0989,  0.0253,  0.0410],\n",
       "                      [ 0.0290, -0.0196, -0.0063,  ..., -0.0417, -0.0428, -0.0226],\n",
       "                      [-0.0853,  0.0462, -0.0227,  ...,  0.0363,  0.0892, -0.0651],\n",
       "                      ...,\n",
       "                      [ 0.1039,  0.0950, -0.0317,  ..., -0.0496, -0.0186,  0.0434],\n",
       "                      [ 0.0236,  0.0513,  0.0226,  ..., -0.0201, -0.0568,  0.0804],\n",
       "                      [ 0.0323, -0.0015, -0.0306,  ..., -0.0336,  0.0089, -0.0561]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.2.attn.proj_key.weight',\n",
       "              tensor([[-0.0875,  0.0598, -0.0267,  ..., -0.0246,  0.0823,  0.1315],\n",
       "                      [-0.1054,  0.0499, -0.0535,  ..., -0.0090, -0.1420,  0.0665],\n",
       "                      [ 0.0007,  0.0412, -0.0569,  ...,  0.0627, -0.0058, -0.0245],\n",
       "                      ...,\n",
       "                      [-0.0700,  0.0381, -0.0593,  ..., -0.1075, -0.0617,  0.0666],\n",
       "                      [ 0.0290, -0.0320,  0.1611,  ...,  0.1158,  0.0143,  0.0543],\n",
       "                      [ 0.0865,  0.0161, -0.0743,  ...,  0.0572, -0.0737, -0.0718]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.2.ff.fc1.weight',\n",
       "              tensor([[-0.0889, -0.0245,  0.0452,  ...,  0.0395,  0.0492, -0.0177],\n",
       "                      [-0.0954, -0.0312, -0.1001,  ..., -0.1617, -0.0961, -0.0323],\n",
       "                      [ 0.1053, -0.1714,  0.0470,  ..., -0.0595,  0.0376,  0.0658],\n",
       "                      ...,\n",
       "                      [-0.0850, -0.0356, -0.0148,  ...,  0.0101, -0.0034,  0.0798],\n",
       "                      [ 0.0402, -0.0709,  0.1721,  ...,  0.0296, -0.0562,  0.0470],\n",
       "                      [-0.1048, -0.0935,  0.1349,  ..., -0.1346, -0.0140, -0.0627]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.2.ff.fc1.bias',\n",
       "              tensor([-0.1070, -0.0891, -0.1593,  ..., -0.1973, -0.0494, -0.2040],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.2.ff.fc2.weight',\n",
       "              tensor([[ 0.0149, -0.0501, -0.0514,  ..., -0.0165, -0.0273, -0.0147],\n",
       "                      [ 0.0369, -0.0449,  0.0020,  ...,  0.0156,  0.0308, -0.0539],\n",
       "                      [ 0.0161,  0.0430,  0.0360,  ...,  0.0943,  0.0381, -0.0102],\n",
       "                      ...,\n",
       "                      [ 0.0407,  0.0051,  0.0168,  ...,  0.0282, -0.0380,  0.1269],\n",
       "                      [-0.0253,  0.0303, -0.0285,  ..., -0.0200, -0.0531, -0.0234],\n",
       "                      [-0.0015,  0.0684,  0.0278,  ...,  0.0463, -0.0167,  0.0149]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.2.ff.fc2.bias',\n",
       "              tensor([-9.0710e-03, -1.3903e-01, -9.7280e-03, -2.6088e-02,  7.0026e-02,\n",
       "                       4.4307e-02, -3.0298e-02,  1.1202e-02, -2.5512e-02,  3.8512e-02,\n",
       "                       8.4852e-03,  3.1209e-02, -3.9294e-02, -7.3474e-02,  1.2234e-02,\n",
       "                       6.0016e-03,  1.1003e-02, -1.1234e-02,  9.6376e-02, -1.3813e-02,\n",
       "                       1.0988e-02, -1.9155e-02, -4.6866e-02, -5.7446e-02, -2.2537e-02,\n",
       "                       1.7398e-02,  6.6381e-04, -2.4569e-02, -1.8443e-02, -4.4916e-02,\n",
       "                       7.3843e-02, -7.7761e-02,  3.9603e-02,  4.9317e-02,  1.9412e-02,\n",
       "                      -2.8015e-02, -1.1815e-02,  6.8512e-03, -7.9874e-02, -1.2874e-01,\n",
       "                       2.0287e-02,  6.0507e-02,  3.5562e-02,  1.3103e-02,  3.3262e-02,\n",
       "                      -1.0392e-01,  1.1696e-02,  5.5734e-02,  9.7569e-02,  1.1687e-03,\n",
       "                       1.2929e-01,  3.3744e-02,  8.5282e-02, -4.2789e-02,  1.0235e-01,\n",
       "                       2.6202e-05, -1.1921e-02, -4.1111e-02,  4.3026e-02, -2.6244e-02,\n",
       "                      -1.3944e-02,  1.1622e-03,  7.6499e-02,  1.2657e-02,  9.9840e-03,\n",
       "                       2.7891e-02, -5.9906e-02, -1.1022e-01,  5.5295e-03, -9.6513e-02,\n",
       "                       6.3325e-02,  1.6585e-03,  4.9650e-02, -7.1392e-02, -5.3491e-02,\n",
       "                       9.0714e-03,  4.5487e-02, -6.4337e-02, -2.1205e-02,  8.5429e-02,\n",
       "                      -1.6668e-03,  3.7462e-03, -1.2581e-02, -3.2531e-02, -8.4596e-02,\n",
       "                       3.0888e-02,  4.4371e-02, -5.4343e-03,  3.4569e-02, -7.1709e-03,\n",
       "                      -5.8171e-02,  3.0671e-02,  4.5608e-02,  1.7881e-02, -3.2625e-02,\n",
       "                       1.1754e-02, -3.7580e-02, -9.0647e-02,  4.1969e-02, -5.3558e-03,\n",
       "                       3.9709e-03,  7.0043e-02,  6.3694e-02, -1.2892e-02,  4.6244e-02,\n",
       "                       1.8550e-02,  6.4743e-04,  1.2326e-02, -4.3017e-02, -5.2487e-02,\n",
       "                       1.3744e-02, -3.9069e-02, -6.6466e-03,  4.7653e-02,  6.1367e-02,\n",
       "                      -1.1715e-01,  7.6465e-03, -4.3139e-02,  5.5682e-03, -2.2512e-02,\n",
       "                      -1.2172e-02, -3.3069e-03,  1.7414e-02,  3.4832e-02,  1.0085e-01,\n",
       "                      -6.9044e-02,  2.5654e-02,  2.4675e-02,  2.9584e-03,  7.2742e-03,\n",
       "                      -2.1058e-02,  1.9462e-02,  2.4243e-02,  1.0166e-01,  8.6828e-03,\n",
       "                      -2.2727e-02, -1.3902e-02, -4.1169e-02, -4.7144e-02,  1.5656e-02,\n",
       "                      -7.3448e-02,  2.5078e-02,  1.2196e-01, -7.7965e-02, -2.6266e-02,\n",
       "                      -3.1521e-02,  2.6267e-02, -1.0721e-01,  2.7517e-02,  2.0699e-03,\n",
       "                      -2.1119e-02,  3.9783e-02,  3.0391e-02, -1.0836e-01, -1.0240e-01,\n",
       "                      -3.7527e-02, -5.2572e-03, -1.8188e-02,  1.3553e-02,  3.6615e-02,\n",
       "                      -2.9207e-02,  1.1471e-01, -1.1549e-01,  3.3531e-02,  9.5906e-02,\n",
       "                      -2.9041e-02,  4.8498e-02, -3.9264e-02,  1.7513e-02, -4.6125e-02,\n",
       "                       2.6688e-02, -3.6573e-02,  3.2938e-02,  9.2251e-02, -7.3326e-03,\n",
       "                      -3.2730e-02, -4.9491e-02, -1.3595e-03, -1.8960e-02,  5.7694e-02,\n",
       "                       1.7150e-02,  4.5438e-02,  2.8027e-03, -6.8296e-02, -6.9891e-03,\n",
       "                      -1.5866e-02, -3.6038e-03,  5.1061e-02,  4.8529e-02,  8.0889e-02,\n",
       "                       3.6603e-02,  1.8115e-02, -7.6425e-04, -7.3555e-02, -1.1328e-01,\n",
       "                      -6.3656e-02, -4.4588e-02, -7.0597e-02,  7.9019e-02,  3.1558e-02,\n",
       "                       1.0948e-01, -8.2522e-03,  3.7803e-02, -6.9471e-02,  7.1542e-02,\n",
       "                      -9.0802e-02, -5.0425e-01,  1.5888e-02, -1.5981e-02, -4.4402e-02,\n",
       "                       6.1458e-02, -3.2022e-02,  3.2111e-02, -2.9198e-02,  6.3844e-02,\n",
       "                      -3.0062e-03,  5.9985e-02,  2.9963e-04, -7.0262e-02, -3.7432e-02,\n",
       "                       1.3960e-02, -6.7521e-02, -4.2754e-03, -1.4082e-02, -1.0488e-01,\n",
       "                       1.1363e-02, -3.3712e-02, -5.8091e-02, -8.2140e-02,  1.6990e-02,\n",
       "                       3.1804e-03,  1.1595e-02, -2.9330e-02, -4.4897e-02, -3.9770e-02,\n",
       "                       1.6737e-02,  1.4171e-02,  2.4125e-02, -5.0009e-02,  3.6625e-02,\n",
       "                      -2.9853e-02, -2.8073e-02,  8.6854e-02,  8.7133e-03,  9.8403e-02,\n",
       "                      -1.1111e-02,  9.2053e-02, -8.8424e-02, -2.8100e-02,  2.6462e-02,\n",
       "                       3.3233e-03,  2.5315e-02, -4.3904e-02,  5.6862e-02,  1.2276e-02,\n",
       "                      -1.0975e-02], device='cuda:0')),\n",
       "             ('module.layers.2.norm1.weight',\n",
       "              tensor([0.9212, 1.0565, 0.9724, 0.9988, 0.9791, 1.0692, 0.9624, 1.0457, 0.9749,\n",
       "                      0.9675, 0.9622, 0.9792, 1.0084, 1.0910, 1.0437, 0.9901, 1.0687, 1.0249,\n",
       "                      1.1198, 0.9661, 0.9557, 1.3994, 0.9564, 0.9802, 0.9691, 1.0885, 1.0225,\n",
       "                      0.9094, 1.0385, 0.9428, 1.0156, 1.0172, 0.9469, 0.9698, 0.9499, 0.9833,\n",
       "                      0.9046, 0.9896, 1.0074, 1.0489, 1.0424, 0.9619, 0.9835, 1.0467, 1.0131,\n",
       "                      1.0397, 1.0025, 1.0068, 0.9843, 1.0234, 0.9704, 1.0204, 0.9031, 1.0415,\n",
       "                      1.1957, 1.1573, 1.0107, 0.9355, 1.0186, 1.0771, 1.0192, 1.0478, 1.0083,\n",
       "                      1.1037, 1.0077, 1.0435, 1.0475, 0.9833, 1.0750, 1.0068, 1.0184, 1.0377,\n",
       "                      0.9433, 0.9624, 1.0002, 0.9437, 1.1139, 1.0534, 0.9951, 1.0674, 1.0140,\n",
       "                      0.9415, 0.9527, 0.9616, 1.0477, 1.0378, 0.9511, 0.9945, 1.0689, 1.0396,\n",
       "                      1.1746, 1.0395, 1.0177, 0.9188, 1.0684, 1.0702, 1.0078, 1.0098, 0.9997,\n",
       "                      0.9670, 0.9363, 1.0161, 0.9393, 1.0365, 1.0155, 1.0153, 1.0235, 0.9699,\n",
       "                      0.9671, 0.9743, 1.0089, 1.0516, 1.0443, 1.0023, 0.9304, 0.9639, 0.9923,\n",
       "                      0.9925, 0.9952, 1.0093, 1.0797, 0.9867, 1.0104, 0.9945, 0.9802, 0.9777,\n",
       "                      0.9554, 0.9617, 0.9832, 1.1577, 1.0320, 0.9692, 0.9412, 1.0657, 0.9710,\n",
       "                      0.9851, 0.9575, 0.9317, 1.0226, 0.9760, 1.0110, 1.0107, 1.0393, 1.0139,\n",
       "                      0.9874, 0.9188, 1.0221, 0.9720, 1.0675, 0.9498, 1.0031, 0.9870, 0.9908,\n",
       "                      0.9629, 0.9529, 1.0270, 1.0575, 0.9909, 0.9824, 1.0085, 0.9953, 0.9936,\n",
       "                      1.2074, 0.9532, 0.9705, 1.0198, 0.9565, 0.9544, 1.0131, 0.9959, 0.9505,\n",
       "                      0.9944, 0.9835, 1.0119, 0.9406, 1.0912, 0.9795, 0.9668, 1.0100, 1.0332,\n",
       "                      1.0144, 0.9875, 0.9752, 0.9565, 0.9866, 1.0237, 1.0360, 1.1216, 0.9555,\n",
       "                      1.0419, 0.9710, 0.9448, 1.0330, 1.0108, 1.0125, 1.0418, 0.9696, 0.9677,\n",
       "                      0.9323, 0.9948, 0.9693, 0.9731, 0.9932, 0.9457, 0.9857, 1.0140, 2.2894,\n",
       "                      1.0792, 0.9617, 0.9717, 0.9445, 1.0207, 0.9921, 1.1516, 0.9963, 0.9908,\n",
       "                      1.0183, 0.9160, 0.9699, 0.9892, 1.0580, 0.9780, 0.9686, 0.9562, 0.9403,\n",
       "                      1.0922, 1.0157, 0.9978, 1.0562, 1.0632, 1.0388, 1.0095, 0.9402, 0.9861,\n",
       "                      1.0099, 1.0199, 1.0035, 0.9749, 1.0121, 1.0396, 0.9996, 0.9286, 0.9895,\n",
       "                      1.0090, 1.0379, 1.1029, 0.9707, 1.0691, 1.0557, 0.9671, 1.0213, 0.9825,\n",
       "                      0.9665, 0.9880, 1.0064, 1.0347], device='cuda:0')),\n",
       "             ('module.layers.2.norm1.bias',\n",
       "              tensor([ 2.0203e-02,  8.6795e-02, -6.8903e-02, -1.8143e-01,  5.6750e-02,\n",
       "                      -7.2757e-02,  4.9774e-02, -1.5166e-01, -3.2026e-02,  6.0222e-02,\n",
       "                      -3.7099e-02,  2.9795e-02,  6.3384e-03,  1.4148e-01,  4.5924e-02,\n",
       "                      -7.5325e-02, -9.7805e-02, -4.3648e-02, -1.5297e-01, -1.0222e-01,\n",
       "                       8.5419e-03,  1.8273e-01, -2.4573e-02, -2.9979e-02,  2.3413e-02,\n",
       "                      -8.0750e-02,  2.6396e-02, -8.3933e-02,  1.4813e-02,  2.4171e-02,\n",
       "                      -7.3120e-02,  1.4411e-02,  1.1052e-01,  7.4232e-02, -1.6752e-02,\n",
       "                      -2.2119e-03, -4.8441e-02, -1.2918e-02, -4.7321e-03,  2.2096e-02,\n",
       "                       7.6686e-02, -6.0619e-02, -4.3189e-02,  1.1334e-01,  1.1178e-01,\n",
       "                       4.4219e-02,  1.1431e-01, -7.4667e-02,  9.0774e-02,  9.0905e-02,\n",
       "                      -8.8200e-02,  1.0606e-01,  1.1832e-02, -1.0408e-02,  4.0515e-02,\n",
       "                       2.3365e-01,  1.2862e-01, -1.8735e-01,  1.2235e-01, -7.9888e-02,\n",
       "                       1.0273e-02,  5.4787e-02, -1.1068e-01, -1.7398e-01, -6.5379e-04,\n",
       "                       1.7107e-01,  3.2959e-02,  5.9431e-02, -2.3827e-02, -1.8244e-02,\n",
       "                       2.4631e-02, -7.2585e-02, -6.3426e-02,  4.2315e-02, -2.5806e-02,\n",
       "                      -9.6159e-03,  5.5350e-02, -2.1828e-02,  3.8973e-02, -8.3085e-02,\n",
       "                      -9.5647e-02,  1.7685e-02,  4.3467e-02,  1.1635e-02,  4.2602e-02,\n",
       "                      -2.3835e-02,  3.5059e-02,  7.1193e-02,  1.7215e-01,  7.9178e-02,\n",
       "                       1.2669e-01,  3.9105e-02,  1.7292e-02, -1.9185e-02, -7.0518e-03,\n",
       "                      -2.1378e-02,  8.3520e-02,  6.2375e-02,  2.6530e-02, -8.8081e-02,\n",
       "                      -5.2546e-03, -5.7678e-02, -4.1737e-02,  5.1253e-02,  1.3848e-01,\n",
       "                       3.7737e-02,  4.6353e-02, -7.6842e-02, -1.4655e-01, -5.7701e-02,\n",
       "                       1.0340e-01,  1.0230e-01,  1.2049e-02, -6.7990e-02,  7.8317e-02,\n",
       "                       5.8646e-02, -1.4071e-01, -1.1224e-01,  8.9585e-02, -1.2439e-01,\n",
       "                       1.1377e-01, -1.5736e-01, -1.2073e-01,  8.7757e-02, -4.3965e-02,\n",
       "                       7.3726e-02,  7.6411e-02, -5.5713e-02,  3.1307e-02, -1.4727e-01,\n",
       "                      -4.8897e-02, -5.8884e-02,  6.3854e-02,  1.8522e-01, -5.0209e-02,\n",
       "                       1.0878e-01, -1.4821e-01, -2.9677e-02, -2.7883e-02, -2.0656e-02,\n",
       "                       1.0348e-01,  4.1528e-02, -3.3936e-02, -5.1361e-02, -5.5749e-02,\n",
       "                      -1.1397e-01,  1.1476e-01, -3.6909e-02,  1.5976e-01, -1.2295e-03,\n",
       "                       5.8409e-02,  2.1274e-01,  7.2551e-02, -2.8191e-02, -2.5345e-03,\n",
       "                      -2.3987e-02, -9.3088e-02,  2.0144e-03, -9.4874e-02,  1.3190e-01,\n",
       "                       8.4007e-03, -2.7985e-02,  1.0258e-02, -1.5929e-02, -1.1345e-01,\n",
       "                       1.0830e-01,  2.6480e-02, -6.7545e-02,  5.2025e-02, -1.2894e-01,\n",
       "                      -2.2662e-02,  6.1250e-02, -9.5697e-02,  7.2905e-02,  2.7686e-02,\n",
       "                      -1.5547e-02, -5.9130e-02,  4.2334e-02,  4.7135e-02,  1.3237e-01,\n",
       "                      -1.2829e-01, -5.1975e-02,  8.9997e-02, -1.2765e-02,  4.2591e-02,\n",
       "                       1.4796e-01, -1.2631e-01, -1.4403e-01,  5.6316e-03, -5.5514e-02,\n",
       "                      -2.9388e-02, -7.6808e-02, -2.9804e-02, -5.7986e-02, -2.1426e-02,\n",
       "                      -9.6178e-02, -1.3523e-02, -2.6999e-03, -6.0565e-02,  9.7915e-02,\n",
       "                       6.2108e-02,  1.2460e-02,  5.6995e-02, -7.1935e-02, -3.6165e-02,\n",
       "                       6.8884e-02, -5.0884e-02, -1.2065e-01,  6.1004e-02,  1.2104e-01,\n",
       "                      -3.9874e-02,  2.0492e-02, -6.1090e-02,  1.6818e-02, -1.2166e-01,\n",
       "                      -6.3418e-02,  3.5731e-02, -1.1091e-02,  8.9618e-02,  3.8758e-02,\n",
       "                       4.8349e-02, -2.2501e-01, -5.2959e-02,  4.3679e-02,  4.2042e-02,\n",
       "                      -7.6804e-02, -3.9260e-02,  7.6127e-02,  2.3191e-02,  1.2592e-01,\n",
       "                       1.3330e-01, -2.8191e-03, -6.4989e-02,  4.6577e-02, -7.7672e-02,\n",
       "                       4.2527e-03,  3.8641e-02, -3.3155e-02,  4.7955e-02, -1.2917e-02,\n",
       "                       3.1704e-02, -4.0356e-02, -1.8935e-02, -3.1237e-02, -9.6631e-02,\n",
       "                       2.2963e-03,  2.8228e-02, -1.7029e-04, -7.8929e-02,  3.7438e-02,\n",
       "                       1.1371e-02,  8.3301e-02,  2.0687e-02, -2.5148e-02, -1.3938e-01,\n",
       "                       4.1145e-02], device='cuda:0')),\n",
       "             ('module.layers.2.norm2.weight',\n",
       "              tensor([0.9222, 0.8768, 0.9666, 0.9001, 0.8814, 0.7483, 0.8617, 0.9235, 0.8758,\n",
       "                      0.9294, 0.9016, 0.8639, 0.8973, 0.8835, 0.8417, 0.8728, 0.7549, 0.8000,\n",
       "                      0.7609, 0.8478, 0.9071, 0.4540, 0.8267, 0.8834, 0.9084, 0.7952, 0.8042,\n",
       "                      0.9469, 0.8767, 0.9122, 0.8500, 0.8370, 0.8795, 0.9172, 0.9379, 0.9040,\n",
       "                      0.9076, 0.8946, 0.8636, 0.8162, 0.8993, 0.8597, 0.8169, 0.7698, 0.8942,\n",
       "                      0.7589, 0.9005, 0.8614, 0.8780, 0.8983, 0.8469, 0.8740, 0.9101, 0.8490,\n",
       "                      0.7091, 0.8784, 0.8669, 0.8824, 0.8850, 0.7961, 0.8749, 0.8394, 0.8649,\n",
       "                      0.7754, 0.9054, 0.8451, 0.7767, 0.9204, 0.8265, 0.8400, 0.9368, 0.8163,\n",
       "                      0.8577, 0.8618, 0.8778, 0.8479, 0.7329, 0.8083, 0.9426, 0.7985, 0.8521,\n",
       "                      0.9523, 0.8758, 0.8706, 0.7903, 0.7960, 0.9309, 0.8984, 0.8244, 0.8710,\n",
       "                      0.7672, 0.9251, 0.9109, 0.9227, 0.7949, 0.8007, 0.8511, 0.8665, 0.9015,\n",
       "                      0.9563, 0.9307, 0.8635, 0.8779, 0.8524, 0.8455, 0.8236, 0.8466, 0.8645,\n",
       "                      0.8951, 0.8387, 0.8335, 0.8033, 0.8237, 0.8655, 0.8842, 0.8376, 0.7240,\n",
       "                      0.9243, 0.8907, 0.8785, 0.8110, 0.8875, 0.8642, 0.8063, 0.8918, 0.9458,\n",
       "                      0.9221, 0.9262, 0.9090, 0.8245, 0.7830, 0.8366, 0.9296, 0.8748, 0.8773,\n",
       "                      0.9048, 0.8939, 0.9400, 0.8884, 0.8613, 0.8429, 0.8205, 0.7901, 0.8239,\n",
       "                      0.8439, 0.9093, 0.8028, 0.8588, 0.8005, 0.9338, 0.8165, 0.8942, 0.8747,\n",
       "                      0.8917, 0.8423, 0.8733, 0.7918, 0.9177, 0.9188, 0.8753, 0.8502, 0.9333,\n",
       "                      0.7748, 0.8417, 0.8846, 0.8165, 0.9014, 0.8990, 0.8852, 0.9134, 0.8892,\n",
       "                      0.8301, 0.9271, 0.8710, 0.9233, 0.8387, 0.9126, 0.8693, 0.9389, 0.7563,\n",
       "                      0.8919, 0.8707, 0.9148, 0.9347, 0.9108, 0.8309, 0.8839, 0.8053, 0.8793,\n",
       "                      0.9228, 0.8877, 0.8368, 0.8435, 0.8644, 0.8998, 0.8876, 0.8742, 0.8578,\n",
       "                      0.9560, 0.9159, 0.8662, 0.8980, 0.8503, 0.8481, 0.8712, 0.8529, 0.1726,\n",
       "                      0.8418, 0.8691, 0.9801, 0.8257, 0.8506, 0.8471, 0.7270, 0.8636, 0.8477,\n",
       "                      0.8877, 0.8753, 0.8486, 0.9064, 0.9202, 0.8623, 0.8977, 0.9177, 0.9566,\n",
       "                      0.7343, 0.9153, 0.8805, 0.8834, 0.7667, 0.8372, 0.8679, 0.8726, 0.9549,\n",
       "                      0.8618, 0.8214, 0.8472, 0.8798, 0.8224, 0.9020, 0.9219, 0.9298, 0.8725,\n",
       "                      0.7782, 0.8165, 0.8527, 0.9100, 0.8090, 0.8494, 0.9104, 0.8571, 0.7740,\n",
       "                      0.9527, 0.9017, 0.8673, 0.8510], device='cuda:0')),\n",
       "             ('module.layers.2.norm2.bias',\n",
       "              tensor([-6.6940e-02, -1.1753e-01,  2.4517e-03, -3.2982e-02,  3.2243e-02,\n",
       "                       4.6108e-02, -3.2950e-02,  3.2832e-02, -1.0638e-02,  1.3587e-02,\n",
       "                       3.0810e-02,  1.2187e-01, -4.8542e-03, -1.1268e-01, -9.2781e-03,\n",
       "                       4.8936e-02,  7.4989e-02,  2.6847e-02,  6.9510e-02, -4.3673e-02,\n",
       "                       6.2048e-02, -1.4981e-01, -1.9076e-02, -9.0242e-02, -3.0271e-02,\n",
       "                       1.1757e-01, -9.2813e-03,  7.3179e-03, -6.5301e-02, -7.8156e-02,\n",
       "                       1.0517e-01,  1.6336e-02,  1.7014e-02, -3.1382e-02, -2.8653e-02,\n",
       "                      -3.0437e-02, -7.8764e-05, -1.2088e-02, -2.3321e-02, -1.2737e-01,\n",
       "                       4.5234e-02,  7.9000e-02,  1.3583e-02,  1.3610e-02,  7.0920e-02,\n",
       "                      -9.9230e-02, -3.9658e-02,  1.8712e-01,  4.1450e-02, -1.2099e-02,\n",
       "                       8.0490e-02,  9.8838e-02,  6.9004e-02, -5.8745e-02, -1.5122e-03,\n",
       "                      -3.6878e-02, -7.9687e-02, -3.7238e-02, -8.8267e-03,  6.8373e-02,\n",
       "                      -1.9892e-03, -2.0448e-02,  9.0859e-02,  8.6232e-02,  3.0926e-02,\n",
       "                      -3.7568e-02, -7.2253e-03, -5.9088e-02, -5.5961e-02, -1.0371e-01,\n",
       "                       5.3185e-02,  4.1004e-02,  2.1571e-02, -1.1447e-01, -2.2553e-02,\n",
       "                       6.2292e-02, -2.5398e-02,  1.6107e-02,  7.4825e-02,  1.5886e-01,\n",
       "                       5.5892e-03, -1.0579e-02, -7.5272e-02, -1.2482e-02, -6.9357e-02,\n",
       "                       3.2251e-02,  5.7365e-02, -4.3326e-02, -1.0276e-02, -5.1222e-02,\n",
       "                      -1.3956e-01,  4.8390e-02,  3.5018e-02,  4.2413e-02, -4.0551e-02,\n",
       "                      -1.9101e-02, -2.3041e-02, -2.2762e-02,  4.2541e-02,  2.5409e-02,\n",
       "                       2.7587e-02,  1.5090e-01,  1.2426e-01,  2.6764e-02,  4.3757e-02,\n",
       "                       3.7463e-02,  5.7052e-03,  8.3688e-02, -4.4742e-03, -6.9405e-02,\n",
       "                      -6.8131e-02, -8.3882e-02,  2.6995e-02,  8.5822e-02,  6.9430e-02,\n",
       "                      -5.8990e-02,  3.9035e-02,  5.5259e-02, -6.6691e-02, -3.9752e-02,\n",
       "                       7.5133e-03,  5.8728e-02,  1.1886e-01, -5.4716e-02,  1.0949e-01,\n",
       "                       7.0152e-04,  1.1362e-04,  6.3592e-02,  3.6804e-02,  7.3487e-02,\n",
       "                       6.4478e-02,  4.7877e-02,  3.5051e-02, -1.7517e-02,  8.3309e-02,\n",
       "                      -8.5677e-02,  6.1612e-02, -2.0943e-02, -1.4915e-02,  1.1054e-02,\n",
       "                      -5.0532e-02,  2.0145e-02,  1.6631e-01, -3.5274e-02,  1.4245e-02,\n",
       "                       1.0199e-01,  3.7733e-02, -6.0393e-02,  5.7578e-02,  3.3127e-02,\n",
       "                       2.5531e-02, -1.1577e-02,  1.7087e-02, -8.0662e-02, -8.6257e-02,\n",
       "                      -9.4864e-03,  1.5314e-02,  1.2659e-02,  2.3668e-02,  2.5823e-02,\n",
       "                      -1.0361e-02,  7.3954e-02, -1.3103e-01,  7.6914e-02,  1.5684e-01,\n",
       "                      -4.4279e-02,  5.7167e-03, -3.2248e-02,  7.2902e-04,  1.3794e-02,\n",
       "                      -1.5471e-02,  5.1059e-02, -8.3666e-03,  3.8653e-02, -8.6081e-04,\n",
       "                      -1.6426e-02,  7.6057e-02, -2.0120e-02, -5.6754e-03, -4.1034e-02,\n",
       "                       7.2583e-02, -3.9342e-03, -6.3475e-02, -2.8126e-03,  3.2658e-02,\n",
       "                       1.1534e-02,  2.7342e-02,  1.8340e-01,  7.8976e-02,  4.7816e-02,\n",
       "                       8.6106e-03,  3.1415e-02,  9.1824e-02, -5.3305e-02, -1.1554e-01,\n",
       "                       1.6283e-02, -3.7142e-02, -1.2009e-01,  2.8484e-02,  3.6842e-03,\n",
       "                       2.0820e-02,  2.0122e-02,  3.8676e-03, -1.0938e-01, -9.6989e-03,\n",
       "                      -6.7057e-02,  4.1229e-02,  8.2460e-02,  7.0392e-02, -4.2596e-02,\n",
       "                       1.2303e-01, -3.2469e-02,  1.8509e-02,  1.2885e-02,  7.5083e-02,\n",
       "                       3.9187e-02,  4.3378e-02, -1.0489e-02, -9.6430e-03, -3.9388e-02,\n",
       "                       4.4200e-03, -7.3790e-04,  4.1538e-03, -7.1528e-02, -7.8023e-02,\n",
       "                       1.2777e-01, -3.4207e-02, -1.4807e-02, -6.4903e-02, -3.8814e-02,\n",
       "                       5.6745e-02,  8.6066e-02,  3.2645e-02, -3.9232e-02,  3.4431e-02,\n",
       "                       4.8605e-02, -5.0992e-02,  5.1173e-02, -9.1318e-03, -6.4211e-02,\n",
       "                       3.8825e-02, -1.0921e-02,  9.5816e-02,  1.8762e-02,  3.5530e-02,\n",
       "                      -6.2000e-02,  6.8151e-02, -1.1365e-01,  6.3613e-02,  4.9711e-02,\n",
       "                       3.4773e-03,  2.7804e-02, -1.7346e-02,  4.2165e-02,  4.7890e-02,\n",
       "                      -1.1046e-02], device='cuda:0')),\n",
       "             ('module.layers.3.attn.attn.adaptive_span._mask.current_val',\n",
       "              tensor([[[0.4899]],\n",
       "              \n",
       "                      [[0.0270]],\n",
       "              \n",
       "                      [[0.0374]],\n",
       "              \n",
       "                      [[0.0560]]], device='cuda:0')),\n",
       "             ('module.layers.3.attn.attn.adaptive_span._mask.mask_template',\n",
       "              tensor([-1.0230e+03, -1.0220e+03, -1.0210e+03,  ..., -2.0000e+00,\n",
       "                      -1.0000e+00,  0.0000e+00], device='cuda:0')),\n",
       "             ('module.layers.3.attn.proj_query.weight',\n",
       "              tensor([[ 0.1601, -0.0339,  0.1235,  ...,  0.1908,  0.0665, -0.2641],\n",
       "                      [ 0.0999, -0.1255, -0.1839,  ..., -0.0320, -0.1297,  0.0647],\n",
       "                      [-0.1003, -0.0939,  0.0134,  ...,  0.0113,  0.0518,  0.0289],\n",
       "                      ...,\n",
       "                      [-0.0472,  0.0013,  0.0339,  ...,  0.0906, -0.1101,  0.0877],\n",
       "                      [-0.0149, -0.0684,  0.2307,  ..., -0.0149, -0.0663, -0.0698],\n",
       "                      [ 0.0228,  0.1913,  0.2079,  ...,  0.0743,  0.1279, -0.0072]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.3.attn.proj_out.weight',\n",
       "              tensor([[ 0.0557, -0.0211,  0.0163,  ..., -0.0346, -0.0113,  0.0250],\n",
       "                      [-0.0218, -0.0739,  0.0540,  ..., -0.0454,  0.0309, -0.1014],\n",
       "                      [-0.0758, -0.0466,  0.0283,  ...,  0.0620,  0.0271,  0.0186],\n",
       "                      ...,\n",
       "                      [ 0.0867, -0.0541,  0.0079,  ...,  0.1213, -0.0458,  0.1223],\n",
       "                      [ 0.0165, -0.0194, -0.0413,  ...,  0.1050, -0.0634,  0.0646],\n",
       "                      [-0.0407,  0.0517, -0.0420,  ..., -0.0653, -0.0581,  0.0024]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.3.attn.proj_val.weight',\n",
       "              tensor([[-0.1091,  0.0318,  0.0145,  ...,  0.0063, -0.0945, -0.0374],\n",
       "                      [ 0.0843, -0.0275,  0.0772,  ..., -0.0060,  0.0054,  0.0539],\n",
       "                      [-0.0614,  0.0470,  0.0126,  ...,  0.0389, -0.0724,  0.0319],\n",
       "                      ...,\n",
       "                      [ 0.0573,  0.0237, -0.0112,  ...,  0.0345,  0.0263,  0.0869],\n",
       "                      [-0.0273, -0.0708,  0.1319,  ..., -0.1130, -0.0137, -0.0156],\n",
       "                      [-0.0413, -0.0057, -0.0962,  ...,  0.0585,  0.0329, -0.0531]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.3.attn.proj_key.weight',\n",
       "              tensor([[-0.1048, -0.1043, -0.1611,  ..., -0.1113,  0.0252, -0.1660],\n",
       "                      [-0.0038,  0.2505, -0.1645,  ..., -0.0023, -0.1944, -0.1757],\n",
       "                      [-0.2283,  0.1012,  0.0452,  ...,  0.2195, -0.0068,  0.0546],\n",
       "                      ...,\n",
       "                      [ 0.1238,  0.0022, -0.1580,  ...,  0.0675, -0.0079, -0.1796],\n",
       "                      [-0.1247, -0.0717, -0.1206,  ...,  0.1284,  0.0058, -0.0406],\n",
       "                      [-0.1019,  0.0208, -0.0453,  ...,  0.0023, -0.1022,  0.0709]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.3.ff.fc1.weight',\n",
       "              tensor([[-0.0192, -0.0086,  0.0443,  ..., -0.0625,  0.0450, -0.0899],\n",
       "                      [ 0.0414, -0.0141,  0.0626,  ..., -0.0473,  0.1028,  0.0144],\n",
       "                      [ 0.0786,  0.0816, -0.0836,  ..., -0.1201, -0.0256, -0.0261],\n",
       "                      ...,\n",
       "                      [-0.0465,  0.0568,  0.1946,  ..., -0.0697, -0.1313, -0.1230],\n",
       "                      [-0.0241,  0.0066, -0.0823,  ..., -0.0059,  0.0377,  0.0931],\n",
       "                      [-0.0747, -0.0402, -0.0004,  ..., -0.0941, -0.1431, -0.1441]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.3.ff.fc1.bias',\n",
       "              tensor([-0.0975, -0.1619, -0.1694,  ..., -0.1919, -0.2074, -0.2109],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.3.ff.fc2.weight',\n",
       "              tensor([[ 0.0515, -0.0028, -0.0146,  ..., -0.0153,  0.0193, -0.0001],\n",
       "                      [-0.0121, -0.0092,  0.0005,  ..., -0.0327,  0.0126,  0.0053],\n",
       "                      [-0.0238, -0.0085,  0.0329,  ..., -0.0413,  0.0002, -0.0397],\n",
       "                      ...,\n",
       "                      [ 0.0388, -0.0490,  0.0101,  ..., -0.0353, -0.0038,  0.0034],\n",
       "                      [-0.0651,  0.0103,  0.0131,  ..., -0.0293,  0.0036,  0.0691],\n",
       "                      [ 0.0026, -0.0023, -0.0049,  ...,  0.0126, -0.0480,  0.0261]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.3.ff.fc2.bias',\n",
       "              tensor([ 1.8138e-02, -1.1814e-01,  3.7918e-02,  4.8467e-02,  1.1012e-01,\n",
       "                      -1.4983e-02, -4.7920e-03,  1.1182e-03, -2.6708e-02, -1.8135e-02,\n",
       "                       4.3050e-03, -7.6827e-02, -2.4433e-02, -5.8492e-02, -1.1940e-02,\n",
       "                      -3.0475e-02, -4.1755e-02,  8.6078e-02,  4.9066e-02, -1.5109e-02,\n",
       "                      -1.2732e-02, -1.1981e-01, -4.6790e-02, -4.4094e-02, -5.1449e-03,\n",
       "                      -2.8475e-02,  4.0349e-02, -1.9539e-02, -5.4003e-02, -3.0715e-02,\n",
       "                       6.0633e-02, -4.0647e-02,  3.5802e-02, -4.8711e-02, -6.0039e-02,\n",
       "                      -6.1542e-02, -2.2535e-02, -1.3706e-02, -4.4895e-02, -6.8413e-02,\n",
       "                       4.9077e-03,  2.3841e-02,  1.4169e-02, -2.4201e-02, -1.3455e-02,\n",
       "                      -1.3893e-01,  2.9101e-02,  1.2453e-01,  7.3523e-02,  1.3106e-02,\n",
       "                       1.2464e-01,  9.0291e-02,  7.9518e-02,  5.0154e-02,  6.5964e-02,\n",
       "                       7.7775e-02, -2.9316e-03, -8.5219e-02,  3.3605e-02, -9.2440e-03,\n",
       "                      -3.3594e-02, -1.8703e-02,  6.6252e-02, -9.7882e-04,  4.9376e-02,\n",
       "                      -1.4495e-02, -7.6944e-02, -6.0978e-02, -3.5738e-03, -1.4144e-01,\n",
       "                       7.8613e-02, -6.9013e-02,  2.1905e-02, -8.1997e-02, -3.8528e-02,\n",
       "                       3.3959e-02, -1.4701e-03, -9.8863e-02, -6.0074e-03,  4.0901e-02,\n",
       "                      -4.1329e-02, -9.5555e-03, -4.3819e-02, -2.2559e-02, -1.4378e-02,\n",
       "                       4.8831e-02,  1.3459e-02, -2.8189e-02,  2.1172e-02, -2.8588e-02,\n",
       "                      -6.2370e-02,  6.1342e-02, -1.7026e-02,  5.0895e-02, -4.3818e-02,\n",
       "                       8.3517e-02,  4.5194e-02, -4.5990e-02,  2.3630e-02, -7.0726e-03,\n",
       "                       1.6240e-02,  3.5549e-02,  9.1943e-02, -8.4148e-02,  8.8531e-02,\n",
       "                       1.3955e-02,  4.3557e-02,  1.8079e-02, -9.1275e-02, -4.3867e-02,\n",
       "                      -1.4272e-03, -8.7186e-03,  1.6770e-02,  4.3208e-02,  1.2045e-02,\n",
       "                      -6.3002e-02,  5.3739e-02,  1.0056e-02,  1.4739e-02, -3.6695e-02,\n",
       "                       5.2459e-02, -2.3965e-02, -9.6253e-03,  2.9319e-02,  2.5549e-02,\n",
       "                      -3.4406e-02,  8.4655e-02,  1.5545e-02,  3.4782e-02, -9.9185e-03,\n",
       "                      -5.8351e-04, -5.1975e-03, -4.0616e-03,  6.7239e-02,  5.9070e-02,\n",
       "                       6.0254e-02,  2.6136e-02, -6.2512e-02, -7.5330e-03, -5.2308e-02,\n",
       "                      -2.9167e-02, -1.6982e-02,  5.4472e-02, -4.2915e-02,  1.7885e-02,\n",
       "                       8.8428e-03,  3.8350e-02, -8.9687e-02,  9.9903e-02, -1.5577e-02,\n",
       "                      -3.8255e-02,  4.6985e-02,  3.9609e-02, -4.2941e-02, -2.5154e-02,\n",
       "                      -3.1735e-02,  4.3220e-02, -8.0712e-02, -2.1333e-02,  4.6085e-02,\n",
       "                      -6.4717e-02,  5.1196e-02, -1.6874e-02, -2.3741e-02,  6.8961e-02,\n",
       "                      -4.8540e-02,  1.1865e-02,  2.5113e-02, -1.1192e-02, -7.4102e-02,\n",
       "                       4.9050e-02,  3.9571e-03,  1.4199e-02,  5.9750e-02,  1.6297e-02,\n",
       "                      -7.4075e-02, -2.8693e-02,  1.1357e-02,  5.8217e-02,  5.9154e-03,\n",
       "                      -1.5061e-01,  1.2109e-01, -3.9303e-02, -1.2160e-01, -2.3327e-02,\n",
       "                      -5.4275e-03, -2.1597e-02,  5.4826e-02, -2.8336e-02,  1.0489e-01,\n",
       "                      -3.3978e-02, -5.6604e-02, -5.6984e-02, -6.6289e-02, -5.1840e-02,\n",
       "                      -1.1290e-02, -1.2419e-02, -1.4803e-02,  1.2197e-01, -1.0418e-02,\n",
       "                       8.8178e-02, -1.0138e-01, -5.1569e-02, -1.2089e-01,  6.7818e-02,\n",
       "                      -1.9942e-02, -3.2585e-01,  2.9459e-02,  3.2610e-02,  1.1069e-02,\n",
       "                       8.0853e-02,  4.0942e-02, -4.7905e-02,  4.4981e-02,  6.7128e-02,\n",
       "                       3.1087e-02,  1.3698e-02, -6.4425e-04, -4.6502e-02, -1.5008e-02,\n",
       "                       7.6732e-02,  1.2063e-02,  4.6381e-02,  4.0466e-02, -1.2158e-03,\n",
       "                       1.6044e-02, -7.3083e-03, -3.1823e-02, -2.5393e-02,  2.3175e-02,\n",
       "                      -3.0241e-02,  4.9595e-03,  4.0861e-02,  7.7424e-02, -2.2438e-02,\n",
       "                       3.2952e-02,  8.3161e-02,  9.4222e-03, -2.4354e-02, -4.3974e-02,\n",
       "                       5.2986e-02, -5.6494e-02,  8.4954e-02,  4.8892e-02,  7.6047e-02,\n",
       "                      -1.0796e-03,  2.8197e-02,  1.6097e-02, -1.0438e-01,  3.8121e-02,\n",
       "                      -3.6592e-03,  3.8840e-02, -8.7776e-05,  6.1697e-02, -4.4424e-02,\n",
       "                      -1.0300e-02], device='cuda:0')),\n",
       "             ('module.layers.3.norm1.weight',\n",
       "              tensor([1.0124, 0.9950, 1.0464, 0.9597, 1.0484, 1.1710, 0.9713, 1.0153, 0.9278,\n",
       "                      0.9804, 1.0162, 1.0183, 1.0780, 0.9398, 1.0483, 1.0973, 0.9817, 0.9623,\n",
       "                      1.1078, 0.9555, 1.0206, 1.3483, 1.0230, 0.9462, 0.9815, 1.1748, 1.0092,\n",
       "                      0.9246, 0.9818, 1.0136, 1.0206, 0.9841, 0.9645, 1.0026, 0.9678, 1.0061,\n",
       "                      0.9827, 1.0268, 1.0454, 0.9781, 1.1228, 1.0204, 1.0517, 0.9933, 0.9500,\n",
       "                      1.1718, 0.9910, 0.9570, 0.9989, 1.0888, 0.9780, 0.9296, 0.9595, 0.9880,\n",
       "                      1.1458, 1.0550, 0.9545, 0.9712, 0.9504, 0.9767, 1.0059, 0.9149, 1.0205,\n",
       "                      1.0663, 1.0011, 0.9610, 1.0167, 1.0015, 1.0162, 0.9977, 1.0022, 0.8818,\n",
       "                      1.1074, 1.0591, 0.9959, 0.9843, 1.1036, 0.9725, 0.9976, 0.9978, 0.9546,\n",
       "                      1.0155, 0.9646, 0.9771, 1.0534, 0.9670, 1.0068, 1.0223, 0.9869, 0.9930,\n",
       "                      1.0855, 0.9521, 0.9719, 1.0753, 1.0659, 1.0468, 0.9648, 1.0348, 0.9752,\n",
       "                      1.0432, 1.0195, 0.9638, 0.9729, 1.0502, 0.9610, 1.0401, 1.0197, 1.0352,\n",
       "                      0.9350, 0.9913, 1.0090, 1.0476, 1.0421, 1.0487, 1.0074, 1.0123, 1.0568,\n",
       "                      0.9780, 0.9619, 0.9655, 1.0319, 0.9868, 1.0354, 0.9887, 0.9952, 1.0225,\n",
       "                      1.0106, 1.0443, 0.9732, 0.9844, 1.0205, 0.9917, 0.9618, 0.9418, 0.9944,\n",
       "                      0.9298, 1.0256, 0.9820, 1.0050, 0.9771, 1.0145, 1.1024, 1.0813, 0.9256,\n",
       "                      1.0142, 0.9635, 0.9677, 1.0104, 1.0529, 1.0222, 0.9952, 1.0088, 0.9909,\n",
       "                      0.9986, 1.0097, 1.0267, 1.0370, 1.0162, 0.9684, 1.0410, 1.0066, 1.0150,\n",
       "                      1.0555, 0.9316, 0.9774, 1.0383, 1.0315, 0.9477, 1.0268, 1.0790, 0.9277,\n",
       "                      1.0742, 0.9962, 0.9882, 0.9917, 1.0359, 0.9629, 0.9278, 1.0539, 1.0480,\n",
       "                      0.9711, 0.9891, 1.0016, 1.0812, 1.0038, 1.1061, 1.0552, 0.9796, 0.9982,\n",
       "                      1.0496, 1.0373, 0.9825, 1.0739, 0.9802, 1.0155, 1.0399, 0.9746, 0.9689,\n",
       "                      0.9831, 0.9705, 0.9513, 1.0531, 0.9819, 0.9458, 0.9977, 1.0381, 2.0622,\n",
       "                      1.0623, 0.9615, 0.9714, 1.0219, 1.0269, 0.9754, 1.0703, 0.9612, 1.1426,\n",
       "                      1.0348, 0.8993, 0.9513, 1.0918, 0.9463, 1.0010, 0.9685, 1.0789, 1.0219,\n",
       "                      1.0701, 1.0106, 1.0346, 1.0658, 0.9401, 1.1426, 1.0068, 1.0360, 1.0705,\n",
       "                      0.9849, 1.0204, 0.9668, 1.0466, 0.9761, 1.0140, 1.0373, 0.9685, 1.0067,\n",
       "                      0.9539, 0.9982, 1.1019, 0.9944, 0.9616, 0.9880, 0.9912, 0.9810, 0.9839,\n",
       "                      0.9532, 0.9652, 0.9950, 0.9390], device='cuda:0')),\n",
       "             ('module.layers.3.norm1.bias',\n",
       "              tensor([ 0.0538, -0.0167,  0.0194,  0.1013, -0.0363, -0.2352, -0.0405, -0.1401,\n",
       "                      -0.0998, -0.0159, -0.0992, -0.1083, -0.1043, -0.0849,  0.0781,  0.0924,\n",
       "                       0.0200,  0.0630, -0.0969,  0.0102, -0.0007,  0.1021, -0.0075,  0.0617,\n",
       "                       0.0810, -0.2107,  0.0425,  0.0084,  0.0738,  0.0160, -0.0202,  0.0991,\n",
       "                      -0.0484,  0.0653, -0.0350, -0.0695, -0.0024, -0.0877,  0.1145,  0.0928,\n",
       "                       0.0214, -0.0523, -0.1611,  0.0434,  0.0305,  0.1496,  0.0256,  0.0721,\n",
       "                       0.0991,  0.0017, -0.0010,  0.0227,  0.0042, -0.0465,  0.0788,  0.0985,\n",
       "                       0.0133, -0.1189,  0.0518, -0.0636,  0.1369, -0.0030,  0.0292, -0.1070,\n",
       "                      -0.0062, -0.0281, -0.0568,  0.0271,  0.0596, -0.0535, -0.0069,  0.0050,\n",
       "                      -0.0826,  0.0519, -0.0460,  0.0475, -0.0009, -0.0467,  0.0154, -0.0179,\n",
       "                      -0.0255, -0.0799,  0.0753,  0.0485,  0.1522, -0.0276, -0.1257,  0.0068,\n",
       "                       0.1152, -0.0396,  0.0641,  0.1247, -0.0757,  0.0837, -0.0160,  0.0314,\n",
       "                      -0.1463, -0.0344,  0.0957, -0.0380, -0.0474,  0.0590, -0.0442,  0.0095,\n",
       "                       0.0305, -0.0808,  0.0922, -0.1706, -0.1354,  0.0505,  0.0526,  0.0994,\n",
       "                      -0.0681, -0.0174,  0.0398,  0.1326, -0.1556, -0.0849, -0.0074, -0.2245,\n",
       "                       0.0018, -0.0660, -0.1570,  0.1329, -0.0302,  0.0556, -0.0064,  0.0189,\n",
       "                       0.0209,  0.1785, -0.0029, -0.0901,  0.0475, -0.0476, -0.0301, -0.0254,\n",
       "                       0.0791,  0.0112,  0.1365, -0.1016,  0.0109,  0.1590, -0.1638, -0.0568,\n",
       "                      -0.0614, -0.0325,  0.1438,  0.0191,  0.1065, -0.0137,  0.0775, -0.0485,\n",
       "                      -0.0357,  0.0011,  0.0497,  0.1415,  0.0043,  0.0268, -0.0669,  0.0941,\n",
       "                       0.0970, -0.0204,  0.0817,  0.0512,  0.0572,  0.0756, -0.1162, -0.0386,\n",
       "                      -0.0302,  0.0064, -0.0842,  0.1811, -0.0712,  0.0085,  0.0382, -0.0944,\n",
       "                       0.0283,  0.0792,  0.0360,  0.0379, -0.1363, -0.0682, -0.1446,  0.0442,\n",
       "                       0.0763,  0.2113, -0.1642, -0.0173, -0.0969, -0.1037,  0.0350, -0.1177,\n",
       "                      -0.0841, -0.0724, -0.0453,  0.0113, -0.0425,  0.0149,  0.0167,  0.0619,\n",
       "                      -0.0554, -0.0459,  0.0392,  0.0287, -0.1572,  0.1027,  0.1018, -0.1705,\n",
       "                       0.0372,  0.1098, -0.0399, -0.1023, -0.0063, -0.0178, -0.1323, -0.1597,\n",
       "                      -0.0419, -0.0864,  0.0803, -0.0987,  0.1146, -0.0806,  0.0166,  0.0577,\n",
       "                       0.0457, -0.1550, -0.0508,  0.0768, -0.0016, -0.0578,  0.1751, -0.0510,\n",
       "                      -0.1752, -0.0078,  0.0009,  0.0278,  0.0965, -0.0232, -0.0155, -0.0041,\n",
       "                       0.1050, -0.0177, -0.0222, -0.1285, -0.0422,  0.0208, -0.0080, -0.0450,\n",
       "                       0.0298, -0.0502,  0.0829,  0.0259,  0.1209,  0.1061,  0.0074,  0.0744],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.3.norm2.weight',\n",
       "              tensor([0.7666, 0.7964, 0.7831, 0.8337, 0.7376, 0.5734, 0.8031, 0.7673, 0.7915,\n",
       "                      0.7866, 0.7965, 0.7358, 0.6502, 0.7724, 0.7105, 0.6952, 0.7760, 0.7308,\n",
       "                      0.7773, 0.7474, 0.7697, 0.6158, 0.8073, 0.7841, 0.7498, 0.5852, 0.7563,\n",
       "                      0.8480, 0.7918, 0.7480, 0.7174, 0.6983, 0.8043, 0.8129, 0.8081, 0.8069,\n",
       "                      0.7975, 0.7548, 0.6127, 0.7746, 0.7781, 0.7506, 0.7916, 0.7466, 0.7555,\n",
       "                      0.6615, 0.7356, 0.7620, 0.6863, 0.7952, 0.7652, 0.7776, 0.7908, 0.7373,\n",
       "                      0.7057, 0.7075, 0.8105, 0.7684, 0.8285, 0.7614, 0.7830, 0.7994, 0.8007,\n",
       "                      0.6658, 0.7928, 0.7834, 0.7318, 0.7899, 0.7239, 0.6667, 0.7872, 0.7610,\n",
       "                      0.7558, 0.7623, 0.7981, 0.7368, 0.6182, 0.7918, 0.7854, 0.7365, 0.8060,\n",
       "                      0.7802, 0.8063, 0.8019, 0.7669, 0.7712, 0.7879, 0.7860, 0.8197, 0.7873,\n",
       "                      0.7365, 0.7687, 0.7789, 0.8019, 0.7167, 0.7764, 0.7915, 0.7030, 0.7390,\n",
       "                      0.7780, 0.7816, 0.7561, 0.7725, 0.6907, 0.8030, 0.7685, 0.7442, 0.7173,\n",
       "                      0.7921, 0.7536, 0.7736, 0.7111, 0.6997, 0.7416, 0.7479, 0.7493, 0.6044,\n",
       "                      0.7446, 0.8360, 0.8059, 0.7374, 0.8207, 0.8068, 0.7524, 0.7315, 0.8099,\n",
       "                      0.8379, 0.7654, 0.8179, 0.8185, 0.6903, 0.7399, 0.7818, 0.7882, 0.8021,\n",
       "                      0.7890, 0.7427, 0.8103, 0.7535, 0.7123, 0.7130, 0.6130, 0.6609, 0.7502,\n",
       "                      0.7830, 0.7957, 0.7307, 0.7697, 0.7022, 0.8233, 0.8110, 0.7351, 0.7269,\n",
       "                      0.7643, 0.7450, 0.7128, 0.6836, 0.7840, 0.7325, 0.7290, 0.7448, 0.7945,\n",
       "                      0.7706, 0.8182, 0.8127, 0.7670, 0.7944, 0.7728, 0.7196, 0.7179, 0.8145,\n",
       "                      0.6113, 0.8277, 0.7576, 0.8217, 0.7534, 0.8182, 0.7714, 0.8395, 0.7856,\n",
       "                      0.6970, 0.7972, 0.7996, 0.7024, 0.7053, 0.6672, 0.7520, 0.8093, 0.8044,\n",
       "                      0.7782, 0.7424, 0.8024, 0.6587, 0.7003, 0.7857, 0.6651, 0.8297, 0.7030,\n",
       "                      0.7282, 0.7466, 0.7662, 0.7495, 0.7925, 0.7627, 0.7609, 0.7560, 0.2286,\n",
       "                      0.6985, 0.7576, 0.8344, 0.7428, 0.7502, 0.7282, 0.6021, 0.8023, 0.6258,\n",
       "                      0.7951, 0.8131, 0.7900, 0.6973, 0.8261, 0.7778, 0.8033, 0.6722, 0.7139,\n",
       "                      0.7503, 0.7130, 0.6885, 0.6073, 0.7840, 0.6448, 0.7846, 0.7046, 0.7176,\n",
       "                      0.8087, 0.7693, 0.7589, 0.7805, 0.7017, 0.7430, 0.7612, 0.8051, 0.7687,\n",
       "                      0.7142, 0.8192, 0.6055, 0.8000, 0.7828, 0.8135, 0.7929, 0.8155, 0.7842,\n",
       "                      0.7780, 0.7675, 0.7677, 0.7505], device='cuda:0')),\n",
       "             ('module.layers.3.norm2.bias',\n",
       "              tensor([-6.5248e-02, -4.8550e-02,  3.8463e-02, -2.5791e-02, -2.0966e-02,\n",
       "                       7.0003e-02,  6.8569e-02, -5.0667e-02, -5.1925e-02, -8.2318e-02,\n",
       "                       4.8966e-02,  1.0939e-01,  9.6979e-02, -2.8746e-02, -1.6711e-02,\n",
       "                       2.3591e-04,  9.2736e-02,  7.1630e-02,  2.5663e-02,  2.8844e-02,\n",
       "                       4.2025e-02, -4.8955e-02, -5.9624e-03, -6.7221e-02, -6.2312e-02,\n",
       "                       8.7917e-02,  2.9794e-02,  1.7809e-02, -8.2972e-02, -8.3299e-02,\n",
       "                      -6.1785e-02,  3.9174e-02,  3.0184e-02,  6.8610e-04, -1.0224e-01,\n",
       "                      -1.6233e-01, -3.4678e-02, -5.2147e-02,  2.2162e-02,  1.5947e-02,\n",
       "                       4.3747e-02,  5.4759e-02, -5.7196e-02, -2.0208e-02,  5.2146e-02,\n",
       "                      -9.6553e-02, -8.9352e-02,  5.9337e-02, -1.2160e-01,  2.1416e-02,\n",
       "                       3.9669e-03,  1.2085e-01,  2.2086e-02, -1.5016e-02, -4.6429e-02,\n",
       "                      -1.4090e-01, -1.2495e-01,  5.3940e-02,  2.8629e-02,  1.7244e-02,\n",
       "                      -6.9413e-02,  9.2553e-02, -4.0107e-02,  1.3527e-01,  2.4018e-02,\n",
       "                       2.6086e-02, -9.7342e-02, -8.6313e-04, -9.1499e-02, -1.8200e-01,\n",
       "                       5.7927e-02, -6.3950e-02, -1.4819e-02, -8.6212e-02,  8.4404e-03,\n",
       "                       6.4309e-02, -1.5089e-01,  3.5044e-02, -7.8577e-03,  7.3140e-02,\n",
       "                      -4.5450e-02, -1.5306e-02, -1.4324e-01, -1.0988e-02,  6.3032e-02,\n",
       "                       4.0199e-02,  6.1873e-02,  5.9586e-02, -3.4532e-02, -5.4314e-03,\n",
       "                      -6.1336e-02,  1.3235e-02,  2.9718e-02,  7.4295e-02, -2.4890e-02,\n",
       "                       6.9988e-02,  7.8391e-02,  7.9436e-02,  2.6280e-02,  5.1647e-02,\n",
       "                      -2.8099e-02,  1.4372e-02,  1.6064e-02, -1.1507e-01,  8.1618e-02,\n",
       "                       1.0585e-02, -1.3720e-02,  1.0647e-01,  2.6797e-02, -3.9380e-02,\n",
       "                      -3.4861e-02, -1.8866e-01,  7.6411e-02,  8.9993e-02,  1.0756e-01,\n",
       "                       3.5402e-02,  5.9958e-04,  9.1350e-03, -1.2622e-02, -1.4054e-02,\n",
       "                       1.7433e-02,  3.8566e-02, -4.0506e-02,  1.4754e-02,  2.8673e-02,\n",
       "                      -2.8485e-02, -8.6881e-02,  3.2844e-02,  6.7025e-03,  9.2038e-02,\n",
       "                       2.0378e-01,  9.4655e-02,  7.4387e-02, -4.0551e-02,  6.7097e-03,\n",
       "                      -1.2873e-01, -1.5836e-02, -2.9653e-02,  6.8433e-02,  1.6459e-02,\n",
       "                       5.0107e-02, -1.6367e-01,  4.3276e-02, -5.4006e-02,  3.6836e-02,\n",
       "                       8.3856e-02,  2.6562e-02,  2.1470e-02,  8.2209e-02, -5.9407e-02,\n",
       "                       1.3206e-02,  4.3557e-02,  6.4308e-02, -4.8664e-02, -4.4196e-02,\n",
       "                      -3.1684e-02, -3.1181e-02, -9.3422e-02, -1.6135e-02, -2.2286e-02,\n",
       "                      -1.2878e-01,  5.2615e-03,  9.8057e-03, -2.6771e-02,  3.9745e-03,\n",
       "                      -1.6750e-02, -9.2966e-02, -8.9567e-02,  2.3707e-02, -6.2648e-02,\n",
       "                       6.8263e-02,  7.8266e-02, -1.2839e-03,  2.0527e-02, -1.8005e-02,\n",
       "                      -3.8232e-02,  7.8028e-02, -2.7867e-02, -1.4245e-02, -9.1284e-02,\n",
       "                      -1.4465e-01, -1.5700e-02, -7.8575e-02,  4.7967e-02,  1.9296e-02,\n",
       "                       2.9931e-02,  6.0816e-02,  4.6476e-02, -1.1464e-01, -2.1655e-02,\n",
       "                      -1.4542e-01, -6.6373e-02,  2.4064e-02, -5.5671e-02, -4.9810e-02,\n",
       "                      -7.1966e-02, -7.6089e-02, -9.4184e-02,  1.1670e-01,  2.5662e-02,\n",
       "                      -4.5877e-02, -5.1724e-02, -1.2393e-02, -7.9425e-02, -7.3505e-03,\n",
       "                       1.4271e-02,  3.5788e-01,  9.0475e-03,  7.7717e-02, -6.5256e-02,\n",
       "                       8.9761e-02,  4.4436e-03, -4.5280e-02,  1.9115e-02,  9.7197e-02,\n",
       "                       1.3351e-01,  4.9293e-02, -6.1107e-02, -1.9566e-02,  5.4368e-03,\n",
       "                       4.8414e-03, -9.5069e-03,  1.2934e-02, -3.2680e-02,  2.0267e-02,\n",
       "                       2.7015e-02,  2.1353e-02, -1.1207e-01, -1.2041e-01, -2.6053e-02,\n",
       "                      -9.9828e-02,  5.4480e-02,  9.6103e-02,  6.5939e-02,  3.8617e-02,\n",
       "                      -5.7327e-02,  2.5373e-04, -6.2647e-04,  1.3166e-01, -2.0181e-01,\n",
       "                       6.4894e-02,  6.2039e-03,  7.9293e-02,  3.4693e-02, -1.0712e-01,\n",
       "                       1.3410e-02, -1.3808e-02, -7.0691e-02,  4.0158e-03,  1.1207e-01,\n",
       "                       4.8881e-02,  3.2123e-02,  1.0418e-01, -4.6684e-02, -4.8944e-02,\n",
       "                       5.5060e-02], device='cuda:0')),\n",
       "             ('module.layers.4.attn.attn.adaptive_span._mask.current_val',\n",
       "              tensor([[[0.0202]],\n",
       "              \n",
       "                      [[0.0116]],\n",
       "              \n",
       "                      [[0.0538]],\n",
       "              \n",
       "                      [[0.0037]]], device='cuda:0')),\n",
       "             ('module.layers.4.attn.attn.adaptive_span._mask.mask_template',\n",
       "              tensor([-1.0230e+03, -1.0220e+03, -1.0210e+03,  ..., -2.0000e+00,\n",
       "                      -1.0000e+00,  0.0000e+00], device='cuda:0')),\n",
       "             ('module.layers.4.attn.proj_query.weight',\n",
       "              tensor([[ 0.0121,  0.0111, -0.0163,  ...,  0.0422, -0.0805, -0.0550],\n",
       "                      [ 0.0605, -0.1430,  0.0756,  ...,  0.0268,  0.0809, -0.1092],\n",
       "                      [-0.0467,  0.0840, -0.0440,  ..., -0.0883,  0.0027, -0.0665],\n",
       "                      ...,\n",
       "                      [ 0.0339, -0.1371,  0.0386,  ..., -0.0052,  0.0435,  0.1019],\n",
       "                      [-0.0594,  0.0549,  0.0228,  ..., -0.1092,  0.0691, -0.0312],\n",
       "                      [-0.0657,  0.0311, -0.0193,  ...,  0.0358,  0.0013, -0.0718]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.attn.proj_out.weight',\n",
       "              tensor([[ 0.0480,  0.0408, -0.0300,  ..., -0.0156, -0.1294, -0.0588],\n",
       "                      [-0.0522, -0.0152, -0.0280,  ...,  0.0714,  0.0238,  0.0723],\n",
       "                      [-0.0101, -0.0698, -0.0173,  ..., -0.0339, -0.0047, -0.0726],\n",
       "                      ...,\n",
       "                      [ 0.0975,  0.0365, -0.0328,  ...,  0.1278,  0.0207, -0.0024],\n",
       "                      [-0.0286,  0.0536, -0.0315,  ...,  0.0139, -0.0302, -0.0226],\n",
       "                      [ 0.0323, -0.0516, -0.0188,  ...,  0.0521,  0.0168,  0.0165]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.attn.proj_val.weight',\n",
       "              tensor([[ 0.0394,  0.0659, -0.0443,  ...,  0.0114,  0.0215, -0.0948],\n",
       "                      [-0.0043, -0.0500,  0.0164,  ..., -0.0098, -0.0009,  0.0081],\n",
       "                      [-0.0345,  0.0968, -0.0659,  ..., -0.0516, -0.0823, -0.0682],\n",
       "                      ...,\n",
       "                      [ 0.0501,  0.0962,  0.1914,  ...,  0.0522, -0.0724,  0.0616],\n",
       "                      [-0.0073,  0.0936,  0.0527,  ...,  0.0011,  0.0636, -0.0299],\n",
       "                      [-0.0343,  0.0886, -0.0315,  ...,  0.0267,  0.0342,  0.1069]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.attn.proj_key.weight',\n",
       "              tensor([[ 0.0525,  0.0333,  0.0592,  ..., -0.0709,  0.0548,  0.0109],\n",
       "                      [-0.0391, -0.1709, -0.0720,  ...,  0.0794,  0.0093, -0.1058],\n",
       "                      [ 0.0072,  0.0280, -0.0210,  ...,  0.0072, -0.0271,  0.0094],\n",
       "                      ...,\n",
       "                      [-0.0134, -0.0998, -0.0560,  ...,  0.0527,  0.0107,  0.0098],\n",
       "                      [-0.1038, -0.0188, -0.0416,  ...,  0.1006,  0.0942, -0.0187],\n",
       "                      [ 0.0268, -0.1062, -0.0718,  ..., -0.0124, -0.1148, -0.0178]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.ff.fc1.weight',\n",
       "              tensor([[-0.1347,  0.0386, -0.0673,  ...,  0.0374, -0.0447, -0.1626],\n",
       "                      [-0.0626, -0.0726, -0.0417,  ..., -0.0070,  0.1411, -0.0698],\n",
       "                      [ 0.0663,  0.1285,  0.1177,  ...,  0.0004,  0.0259, -0.0655],\n",
       "                      ...,\n",
       "                      [ 0.0213, -0.1001, -0.1201,  ...,  0.0580,  0.0995,  0.1726],\n",
       "                      [ 0.0153, -0.0418, -0.0805,  ...,  0.0084,  0.0447,  0.1801],\n",
       "                      [ 0.0124, -0.0356,  0.0013,  ..., -0.0086, -0.0267, -0.1020]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.ff.fc1.bias',\n",
       "              tensor([-0.0364, -0.1544, -0.0016,  ..., -0.1945, -0.0173, -0.1064],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.ff.fc2.weight',\n",
       "              tensor([[-0.0410,  0.0084, -0.0336,  ...,  0.0048,  0.0354,  0.0083],\n",
       "                      [ 0.0392, -0.0009,  0.0233,  ...,  0.0302, -0.0277,  0.0021],\n",
       "                      [-0.0275, -0.0031,  0.0027,  ..., -0.0031, -0.0430, -0.0130],\n",
       "                      ...,\n",
       "                      [-0.0108, -0.0247, -0.0215,  ..., -0.0043,  0.0099, -0.0131],\n",
       "                      [ 0.0110, -0.0094, -0.0036,  ..., -0.0068, -0.0077, -0.0791],\n",
       "                      [-0.0279,  0.0076, -0.0120,  ...,  0.0390, -0.0251,  0.0480]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.ff.fc2.bias',\n",
       "              tensor([-0.0815, -0.0345,  0.0293, -0.0403, -0.0331, -0.1398, -0.0139,  0.0006,\n",
       "                      -0.0608, -0.0433,  0.1043,  0.0495,  0.0252, -0.1366,  0.0853,  0.1395,\n",
       "                       0.0188,  0.0142, -0.2098,  0.0435, -0.0461, -0.0502, -0.1682,  0.0605,\n",
       "                       0.0222, -0.1735,  0.0659, -0.0362, -0.0916,  0.0956, -0.0516,  0.0596,\n",
       "                       0.0902, -0.0744, -0.0431,  0.0783, -0.0764,  0.0895,  0.1114, -0.0540,\n",
       "                       0.0913,  0.1533,  0.0094, -0.0611,  0.0017,  0.0593,  0.0373,  0.0131,\n",
       "                       0.1028,  0.1529, -0.0826,  0.0558, -0.0037,  0.1691, -0.0780,  0.0643,\n",
       "                       0.0178,  0.0098,  0.0974, -0.1047,  0.0536, -0.0312, -0.1803, -0.0422,\n",
       "                       0.0544, -0.0873, -0.0425, -0.0134, -0.1393, -0.0862,  0.0376, -0.1607,\n",
       "                       0.0151, -0.0856,  0.1235,  0.0093, -0.0589, -0.1477,  0.0504,  0.0582,\n",
       "                      -0.0286,  0.0742,  0.0949,  0.0510,  0.0265, -0.0755,  0.0015, -0.0069,\n",
       "                      -0.0927,  0.0298, -0.0538, -0.0643,  0.0221,  0.1861, -0.0608,  0.1764,\n",
       "                      -0.0063,  0.0098, -0.2395,  0.0345,  0.1002, -0.0517,  0.0012,  0.1091,\n",
       "                       0.0142,  0.0141,  0.1641,  0.1300, -0.1396,  0.0494,  0.0512, -0.0419,\n",
       "                       0.1641,  0.0326, -0.0264, -0.0429,  0.0283, -0.0370, -0.0552,  0.1026,\n",
       "                      -0.0459, -0.0845, -0.0716,  0.1918,  0.0519, -0.1061, -0.0417,  0.0131,\n",
       "                       0.0661,  0.1388,  0.0671,  0.0048,  0.0939,  0.0327,  0.0928,  0.0464,\n",
       "                      -0.1095,  0.0542,  0.0690, -0.0158,  0.0045, -0.1261, -0.1540,  0.0176,\n",
       "                      -0.0367, -0.0155,  0.2139, -0.1021,  0.0244,  0.0386, -0.0353,  0.0067,\n",
       "                      -0.0848, -0.0423,  0.0087,  0.0238, -0.0348, -0.0060, -0.1366,  0.0185,\n",
       "                      -0.1511,  0.1371, -0.0845, -0.0744, -0.0022, -0.0056,  0.0394,  0.0517,\n",
       "                       0.0857, -0.0868, -0.0080,  0.1406, -0.1212, -0.0332,  0.0818,  0.0004,\n",
       "                      -0.0615,  0.0063,  0.0062,  0.0274, -0.1579,  0.0831, -0.0624, -0.0093,\n",
       "                       0.1750,  0.1151, -0.0542,  0.0790, -0.1233, -0.0593, -0.1125, -0.1344,\n",
       "                      -0.0405, -0.1593, -0.0011, -0.0129, -0.0821, -0.1823,  0.0494, -0.0559,\n",
       "                      -0.0473, -0.1010, -0.0006, -0.0885,  0.0173, -0.0079, -0.3101, -0.0084,\n",
       "                       0.0049, -0.0209, -0.1000,  0.0286,  0.0220, -0.0883,  0.1200,  0.0203,\n",
       "                       0.0374, -0.0720,  0.0577, -0.0541, -0.0424,  0.0064, -0.0244,  0.2093,\n",
       "                      -0.0263,  0.0177, -0.0409, -0.0328, -0.0561, -0.0164, -0.0484, -0.0121,\n",
       "                      -0.0252,  0.0336,  0.0539,  0.1350,  0.0700, -0.0673,  0.0216, -0.1191,\n",
       "                      -0.0520, -0.0822,  0.0920,  0.0965,  0.0293,  0.2385,  0.1217,  0.0539,\n",
       "                       0.0585, -0.0191,  0.1278,  0.0989,  0.0068,  0.0433, -0.1062,  0.1229],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.norm1.weight',\n",
       "              tensor([1.0406, 0.9758, 1.0684, 0.9874, 1.0292, 1.0571, 0.9576, 1.0231, 0.9889,\n",
       "                      1.1062, 1.0201, 1.0681, 1.0026, 1.0280, 0.9863, 1.0634, 0.9512, 0.9946,\n",
       "                      0.9864, 1.0084, 1.0561, 1.0835, 1.0517, 1.0119, 0.9841, 1.0485, 1.0464,\n",
       "                      1.0472, 0.9765, 1.1947, 1.0214, 0.9292, 0.9742, 1.0769, 1.0507, 1.0730,\n",
       "                      1.0349, 1.1430, 0.9504, 1.0497, 1.0533, 1.0359, 1.0155, 1.0372, 0.8651,\n",
       "                      1.0746, 1.0370, 0.9870, 1.1199, 1.0322, 0.9420, 1.0392, 1.0289, 0.9504,\n",
       "                      1.0891, 1.0233, 1.0555, 0.9784, 1.0715, 0.9603, 1.0222, 0.9888, 1.0331,\n",
       "                      1.0156, 1.0321, 0.9377, 1.0425, 0.9623, 0.9619, 0.8699, 1.0215, 0.9305,\n",
       "                      1.1197, 0.9867, 1.0251, 0.9209, 0.9773, 0.9576, 1.0113, 0.9844, 0.9940,\n",
       "                      1.0772, 0.9644, 1.0171, 1.0609, 1.0683, 1.1447, 1.0567, 1.0321, 1.0194,\n",
       "                      0.9979, 0.9526, 0.9878, 1.0009, 1.0172, 1.0158, 0.9938, 1.0603, 0.9343,\n",
       "                      0.9793, 1.0470, 1.0509, 1.0035, 0.9936, 0.9891, 0.9939, 1.0608, 1.0093,\n",
       "                      0.9458, 1.0171, 1.0042, 0.9346, 0.9814, 1.0546, 0.9895, 1.0522, 1.0486,\n",
       "                      1.0295, 0.9884, 0.9309, 0.9804, 1.1001, 1.0411, 0.9119, 0.9343, 1.1083,\n",
       "                      1.0492, 1.0132, 1.0168, 1.0063, 1.0827, 0.9118, 1.0151, 0.9956, 1.0624,\n",
       "                      1.0625, 1.0741, 1.0088, 1.0599, 0.9627, 1.0383, 1.0431, 0.9753, 0.9756,\n",
       "                      1.1128, 1.0041, 1.0261, 0.9776, 1.0568, 1.1271, 1.0298, 0.9796, 0.9811,\n",
       "                      1.0038, 0.9578, 1.0322, 1.0140, 1.0377, 1.0908, 1.0057, 0.9974, 1.0785,\n",
       "                      1.0517, 0.9965, 0.9931, 0.9866, 1.0905, 1.0594, 1.0649, 1.0838, 1.0224,\n",
       "                      1.1012, 1.0643, 1.0004, 1.0714, 0.9965, 0.9920, 0.9991, 1.0469, 1.0172,\n",
       "                      0.9901, 1.0468, 1.0405, 1.1063, 1.0182, 1.0478, 1.0827, 1.0210, 1.0459,\n",
       "                      1.0839, 0.9544, 1.0095, 0.9161, 0.9579, 0.9071, 0.9355, 0.9926, 0.9755,\n",
       "                      1.0217, 0.9567, 0.9620, 0.9824, 1.0080, 1.0662, 0.9755, 0.9891, 1.4537,\n",
       "                      1.0336, 0.9420, 1.0219, 0.9910, 1.0043, 1.0369, 1.0030, 1.0519, 0.9654,\n",
       "                      1.0549, 1.0441, 0.9975, 0.9991, 1.0311, 0.9958, 1.0608, 1.0370, 1.0277,\n",
       "                      0.9870, 0.9863, 1.0027, 0.9762, 1.0229, 1.0047, 1.0285, 1.0106, 1.0405,\n",
       "                      0.9985, 1.0611, 1.0289, 1.1247, 0.9684, 1.0844, 1.0253, 1.0873, 0.9672,\n",
       "                      0.9316, 1.0792, 1.0724, 1.0948, 1.0195, 1.0215, 1.0406, 1.0231, 1.0093,\n",
       "                      0.9689, 0.9454, 1.0157, 0.9878], device='cuda:0')),\n",
       "             ('module.layers.4.norm1.bias',\n",
       "              tensor([-0.0338, -0.1010,  0.0206, -0.0694, -0.0572, -0.1717,  0.0429, -0.0461,\n",
       "                      -0.1017,  0.0379,  0.0406,  0.0390,  0.0530, -0.0833, -0.0171,  0.0739,\n",
       "                       0.0215, -0.0253, -0.0753,  0.0618, -0.0295,  0.0180, -0.1000,  0.0416,\n",
       "                      -0.0121, -0.1002,  0.0320,  0.0878, -0.0321,  0.0239, -0.0222, -0.0244,\n",
       "                       0.0480, -0.0518,  0.0410, -0.0674, -0.1100,  0.0129,  0.1043, -0.0483,\n",
       "                       0.0259,  0.0598, -0.0030, -0.0969,  0.0303,  0.0063, -0.0318,  0.0176,\n",
       "                       0.0169, -0.0242, -0.0275,  0.1088, -0.0237,  0.0641,  0.1085,  0.0580,\n",
       "                       0.0136, -0.0079,  0.0297, -0.0360,  0.0664,  0.0267, -0.1342, -0.0603,\n",
       "                       0.0341, -0.0968, -0.0436,  0.0415, -0.1166, -0.0431, -0.0067,  0.0044,\n",
       "                      -0.0420, -0.0455, -0.0082,  0.0125, -0.0214, -0.0495,  0.0010,  0.0596,\n",
       "                       0.0471,  0.0188,  0.0515,  0.0003,  0.0905, -0.0948, -0.1095, -0.0292,\n",
       "                      -0.0364, -0.0253, -0.0395, -0.0273,  0.0102,  0.0878, -0.0044,  0.0657,\n",
       "                      -0.0269,  0.0100, -0.1000,  0.0039, -0.0240, -0.0892, -0.1183,  0.1165,\n",
       "                      -0.0658,  0.0115,  0.1018, -0.0405, -0.1539,  0.0087, -0.0236, -0.0840,\n",
       "                       0.0928,  0.0521, -0.0231,  0.0011,  0.0459, -0.1496, -0.1149,  0.0221,\n",
       "                       0.0195,  0.0813, -0.0588,  0.1736,  0.0742, -0.0223, -0.0816,  0.0386,\n",
       "                       0.1104,  0.0963,  0.0309, -0.0336,  0.0845, -0.0282,  0.1299, -0.0528,\n",
       "                      -0.0348, -0.0351,  0.1509,  0.0251,  0.0036, -0.0787, -0.1468,  0.0141,\n",
       "                       0.0075,  0.0267,  0.1832, -0.0544,  0.0093,  0.0105, -0.0654, -0.0611,\n",
       "                      -0.0812,  0.0797,  0.0474,  0.0405,  0.0147,  0.0047, -0.0832,  0.0448,\n",
       "                      -0.0147,  0.0697, -0.0170, -0.0434,  0.0021,  0.0049, -0.0287, -0.0051,\n",
       "                      -0.0117, -0.0104, -0.0919,  0.0642,  0.0040, -0.0237,  0.0703, -0.0060,\n",
       "                      -0.0131, -0.0337, -0.1395,  0.0406, -0.0863,  0.0458, -0.1896,  0.0384,\n",
       "                       0.0802,  0.1224, -0.0805,  0.1103, -0.0059, -0.0042, -0.0221, -0.0837,\n",
       "                       0.0021, -0.1340,  0.0022,  0.1163, -0.0955, -0.0550, -0.0378,  0.0302,\n",
       "                      -0.0415, -0.0705,  0.0059, -0.0032, -0.0402, -0.0253,  0.0530, -0.0615,\n",
       "                      -0.0312, -0.0309, -0.0743, -0.0845, -0.0157, -0.0984,  0.0833,  0.0216,\n",
       "                      -0.0566, -0.0777,  0.0612,  0.0333,  0.0370,  0.0195, -0.0017,  0.1765,\n",
       "                      -0.0051,  0.0109, -0.1122,  0.0570,  0.0542, -0.0096, -0.0238, -0.0193,\n",
       "                      -0.0226,  0.0116,  0.0747, -0.0398,  0.1239, -0.0324,  0.0269, -0.0894,\n",
       "                      -0.0272,  0.0178,  0.0874, -0.0449, -0.0149,  0.0930,  0.0281, -0.0458,\n",
       "                       0.1339,  0.0169,  0.0798,  0.0025,  0.0004, -0.0032, -0.0153,  0.0836],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.4.norm2.weight',\n",
       "              tensor([0.8200, 0.6369, 0.6395, 0.8046, 0.7757, 0.7319, 0.7693, 0.6886, 0.6781,\n",
       "                      0.7839, 0.7072, 0.7368, 0.7085, 0.6432, 0.7618, 0.6640, 1.0638, 0.7314,\n",
       "                      0.7799, 0.8471, 0.7110, 0.8147, 0.8402, 0.7611, 0.7523, 0.7559, 0.7264,\n",
       "                      0.7554, 0.7608, 0.5786, 0.6701, 0.6659, 0.8741, 0.8392, 0.6790, 0.7122,\n",
       "                      0.6718, 0.7129, 0.7441, 0.7611, 0.7180, 0.8621, 0.6752, 0.6406, 1.0630,\n",
       "                      0.7400, 0.7206, 0.6880, 0.6194, 0.5778, 0.8058, 0.7854, 0.7804, 0.8587,\n",
       "                      0.7650, 0.9050, 0.7789, 0.7144, 0.6562, 0.9609, 0.7519, 0.7591, 0.7972,\n",
       "                      0.7833, 0.6840, 0.8200, 0.6217, 0.8590, 0.7421, 0.8306, 0.7897, 0.7848,\n",
       "                      0.7613, 0.9846, 0.8147, 0.7704, 0.7668, 0.8880, 0.6656, 0.7818, 0.7006,\n",
       "                      0.6714, 0.6782, 0.7083, 0.6302, 0.6910, 0.6110, 0.7637, 0.7295, 0.7083,\n",
       "                      0.6743, 0.7776, 0.6704, 0.6733, 0.8053, 0.6983, 0.7535, 0.7228, 0.8550,\n",
       "                      0.7711, 0.7171, 0.7726, 0.7540, 0.7275, 0.7403, 0.8057, 0.6942, 0.7060,\n",
       "                      0.8102, 0.7050, 0.7272, 0.9463, 0.8764, 0.7862, 0.8530, 0.6585, 0.6785,\n",
       "                      0.7511, 0.8556, 0.7504, 0.8222, 0.6991, 0.7799, 0.8966, 0.6850, 0.6656,\n",
       "                      0.7773, 0.6531, 0.7327, 0.6500, 0.7195, 0.9074, 0.7008, 0.7997, 0.6057,\n",
       "                      0.6788, 0.7836, 0.6864, 0.6550, 0.9291, 0.6931, 0.6909, 0.8639, 0.6711,\n",
       "                      0.7101, 0.5961, 0.8172, 0.7543, 0.7099, 0.6706, 0.7802, 0.6439, 0.8402,\n",
       "                      0.7306, 0.8419, 0.7095, 0.8346, 0.7461, 0.7934, 0.7887, 0.7234, 0.6618,\n",
       "                      0.7736, 0.6297, 0.7342, 0.7088, 0.6913, 0.6858, 0.7492, 0.6509, 0.7168,\n",
       "                      0.7296, 0.7460, 0.7009, 0.6745, 0.7664, 0.8273, 0.7222, 0.6873, 0.6047,\n",
       "                      0.6501, 0.7055, 0.7092, 0.6452, 0.6643, 0.6610, 0.7158, 0.7151, 0.6932,\n",
       "                      0.6691, 0.6805, 0.7627, 0.7114, 0.7234, 0.8432, 0.7485, 0.7471, 0.8758,\n",
       "                      0.7466, 0.9297, 0.9513, 0.8539, 0.8843, 0.5852, 0.9922, 0.7215, 0.0787,\n",
       "                      0.6877, 0.8530, 0.7356, 0.6858, 0.7186, 0.7109, 0.7960, 0.6465, 0.6976,\n",
       "                      0.6979, 0.7438, 0.7293, 0.8613, 0.6966, 0.8248, 0.7453, 0.8607, 0.7219,\n",
       "                      0.7089, 0.7172, 0.6342, 0.9470, 0.7265, 0.7520, 0.6895, 0.8412, 0.8300,\n",
       "                      0.8557, 0.6132, 0.6404, 0.6459, 0.7143, 0.6924, 0.7110, 0.7086, 0.7433,\n",
       "                      0.6291, 0.6930, 0.5933, 0.6956, 0.7217, 0.7419, 0.7392, 0.8081, 0.6272,\n",
       "                      0.8327, 0.7705, 0.7400, 0.7530], device='cuda:0')),\n",
       "             ('module.layers.4.norm2.bias',\n",
       "              tensor([-2.2733e-01,  5.7146e-02,  1.3394e-01, -3.6654e-01, -1.1706e-01,\n",
       "                      -5.0054e-02, -1.1441e-01, -2.7861e-02, -5.6390e-02, -1.9533e-01,\n",
       "                      -8.9325e-03,  1.9028e-01,  1.8001e-01, -9.9395e-02, -9.0670e-02,\n",
       "                       8.5893e-02,  3.2762e-01,  1.4347e-01, -2.0865e-01,  3.0913e-01,\n",
       "                       1.6088e-01, -2.5989e-01, -1.6169e-01, -1.1315e-01, -2.1521e-01,\n",
       "                      -1.1347e-01, -1.4580e-01,  1.7169e-02, -3.4751e-02, -1.7831e-01,\n",
       "                      -1.5770e-01,  2.0898e-01,  2.2596e-01,  9.0699e-02, -1.1243e-01,\n",
       "                       2.9649e-02, -2.2381e-01, -9.8538e-02, -2.4951e-02,  3.5768e-01,\n",
       "                      -2.3076e-02,  2.2084e-01, -2.0709e-01, -1.9099e-02,  1.5847e-01,\n",
       "                      -6.5578e-02,  8.5835e-02, -8.8267e-02, -1.4742e-01,  1.6940e-01,\n",
       "                      -9.5639e-03,  1.6063e-02,  4.6089e-02,  1.2555e-01, -2.5014e-01,\n",
       "                      -4.0794e-01, -2.1113e-01, -2.2442e-02,  1.0525e-01,  1.4190e-01,\n",
       "                       1.1906e-01,  6.3942e-02,  7.2328e-02,  3.0509e-01, -9.4659e-03,\n",
       "                      -6.8421e-02, -4.5451e-01,  1.3181e-01, -1.8111e-01,  2.1337e-03,\n",
       "                       1.2706e-02, -1.3367e-01, -9.8050e-02, -2.6306e-02,  9.4569e-02,\n",
       "                       8.9248e-02, -1.8905e-01,  1.1819e-01,  1.0482e-02,  7.0590e-02,\n",
       "                      -8.1992e-02,  4.2668e-01, -1.1403e-01, -7.2749e-02, -2.5032e-01,\n",
       "                       1.2492e-01,  2.4047e-01,  6.8749e-04, -1.4437e-01, -5.5892e-02,\n",
       "                      -1.8478e-01,  1.3423e-01,  7.8479e-02,  1.5433e-02, -1.7743e-01,\n",
       "                       1.7050e-01,  1.3578e-01,  1.2825e-01,  3.3753e-02,  1.0572e-01,\n",
       "                       1.4276e-01, -1.3111e-01, -1.9864e-01, -2.7178e-02, -1.6955e-02,\n",
       "                       1.9175e-02, -2.8580e-02,  7.6191e-02, -2.3408e-02,  2.3513e-02,\n",
       "                      -8.8115e-02, -4.8202e-01,  1.7151e-01,  1.7261e-01,  1.0417e-01,\n",
       "                      -7.9177e-02,  1.2364e-01,  1.2925e-01, -2.7407e-01, -1.4707e-01,\n",
       "                       1.4289e-01, -1.6702e-01, -1.4121e-01, -1.1201e-01,  7.9016e-02,\n",
       "                      -7.8467e-02, -1.6759e-01, -2.0486e-01,  2.2667e-01,  1.4486e-02,\n",
       "                      -1.3879e-02,  2.6447e-01,  1.5785e-01, -1.7196e-01,  1.0599e-01,\n",
       "                      -1.5114e-01, -4.1372e-02,  2.9874e-02, -5.2641e-02,  1.7018e-01,\n",
       "                       1.1700e-01, -4.8675e-01, -3.3743e-02, -1.1087e-01, -2.4613e-01,\n",
       "                      -8.1317e-02, -3.6409e-02,  2.8347e-02,  1.8015e-02, -9.7324e-03,\n",
       "                      -2.5717e-02, -3.4831e-02, -8.1445e-02, -6.6705e-02,  1.3529e-01,\n",
       "                       3.3594e-02,  1.2650e-01,  1.3420e-02, -8.3014e-02, -5.5515e-02,\n",
       "                      -5.2743e-01, -2.2418e-01, -6.5161e-02, -1.4862e-01, -3.6706e-02,\n",
       "                      -1.2644e-01, -8.6691e-02, -9.3142e-02,  1.0502e-01,  1.3430e-02,\n",
       "                       2.1340e-02, -8.1884e-03, -4.6487e-02,  8.1115e-02, -4.1384e-02,\n",
       "                       1.0005e-01, -1.3234e-01,  1.0647e-01,  6.2406e-02,  8.7047e-02,\n",
       "                      -9.6464e-02,  4.0865e-02, -1.7023e-01,  1.0188e-01,  3.6104e-02,\n",
       "                       3.5928e-01,  2.8178e-03, -9.3623e-02, -8.9903e-02, -1.5153e-01,\n",
       "                      -5.4654e-02,  7.2265e-02, -1.0191e-01, -1.7656e-01,  2.4591e-01,\n",
       "                       3.5558e-02, -1.4551e-01, -4.3362e-01,  3.3658e-02,  2.8902e-02,\n",
       "                      -4.5001e-01, -3.2804e-02, -2.0619e-01, -2.8964e-01, -2.3113e-01,\n",
       "                      -7.3695e-02,  9.8101e-01, -1.7647e-01,  2.3655e-01, -9.9297e-02,\n",
       "                      -8.9740e-02,  1.9517e-02,  1.8340e-02,  5.3616e-02,  1.2431e-01,\n",
       "                      -1.2108e-02,  5.0419e-02,  6.7387e-02, -7.3821e-02, -2.0084e-01,\n",
       "                      -9.5084e-02,  2.3496e-01, -1.2987e-01,  8.0557e-03, -1.8767e-01,\n",
       "                      -3.5794e-02,  9.4028e-02, -2.8712e-01,  7.3501e-02, -1.1838e-01,\n",
       "                      -8.9364e-02,  9.7676e-03, -3.2325e-02, -8.7304e-02,  3.4622e-02,\n",
       "                      -2.1165e-01, -2.8387e-01, -1.7156e-01,  3.0555e-01, -2.2527e-01,\n",
       "                      -3.9326e-03, -4.9415e-03,  2.0315e-01,  3.3684e-02,  3.5962e-01,\n",
       "                      -1.2895e-01, -6.1479e-02,  1.1950e-01,  2.9615e-02,  8.3321e-02,\n",
       "                       7.4754e-02, -2.4064e-01,  7.7980e-02, -6.0737e-02, -8.5349e-02,\n",
       "                       7.3485e-03], device='cuda:0')),\n",
       "             ('module.layers.5.attn.attn.adaptive_span._mask.current_val',\n",
       "              tensor([[[0.4490]],\n",
       "              \n",
       "                      [[0.0137]],\n",
       "              \n",
       "                      [[0.0423]],\n",
       "              \n",
       "                      [[0.9667]]], device='cuda:0')),\n",
       "             ('module.layers.5.attn.attn.adaptive_span._mask.mask_template',\n",
       "              tensor([-1.0230e+03, -1.0220e+03, -1.0210e+03,  ..., -2.0000e+00,\n",
       "                      -1.0000e+00,  0.0000e+00], device='cuda:0')),\n",
       "             ('module.layers.5.attn.proj_query.weight',\n",
       "              tensor([[ 1.3114e-01, -2.3165e-02, -7.1532e-02,  ..., -7.1397e-02,\n",
       "                       -6.9124e-02,  6.1854e-02],\n",
       "                      [ 1.4291e-03,  3.3056e-02, -1.6125e-02,  ...,  9.6581e-03,\n",
       "                        3.9969e-02, -8.1175e-02],\n",
       "                      [-6.9688e-02,  7.0162e-02, -9.0782e-02,  ..., -1.3487e-01,\n",
       "                        2.1330e-01,  6.7554e-02],\n",
       "                      ...,\n",
       "                      [-9.0875e-02,  6.8368e-02, -1.1887e-04,  ..., -9.7255e-02,\n",
       "                       -3.6088e-03, -7.6136e-02],\n",
       "                      [ 9.6602e-02, -1.1333e-01, -5.9982e-02,  ..., -5.9723e-02,\n",
       "                       -7.1493e-03,  2.8310e-03],\n",
       "                      [-2.3561e-01,  4.8821e-03, -2.6904e-01,  ..., -4.3626e-03,\n",
       "                        1.4412e-01, -9.2829e-02]], device='cuda:0')),\n",
       "             ('module.layers.5.attn.proj_out.weight',\n",
       "              tensor([[-0.1101,  0.0111,  0.0060,  ...,  0.0346,  0.0952, -0.0171],\n",
       "                      [ 0.0037, -0.0714,  0.0090,  ...,  0.0841, -0.1168,  0.0381],\n",
       "                      [-0.0080, -0.0116, -0.0896,  ...,  0.0414, -0.0119,  0.0956],\n",
       "                      ...,\n",
       "                      [ 0.0367,  0.0268,  0.0028,  ..., -0.0307,  0.1234,  0.0019],\n",
       "                      [ 0.1059, -0.0041,  0.0185,  ...,  0.1399,  0.0193, -0.0283],\n",
       "                      [ 0.0547,  0.0127,  0.0567,  ..., -0.1223,  0.0372,  0.1526]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.5.attn.proj_val.weight',\n",
       "              tensor([[ 0.0760, -0.0290, -0.0145,  ..., -0.0840, -0.0973, -0.0864],\n",
       "                      [ 0.0481, -0.0639,  0.0513,  ..., -0.0379, -0.0229,  0.0589],\n",
       "                      [-0.0587,  0.0128,  0.0752,  ...,  0.0052, -0.0039, -0.0456],\n",
       "                      ...,\n",
       "                      [ 0.0381,  0.0764, -0.0468,  ...,  0.0586, -0.0134, -0.1120],\n",
       "                      [ 0.0409,  0.0691, -0.0189,  ..., -0.0658, -0.0034, -0.0097],\n",
       "                      [-0.0137,  0.0298,  0.0363,  ..., -0.0276, -0.0533,  0.0874]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.5.attn.proj_key.weight',\n",
       "              tensor([[ 0.0553, -0.1860,  0.0360,  ...,  0.0020, -0.0263,  0.0196],\n",
       "                      [ 0.0661,  0.0628,  0.0434,  ..., -0.0210,  0.1380, -0.3141],\n",
       "                      [ 0.0139,  0.2782, -0.1760,  ..., -0.1597,  0.3721,  0.2126],\n",
       "                      ...,\n",
       "                      [ 0.1791, -0.3019, -0.1516,  ..., -0.0299,  0.0870,  0.1856],\n",
       "                      [-0.0987,  0.1121,  0.1776,  ...,  0.0437,  0.0304,  0.1057],\n",
       "                      [ 0.0239, -0.5966, -0.1722,  ..., -0.2422,  0.0955,  0.1328]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.5.ff.fc1.weight',\n",
       "              tensor([[ 0.0898,  0.0742, -0.0703,  ...,  0.0043, -0.0422,  0.0397],\n",
       "                      [-0.0677, -0.0237,  0.0966,  ..., -0.0073, -0.0182,  0.0794],\n",
       "                      [ 0.0072,  0.1500,  0.2777,  ..., -0.1290, -0.0590,  0.0499],\n",
       "                      ...,\n",
       "                      [-0.0224,  0.0260, -0.1176,  ...,  0.1327,  0.0712, -0.1239],\n",
       "                      [-0.0423,  0.0759, -0.0902,  ..., -0.0077,  0.0981, -0.0689],\n",
       "                      [ 0.0840, -0.1207, -0.0015,  ...,  0.0252,  0.0342, -0.0214]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.5.ff.fc1.bias',\n",
       "              tensor([-0.0926, -0.1137, -0.1160,  ..., -0.1980, -0.0865, -0.1054],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.5.ff.fc2.weight',\n",
       "              tensor([[-0.0124,  0.0153, -0.0166,  ..., -0.0172, -0.0046, -0.0134],\n",
       "                      [-0.0169,  0.0087,  0.0347,  ..., -0.0158,  0.0174, -0.0097],\n",
       "                      [-0.0053,  0.0084, -0.0104,  ..., -0.0304,  0.0348,  0.0092],\n",
       "                      ...,\n",
       "                      [ 0.0175,  0.0313, -0.0120,  ..., -0.0138,  0.0070, -0.0313],\n",
       "                      [ 0.0263,  0.0009, -0.0357,  ...,  0.0232, -0.0419,  0.0025],\n",
       "                      [-0.0099, -0.0259, -0.0250,  ...,  0.0364, -0.0321, -0.0252]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.5.ff.fc2.bias',\n",
       "              tensor([ 0.0289, -0.0057,  0.1777, -0.0818,  0.0503, -0.0174,  0.0063,  0.0622,\n",
       "                      -0.0014,  0.1012, -0.0500, -0.0233, -0.0676, -0.0761, -0.0349, -0.0505,\n",
       "                      -0.0974,  0.0745,  0.0315,  0.0852,  0.0668,  0.0317, -0.0463, -0.1408,\n",
       "                       0.0279, -0.0169, -0.0491, -0.0119, -0.0175, -0.0610,  0.0811, -0.1228,\n",
       "                       0.1089, -0.0059, -0.2208,  0.0027, -0.0414, -0.0173,  0.0870,  0.0358,\n",
       "                       0.1937,  0.1569, -0.2761,  0.0592,  0.0856,  0.0187, -0.0461,  0.0396,\n",
       "                       0.2022,  0.0911,  0.1086, -0.0058,  0.1345, -0.1019,  0.1783,  0.0145,\n",
       "                      -0.1145, -0.0869,  0.0366, -0.1227,  0.0558,  0.0235,  0.2199, -0.1757,\n",
       "                       0.0464, -0.0051,  0.0316, -0.0215, -0.0674,  0.0326, -0.0330, -0.0966,\n",
       "                      -0.0373, -0.0110, -0.1367, -0.0448,  0.1217, -0.0402, -0.0216, -0.0421,\n",
       "                      -0.1430, -0.1214, -0.0883,  0.0848,  0.0495,  0.1202,  0.0141,  0.0425,\n",
       "                      -0.1321, -0.1605, -0.0202,  0.2714, -0.1885,  0.1289,  0.1118, -0.0854,\n",
       "                      -0.0193, -0.1084,  0.1482, -0.0315,  0.1367,  0.0152, -0.0643, -0.0011,\n",
       "                       0.1579, -0.1213, -0.0091,  0.0528,  0.0484, -0.0710,  0.0881, -0.0386,\n",
       "                      -0.1029,  0.0254, -0.0468, -0.0698, -0.0028, -0.0557, -0.0677, -0.0444,\n",
       "                      -0.0177,  0.0204, -0.0963,  0.0242,  0.0347,  0.0945,  0.0916, -0.0589,\n",
       "                      -0.0706,  0.0072,  0.0573, -0.1015,  0.0713,  0.1612, -0.0239, -0.0434,\n",
       "                      -0.0120, -0.1195, -0.1483, -0.0159,  0.0860,  0.1306,  0.1389, -0.0465,\n",
       "                       0.0211, -0.0277, -0.1494, -0.1962,  0.0662, -0.0597,  0.1656,  0.0636,\n",
       "                      -0.0062, -0.0189,  0.0693, -0.0264, -0.0461,  0.0336,  0.0777,  0.0635,\n",
       "                       0.1476, -0.1301,  0.0113, -0.0254,  0.0499, -0.0159,  0.0797,  0.0404,\n",
       "                      -0.0628,  0.0091,  0.1569,  0.0100,  0.0457,  0.0215, -0.0736, -0.0302,\n",
       "                       0.2016, -0.0218, -0.0103, -0.1296, -0.0776,  0.1129,  0.0106, -0.0523,\n",
       "                      -0.0335,  0.0314,  0.0662, -0.0310, -0.0058,  0.0218, -0.0019, -0.0215,\n",
       "                       0.0838,  0.2150, -0.0033, -0.1168, -0.0855, -0.1752,  0.1560,  0.1136,\n",
       "                      -0.0936, -0.0382,  0.0071, -0.1345, -0.0235,  0.0435,  0.0128, -0.1937,\n",
       "                       0.0538, -0.0632,  0.0954,  0.0903,  0.0150,  0.1019, -0.0400, -0.1062,\n",
       "                       0.0532,  0.0468, -0.0313, -0.0325, -0.0669, -0.0335, -0.0257, -0.0066,\n",
       "                       0.0573, -0.0306,  0.0126,  0.0224,  0.0357,  0.0207,  0.0530,  0.1111,\n",
       "                       0.1041, -0.0018, -0.1167,  0.0723,  0.0558, -0.0175,  0.0479,  0.0425,\n",
       "                       0.0212, -0.0519,  0.0513, -0.0008, -0.0389, -0.0125, -0.0473, -0.0803,\n",
       "                      -0.0152, -0.1018,  0.0014, -0.0741, -0.0572, -0.0032, -0.2048, -0.0580],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.5.norm1.weight',\n",
       "              tensor([0.9396, 1.1322, 1.0910, 0.9004, 1.0730, 0.9712, 1.0699, 1.0004, 1.0319,\n",
       "                      1.0314, 0.9431, 1.1603, 1.1375, 1.2082, 1.0477, 0.9848, 0.8348, 0.9989,\n",
       "                      0.9899, 0.8874, 1.0261, 0.9202, 0.9094, 1.0532, 0.9205, 0.9898, 1.0683,\n",
       "                      1.0769, 1.0229, 1.1368, 1.0734, 1.1328, 0.9779, 0.9731, 1.1816, 1.1335,\n",
       "                      1.0536, 0.9866, 0.8856, 0.9862, 1.0143, 0.8940, 1.1291, 1.1075, 0.8723,\n",
       "                      1.0091, 1.0236, 1.0737, 1.0757, 1.1040, 1.0863, 0.9796, 1.0116, 0.9027,\n",
       "                      0.8772, 1.0201, 0.9418, 0.9882, 1.0418, 0.8691, 1.0239, 0.9004, 0.7788,\n",
       "                      0.9444, 1.0440, 0.8847, 1.0420, 0.8956, 0.9689, 0.9080, 0.9517, 0.8981,\n",
       "                      0.9586, 0.9233, 0.8907, 1.0372, 0.9702, 0.8735, 1.1315, 0.9417, 1.0849,\n",
       "                      0.9930, 0.8635, 1.0734, 1.0806, 0.9824, 1.0985, 0.9931, 1.0858, 1.1324,\n",
       "                      1.0415, 1.0022, 0.9712, 1.0122, 0.9921, 1.0527, 1.0581, 1.0701, 0.9272,\n",
       "                      1.0166, 1.0071, 0.9353, 0.9595, 0.9153, 0.9743, 0.9556, 1.0182, 1.0546,\n",
       "                      0.9606, 1.1262, 1.0538, 0.8634, 0.8689, 1.0300, 0.9118, 1.0272, 1.0082,\n",
       "                      1.1282, 1.0251, 0.9560, 0.9176, 1.1502, 0.9424, 0.8840, 1.1623, 1.1521,\n",
       "                      1.0724, 1.0958, 1.0885, 0.9957, 1.1487, 0.9194, 1.0618, 0.9434, 1.1410,\n",
       "                      0.9897, 0.9744, 1.0299, 1.0016, 0.8744, 1.1567, 0.9147, 0.9050, 1.0779,\n",
       "                      0.9867, 1.1533, 0.9768, 0.9957, 1.0875, 1.1135, 0.9245, 0.9176, 0.9108,\n",
       "                      1.0231, 0.8603, 0.9696, 0.8530, 0.9493, 1.0144, 1.0302, 0.9655, 0.9352,\n",
       "                      0.9882, 1.0034, 1.0164, 0.9948, 1.1113, 1.0415, 0.9300, 1.1169, 1.0688,\n",
       "                      0.9412, 1.1607, 0.9937, 1.1223, 1.0759, 0.9502, 1.0342, 1.0676, 1.0983,\n",
       "                      1.0049, 1.0975, 0.9628, 1.1616, 1.1661, 1.0897, 1.1055, 1.0582, 0.9738,\n",
       "                      1.0829, 1.0821, 0.9477, 1.0176, 0.9422, 0.9504, 1.0182, 0.9794, 0.8793,\n",
       "                      0.9922, 0.9120, 0.8505, 0.9280, 0.8729, 1.0946, 0.8262, 1.0437, 1.2746,\n",
       "                      1.0225, 0.9690, 1.0277, 1.0993, 1.0705, 1.0950, 0.9401, 1.1939, 0.9095,\n",
       "                      1.0012, 1.0383, 0.9588, 0.9514, 1.2163, 0.9529, 1.0458, 0.8217, 1.0625,\n",
       "                      1.0612, 1.0256, 1.0511, 0.8370, 1.0483, 0.9852, 1.1417, 0.9720, 0.9229,\n",
       "                      0.9166, 1.0962, 1.0709, 1.1451, 1.0577, 1.0302, 1.0665, 1.0817, 0.9424,\n",
       "                      1.1981, 1.1083, 1.0607, 1.1023, 1.0189, 0.9078, 0.9935, 0.9665, 1.0184,\n",
       "                      0.9433, 1.0771, 0.9800, 0.9253], device='cuda:0')),\n",
       "             ('module.layers.5.norm1.bias',\n",
       "              tensor([ 0.1142, -0.0733,  0.0275, -0.1097,  0.0268,  0.1068,  0.1422,  0.0220,\n",
       "                      -0.0751,  0.2101, -0.0941,  0.0208,  0.0954,  0.0044, -0.0239, -0.0589,\n",
       "                      -0.0642,  0.0647,  0.1931,  0.0092,  0.1363, -0.0497,  0.1117, -0.1945,\n",
       "                       0.0698,  0.0276, -0.1733, -0.0280, -0.0059, -0.0712,  0.1426, -0.0401,\n",
       "                       0.0047,  0.0864, -0.1771, -0.0159, -0.0026, -0.1289, -0.1648,  0.1394,\n",
       "                       0.0341, -0.0891, -0.1879,  0.0208,  0.1174, -0.1095, -0.0343,  0.1251,\n",
       "                       0.1117, -0.0458,  0.0273, -0.0852,  0.0488, -0.0695,  0.2850, -0.0742,\n",
       "                       0.0124, -0.1325,  0.0308, -0.1199, -0.0168,  0.0648,  0.4062, -0.1467,\n",
       "                       0.1560,  0.0705,  0.0890, -0.0565, -0.0043, -0.0224,  0.1404,  0.0847,\n",
       "                      -0.1209, -0.0296, -0.2411, -0.0208,  0.0769,  0.1805, -0.0468,  0.0022,\n",
       "                      -0.0744, -0.1014, -0.2170, -0.0810, -0.0299,  0.1597,  0.0806, -0.0846,\n",
       "                       0.0031, -0.1080, -0.0549,  0.2528, -0.1062,  0.0144,  0.1346,  0.0400,\n",
       "                      -0.0599, -0.0866,  0.2158, -0.0274, -0.0317, -0.1415, -0.0448,  0.0080,\n",
       "                       0.0742, -0.1099, -0.0383,  0.0025, -0.1143, -0.0627,  0.0188, -0.0722,\n",
       "                      -0.0733, -0.0210,  0.0121, -0.1737, -0.0611, -0.0659, -0.0646, -0.1102,\n",
       "                       0.0692, -0.0023, -0.1383, -0.0222,  0.1182,  0.0071,  0.1186,  0.0080,\n",
       "                      -0.0161, -0.0017,  0.0190, -0.1372,  0.0285,  0.1156,  0.0505, -0.0232,\n",
       "                       0.0630, -0.1715, -0.0886,  0.1262,  0.0594,  0.0355,  0.1167, -0.1144,\n",
       "                      -0.0304,  0.0691, -0.2017, -0.0926,  0.0722, -0.0045, -0.0113, -0.1029,\n",
       "                       0.0227, -0.0581, -0.0113,  0.0480, -0.0418,  0.0112,  0.0834,  0.0884,\n",
       "                       0.1339, -0.1216,  0.0713, -0.0595,  0.0361,  0.0171,  0.1448, -0.0906,\n",
       "                      -0.0610, -0.0176,  0.1701, -0.0232,  0.1105, -0.0183, -0.0015,  0.0409,\n",
       "                       0.1885,  0.0664, -0.0245,  0.1314, -0.0677,  0.1689, -0.1025, -0.0895,\n",
       "                      -0.1587, -0.0525, -0.0315, -0.0657,  0.1359,  0.0644,  0.0680,  0.0514,\n",
       "                       0.1561,  0.0926,  0.0589,  0.0279, -0.0767,  0.0815,  0.1375,  0.1581,\n",
       "                       0.0686,  0.0739,  0.0106, -0.0776, -0.1529,  0.1133,  0.3088, -0.1178,\n",
       "                       0.1490, -0.1036,  0.1531,  0.0468,  0.0771,  0.0803, -0.0774, -0.1069,\n",
       "                      -0.0310,  0.0209, -0.1370,  0.0640, -0.0079,  0.0663,  0.0262, -0.0881,\n",
       "                      -0.1358, -0.0669, -0.1949,  0.1203, -0.0376, -0.0589,  0.0092,  0.1587,\n",
       "                      -0.0600, -0.0073, -0.1665, -0.0184, -0.0482, -0.0547,  0.0101, -0.0843,\n",
       "                       0.0821, -0.0257,  0.0101, -0.0500,  0.0423, -0.1442, -0.1027, -0.0225,\n",
       "                      -0.0222, -0.0193, -0.0284, -0.0496, -0.1054,  0.0428, -0.0445, -0.0098],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.5.norm2.weight',\n",
       "              tensor([1.2257, 1.1694, 1.1000, 1.2900, 1.2370, 1.1657, 1.0942, 1.2243, 1.1715,\n",
       "                      1.2575, 1.1658, 1.0974, 1.1258, 1.2318, 1.2262, 1.1381, 1.2533, 1.2292,\n",
       "                      1.1461, 1.2740, 1.2191, 1.1147, 1.1606, 1.1965, 1.1907, 1.0841, 1.0880,\n",
       "                      1.0670, 1.2296, 1.3489, 1.3241, 1.1725, 1.2553, 1.2203, 1.2919, 1.1651,\n",
       "                      1.2309, 0.9802, 1.2663, 1.3852, 1.2408, 1.0680, 1.1067, 1.2843, 1.1669,\n",
       "                      1.1887, 1.1010, 1.2587, 1.2855, 1.2438, 1.1853, 1.1473, 1.2932, 1.1544,\n",
       "                      1.1129, 1.1720, 1.2383, 1.4700, 1.1519, 1.1875, 1.0993, 1.1810, 1.3134,\n",
       "                      1.2344, 1.0948, 1.0960, 1.0665, 1.0834, 1.1907, 1.1160, 1.1979, 1.1290,\n",
       "                      1.1974, 1.1505, 1.3735, 1.0798, 1.1295, 1.1009, 1.2312, 1.2609, 1.2800,\n",
       "                      1.1314, 1.0747, 1.1550, 1.1680, 1.2499, 1.1561, 1.0940, 1.3365, 1.2017,\n",
       "                      1.0724, 1.1298, 1.2073, 1.3330, 1.1307, 1.1696, 1.3148, 1.1147, 1.1643,\n",
       "                      1.0204, 1.1648, 1.2611, 1.0828, 1.0937, 1.2586, 1.1809, 1.1414, 1.0234,\n",
       "                      1.1928, 1.1821, 1.2237, 1.1351, 1.0511, 1.1810, 1.0570, 1.2431, 1.1093,\n",
       "                      1.0924, 1.0315, 1.2374, 1.1676, 0.9973, 1.3026, 1.1898, 0.9775, 1.1208,\n",
       "                      1.1538, 1.4478, 1.0979, 1.1034, 1.0699, 1.1445, 1.2022, 1.2867, 1.0093,\n",
       "                      1.1429, 1.1512, 1.2120, 1.1434, 1.1235, 1.2416, 1.1499, 1.2380, 1.1137,\n",
       "                      1.2845, 1.2063, 1.2081, 1.1452, 1.1352, 1.2408, 1.2063, 1.0159, 1.1425,\n",
       "                      1.2154, 1.1607, 1.2381, 1.0794, 1.1026, 1.0638, 1.1866, 1.1993, 1.2774,\n",
       "                      1.2179, 1.1544, 1.1156, 1.0183, 1.2499, 1.0508, 1.2236, 1.1546, 1.1546,\n",
       "                      1.0526, 1.1778, 1.1869, 1.1176, 1.1528, 1.1064, 1.1451, 1.2588, 1.2116,\n",
       "                      1.1272, 1.3113, 1.1885, 1.1527, 0.9896, 1.2646, 1.1245, 1.2173, 1.1485,\n",
       "                      1.1864, 1.1117, 1.1840, 1.0592, 1.3883, 1.0943, 1.0899, 1.1376, 1.1800,\n",
       "                      1.1081, 1.2645, 1.2288, 1.0858, 1.1690, 1.1477, 1.0231, 1.2058, 1.0922,\n",
       "                      1.2011, 1.2886, 1.1645, 1.1101, 1.1408, 1.1563, 1.0967, 1.2366, 1.1036,\n",
       "                      1.0986, 1.1884, 1.2260, 1.1625, 1.2717, 1.1623, 1.3606, 1.0414, 1.1698,\n",
       "                      1.3825, 1.0201, 1.1555, 1.0175, 0.9932, 1.1893, 1.1925, 1.0322, 1.2946,\n",
       "                      1.1526, 1.0263, 1.1787, 1.1431, 1.0259, 1.2248, 1.2602, 1.2049, 1.1498,\n",
       "                      1.2508, 0.8671, 1.2528, 1.1442, 1.0626, 1.1964, 1.2106, 1.2017, 1.2200,\n",
       "                      1.2221, 1.1262, 1.1496, 1.0304], device='cuda:0')),\n",
       "             ('module.layers.5.norm2.bias',\n",
       "              tensor([-0.0423,  0.0715,  0.1602, -0.1917, -0.0543,  0.0205, -0.0514, -0.1219,\n",
       "                       0.0081, -0.1421, -0.1271,  0.0909,  0.0005, -0.0722, -0.0445, -0.0826,\n",
       "                      -0.1392,  0.0382, -0.0058,  0.1384, -0.1009,  0.0864, -0.1901, -0.1237,\n",
       "                       0.1503,  0.0355, -0.1328, -0.1248,  0.0069, -0.1169, -0.1978,  0.0160,\n",
       "                       0.1679, -0.0718, -0.2816,  0.0038, -0.1480, -0.1753,  0.0439,  0.2165,\n",
       "                       0.2063,  0.2212, -0.2653,  0.0838,  0.0607, -0.0118,  0.1028,  0.0231,\n",
       "                       0.2649, -0.0414,  0.1453, -0.1171,  0.3121, -0.1966,  0.1034,  0.0055,\n",
       "                      -0.2171,  0.1303,  0.1502, -0.0178,  0.1665,  0.1273,  0.2653, -0.1211,\n",
       "                      -0.1597,  0.0577,  0.0399,  0.0316, -0.2172,  0.1067,  0.0521, -0.2161,\n",
       "                       0.1724, -0.1165,  0.2600, -0.0418, -0.0369,  0.0218, -0.1064, -0.1256,\n",
       "                      -0.3241,  0.0239,  0.0587, -0.0405, -0.0025,  0.0916,  0.1172,  0.1266,\n",
       "                      -0.1262, -0.1565, -0.0764,  0.1484, -0.2376,  0.2002,  0.0713, -0.1840,\n",
       "                       0.2120, -0.0273,  0.1774,  0.0196,  0.0477,  0.0500, -0.0667, -0.1374,\n",
       "                       0.3006, -0.0498, -0.1303, -0.0729,  0.1034,  0.0691,  0.1674, -0.1283,\n",
       "                      -0.1136, -0.0329, -0.1634,  0.0630,  0.1490,  0.0690, -0.0980, -0.0541,\n",
       "                      -0.0920, -0.0313,  0.1866,  0.0817,  0.0495,  0.0147, -0.0064, -0.1677,\n",
       "                      -0.1748, -0.0911,  0.0831, -0.1991,  0.1674,  0.1845, -0.1630, -0.0998,\n",
       "                      -0.0665, -0.0791, -0.3499, -0.1903,  0.1327, -0.0122, -0.0273, -0.0728,\n",
       "                       0.1776, -0.1084, -0.2562, -0.1460,  0.0315, -0.1067,  0.2344,  0.2320,\n",
       "                      -0.0784, -0.0082,  0.1362, -0.0929, -0.1375, -0.0618,  0.0984, -0.1518,\n",
       "                       0.1150, -0.2698,  0.0161,  0.0750, -0.2565, -0.0620,  0.0289, -0.1170,\n",
       "                       0.0191,  0.0579,  0.0823, -0.0795, -0.0257,  0.1222, -0.0522, -0.0380,\n",
       "                       0.0301,  0.0827,  0.0436, -0.1294, -0.2132, -0.1275, -0.0259, -0.0276,\n",
       "                      -0.2133,  0.2183,  0.0868, -0.1197, -0.0702, -0.0578, -0.0907, -0.0616,\n",
       "                       0.2307,  0.3283, -0.1008, -0.2693, -0.0338, -0.1301,  0.3069,  0.1004,\n",
       "                      -0.3193, -0.0348, -0.0591, -0.1132, -0.0576, -0.0792,  0.0888, -0.2567,\n",
       "                       0.0233, -0.1068,  0.0761,  0.1822, -0.1242,  0.3687,  0.0058, -0.0358,\n",
       "                       0.0924, -0.0724,  0.0153, -0.1256, -0.1676, -0.0571, -0.0455,  0.1000,\n",
       "                      -0.0156, -0.1463,  0.0691,  0.0885, -0.0559, -0.0329, -0.0318,  0.2648,\n",
       "                       0.0890, -0.0591, -0.2469, -0.0091, -0.1631,  0.0278,  0.0149, -0.0301,\n",
       "                       0.1960, -0.0701,  0.0277, -0.0072, -0.0683,  0.1809, -0.1490,  0.0052,\n",
       "                      -0.2006,  0.0089, -0.1806, -0.1748, -0.0489, -0.0834, -0.2042, -0.0796],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.6.attn.attn.adaptive_span._mask.current_val',\n",
       "              tensor([[[0.0027]],\n",
       "              \n",
       "                      [[0.3478]],\n",
       "              \n",
       "                      [[0.1712]],\n",
       "              \n",
       "                      [[0.4327]]], device='cuda:0')),\n",
       "             ('module.layers.6.attn.attn.adaptive_span._mask.mask_template',\n",
       "              tensor([-1.0230e+03, -1.0220e+03, -1.0210e+03,  ..., -2.0000e+00,\n",
       "                      -1.0000e+00,  0.0000e+00], device='cuda:0')),\n",
       "             ('module.layers.6.attn.proj_query.weight',\n",
       "              tensor([[-0.0448,  0.0897, -0.0452,  ...,  0.0349, -0.0191, -0.0433],\n",
       "                      [-0.0037,  0.0076, -0.0109,  ...,  0.0294, -0.0210,  0.0235],\n",
       "                      [ 0.0328, -0.0174,  0.1273,  ...,  0.0014, -0.0632, -0.0460],\n",
       "                      ...,\n",
       "                      [-0.0927,  0.1337,  0.0412,  ..., -0.0714,  0.0036, -0.0702],\n",
       "                      [-0.0585, -0.1195, -0.0537,  ..., -0.0136,  0.0159,  0.0100],\n",
       "                      [ 0.0517,  0.0053,  0.0549,  ...,  0.0410, -0.1008, -0.1222]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.6.attn.proj_out.weight',\n",
       "              tensor([[-0.0938,  0.0976, -0.1737,  ...,  0.0385,  0.0171,  0.0460],\n",
       "                      [-0.0298, -0.0682, -0.0274,  ..., -0.0078,  0.0070,  0.0962],\n",
       "                      [-0.0266, -0.0196,  0.0427,  ...,  0.0722, -0.0063, -0.1630],\n",
       "                      ...,\n",
       "                      [ 0.0778,  0.0608,  0.1060,  ...,  0.1114,  0.0669, -0.2023],\n",
       "                      [ 0.0317, -0.0330,  0.0198,  ..., -0.0106,  0.0557,  0.0255],\n",
       "                      [ 0.1012,  0.0080, -0.0331,  ..., -0.1888, -0.0572, -0.1119]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.6.attn.proj_val.weight',\n",
       "              tensor([[-0.0219, -0.0717,  0.0541,  ..., -0.0131, -0.0666,  0.0451],\n",
       "                      [ 0.0345, -0.0557,  0.0930,  ...,  0.0041, -0.0110,  0.0258],\n",
       "                      [ 0.0158, -0.0810,  0.0930,  ...,  0.0904, -0.0559,  0.0335],\n",
       "                      ...,\n",
       "                      [ 0.0085, -0.0305, -0.0088,  ...,  0.0921,  0.0541, -0.0768],\n",
       "                      [ 0.0102,  0.0571, -0.0219,  ..., -0.0727, -0.0046, -0.0113],\n",
       "                      [ 0.0765, -0.0397,  0.0853,  ..., -0.0698,  0.1391,  0.0637]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.6.attn.proj_key.weight',\n",
       "              tensor([[-0.0717,  0.0285, -0.0333,  ..., -0.0097,  0.0296, -0.0222],\n",
       "                      [-0.0225,  0.0895,  0.0018,  ...,  0.0572, -0.0848,  0.0150],\n",
       "                      [ 0.0044, -0.0639, -0.0247,  ..., -0.0008,  0.0168,  0.0396],\n",
       "                      ...,\n",
       "                      [ 0.0337,  0.0507, -0.0136,  ..., -0.1984, -0.0847,  0.1541],\n",
       "                      [ 0.2476, -0.1891, -0.0364,  ..., -0.2320,  0.0366, -0.3224],\n",
       "                      [ 0.0875,  0.1170,  0.1361,  ...,  0.0905, -0.1830, -0.3865]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.6.ff.fc1.weight',\n",
       "              tensor([[ 0.0619, -0.0428,  0.0126,  ...,  0.0187, -0.0780,  0.0499],\n",
       "                      [ 0.1106,  0.0832,  0.1274,  ..., -0.1241, -0.0526, -0.0334],\n",
       "                      [ 0.1711, -0.0122, -0.0094,  ..., -0.0223, -0.1510, -0.0213],\n",
       "                      ...,\n",
       "                      [-0.0494,  0.0019, -0.0279,  ..., -0.0619,  0.0239,  0.0417],\n",
       "                      [ 0.1017, -0.0160,  0.0551,  ..., -0.1045,  0.1050, -0.1405],\n",
       "                      [ 0.0167,  0.1657,  0.0884,  ..., -0.0868, -0.0478, -0.0763]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.6.ff.fc1.bias',\n",
       "              tensor([-0.1927, -0.1923, -0.1513,  ..., -0.1745, -0.1630, -0.1125],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.6.ff.fc2.weight',\n",
       "              tensor([[ 0.0036,  0.0290,  0.0471,  ...,  0.0096,  0.0042, -0.0210],\n",
       "                      [-0.0136,  0.0489, -0.0254,  ..., -0.0045,  0.0034,  0.0503],\n",
       "                      [ 0.0671,  0.0066, -0.0414,  ...,  0.0075, -0.0365, -0.0113],\n",
       "                      ...,\n",
       "                      [-0.0146, -0.0285,  0.0501,  ...,  0.0398, -0.0013, -0.0220],\n",
       "                      [ 0.0216,  0.0380,  0.0059,  ...,  0.0311,  0.0014,  0.0072],\n",
       "                      [-0.0154, -0.0191, -0.0020,  ..., -0.0394, -0.0349, -0.0104]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.6.ff.fc2.bias',\n",
       "              tensor([-3.4640e-02, -7.6900e-02,  6.0845e-02, -1.6798e-02, -1.3657e-01,\n",
       "                      -7.1361e-02, -8.9194e-02, -1.2530e-02,  8.7730e-02,  1.5178e-01,\n",
       "                      -1.6213e-01, -7.2698e-02, -3.0170e-01,  6.7811e-02,  3.3272e-02,\n",
       "                       9.2858e-02,  2.6082e-02, -5.5468e-02,  1.9495e-02,  1.1086e-02,\n",
       "                       1.6694e-01,  7.1246e-02,  1.4433e-01, -8.9965e-02,  9.6105e-03,\n",
       "                      -9.2778e-02,  5.6947e-02, -5.4597e-02, -3.2475e-02, -5.6797e-02,\n",
       "                       1.8702e-01, -6.8821e-02, -1.4357e-01,  5.2317e-02, -7.3265e-02,\n",
       "                       1.3058e-01,  5.1257e-04, -5.1374e-02,  4.4602e-02,  8.6606e-02,\n",
       "                       3.2550e-02,  1.4548e-02,  1.4382e-03, -5.3725e-02,  1.0505e-01,\n",
       "                       2.1168e-02,  9.4197e-02,  4.9887e-02,  1.0520e-01, -8.9783e-02,\n",
       "                      -1.3560e-02,  1.9464e-04, -4.8538e-03,  5.8990e-02,  4.5573e-02,\n",
       "                      -6.2728e-03,  4.7973e-02, -9.7941e-02, -2.5958e-02, -2.4702e-02,\n",
       "                      -9.1302e-02,  4.0519e-02,  1.4512e-01, -2.8849e-02,  1.1705e-01,\n",
       "                       4.2270e-02,  7.1216e-02, -9.3054e-02, -5.2068e-02, -3.5896e-02,\n",
       "                       9.8461e-02, -9.3421e-02, -1.1197e-01, -2.4863e-02, -2.8580e-02,\n",
       "                       1.0098e-01, -1.2820e-01,  2.9209e-02,  4.4757e-02,  2.5417e-02,\n",
       "                      -1.0302e-01, -4.2790e-02, -7.4048e-02,  1.2503e-01, -1.1685e-01,\n",
       "                      -3.5124e-02, -3.0702e-02, -6.0308e-02, -4.5021e-02,  2.5210e-02,\n",
       "                      -8.6171e-03, -4.5724e-02, -2.6496e-02, -4.7280e-02, -1.1948e-01,\n",
       "                       9.0239e-02, -3.1265e-02, -1.1624e-01,  8.4106e-02, -4.9492e-02,\n",
       "                       4.7056e-02, -1.3133e-01,  1.1327e-01, -1.0606e-02,  5.3876e-02,\n",
       "                      -1.4260e-01, -6.3166e-03,  1.5237e-01, -1.7094e-02, -8.5990e-02,\n",
       "                      -5.3451e-02, -4.3622e-02,  1.0452e-01, -5.2930e-02,  1.9076e-02,\n",
       "                      -1.7765e-01, -2.0681e-02,  8.3603e-02,  3.9001e-02, -4.9005e-02,\n",
       "                       1.2444e-01, -4.4524e-02, -1.2298e-01,  1.8534e-02, -4.4140e-02,\n",
       "                       7.8300e-02, -6.3392e-02, -2.2368e-01, -2.9802e-02,  2.3077e-02,\n",
       "                       5.2182e-02,  3.3128e-02,  9.0051e-02,  8.9589e-02,  1.3235e-01,\n",
       "                       2.6759e-02, -1.8308e-03, -9.5194e-02,  9.5782e-02,  1.1821e-01,\n",
       "                      -6.2650e-02,  1.2488e-03,  2.6804e-02, -7.0431e-03, -4.1603e-02,\n",
       "                       1.5257e-01, -2.4608e-02,  1.6703e-03,  6.7339e-02,  4.8207e-02,\n",
       "                      -1.1394e-01, -1.3645e-01, -7.7647e-02, -4.6246e-02,  2.7877e-03,\n",
       "                       8.4201e-02,  4.2134e-02,  1.6046e-02,  2.3450e-02,  8.8060e-02,\n",
       "                       4.8085e-02, -8.4916e-02,  1.2129e-02, -4.2934e-02, -5.6721e-03,\n",
       "                      -1.1035e-02,  1.3204e-02, -5.8016e-02,  8.7084e-02, -1.4294e-02,\n",
       "                       1.4679e-02,  7.4082e-02, -3.7229e-02, -3.4799e-02,  2.5808e-02,\n",
       "                       2.4000e-02, -3.3563e-02,  1.6848e-01,  1.0602e-01,  5.9582e-02,\n",
       "                       8.3997e-02,  7.8156e-02, -3.7508e-02, -4.1557e-01,  2.3600e-02,\n",
       "                       3.1274e-03,  7.4603e-03,  8.4531e-02,  3.2849e-02, -1.0143e-01,\n",
       "                      -3.7433e-02,  8.5322e-02, -1.5911e-02, -2.1363e-02,  7.3310e-02,\n",
       "                      -2.7056e-02,  1.5256e-02, -1.9991e-02,  4.2704e-02,  7.7894e-02,\n",
       "                       5.5588e-02,  1.7986e-02,  2.5642e-02, -7.9179e-02, -2.3992e-02,\n",
       "                      -6.2029e-03, -2.9796e-02, -1.4673e-03,  9.3502e-02,  6.3489e-02,\n",
       "                       1.1908e-01,  6.2056e-02, -5.6944e-02, -7.1954e-02, -6.1192e-02,\n",
       "                      -1.1725e-02, -3.9700e-02, -1.1771e-01, -5.8190e-02, -7.5772e-02,\n",
       "                       7.6295e-02,  1.9110e-02,  2.9121e-02, -2.0429e-03, -7.0175e-02,\n",
       "                       2.2340e-02, -1.5328e-01,  2.6594e-02,  2.2898e-02, -5.6616e-02,\n",
       "                       1.5324e-01, -6.6904e-02,  1.1988e-01, -5.0318e-03, -5.7539e-03,\n",
       "                       3.2985e-02, -4.6482e-02, -1.1958e-02,  1.1936e-02, -7.1598e-02,\n",
       "                       4.6951e-02, -5.3758e-02, -4.5565e-02,  7.1447e-02,  6.7585e-02,\n",
       "                      -4.8113e-02,  5.1175e-02,  6.9373e-03,  7.2155e-02, -2.6037e-01,\n",
       "                      -7.3307e-02, -4.0713e-03, -3.3950e-02,  1.2255e-01, -1.0152e-02,\n",
       "                       2.2888e-02], device='cuda:0')),\n",
       "             ('module.layers.6.norm1.weight',\n",
       "              tensor([0.9620, 1.0064, 1.0889, 0.9619, 0.9431, 1.1026, 1.0995, 0.9761, 0.9554,\n",
       "                      0.9463, 1.1674, 1.0270, 1.3037, 0.9120, 1.1057, 1.0486, 0.8935, 0.9243,\n",
       "                      1.1262, 0.9447, 1.0348, 1.0869, 0.9952, 1.0635, 1.0306, 0.8709, 0.9727,\n",
       "                      1.0244, 1.0797, 0.7585, 1.1374, 0.9768, 1.0251, 1.0159, 0.8986, 1.0336,\n",
       "                      1.0552, 0.9305, 0.7790, 0.9064, 0.9951, 1.0488, 0.9249, 0.8971, 1.0805,\n",
       "                      1.0470, 1.0855, 0.7802, 0.9219, 0.9475, 0.9557, 1.0079, 0.9345, 1.0000,\n",
       "                      1.0246, 1.0731, 0.9557, 0.8860, 1.0068, 1.0151, 0.9278, 1.0191, 1.0285,\n",
       "                      0.9100, 1.1208, 1.1301, 0.8929, 1.1220, 0.8212, 0.9364, 1.0419, 1.0662,\n",
       "                      1.0323, 1.0095, 0.9070, 1.0143, 1.0722, 1.0321, 0.9453, 0.9620, 0.9692,\n",
       "                      1.0727, 1.1216, 0.9770, 1.0041, 0.8655, 1.1107, 1.1323, 0.8524, 1.0985,\n",
       "                      1.0995, 1.0449, 1.0026, 0.8828, 1.1146, 0.8745, 0.8468, 1.0184, 0.9811,\n",
       "                      1.0206, 0.9777, 0.8877, 1.0102, 1.1180, 0.9354, 0.9863, 0.9783, 1.1562,\n",
       "                      0.9398, 0.8371, 1.1197, 1.0593, 1.0320, 1.0023, 1.1108, 0.9433, 0.8821,\n",
       "                      1.0164, 1.0166, 0.9627, 1.0310, 1.0995, 0.9128, 0.9989, 1.1846, 1.0893,\n",
       "                      1.0904, 0.9266, 1.0427, 1.0691, 1.0009, 1.0362, 0.9976, 0.9274, 1.0960,\n",
       "                      1.0013, 1.0008, 1.0382, 1.0036, 0.9146, 0.7852, 0.9613, 1.0183, 0.9504,\n",
       "                      1.0052, 0.9954, 1.0323, 1.0090, 1.0326, 0.9943, 1.0584, 1.0580, 0.9973,\n",
       "                      0.9519, 0.9847, 0.9734, 1.0389, 1.0332, 0.9623, 1.0156, 0.9995, 0.8972,\n",
       "                      0.9564, 0.9514, 0.9629, 1.1197, 1.0829, 1.0922, 1.0150, 1.0596, 1.0754,\n",
       "                      1.0635, 0.9893, 0.9021, 1.0107, 0.9762, 0.9993, 1.0739, 0.9312, 0.8987,\n",
       "                      0.7925, 0.9495, 0.9044, 1.3489, 0.9864, 1.0021, 0.9448, 0.9569, 1.0985,\n",
       "                      1.1043, 1.0459, 0.9262, 0.9575, 0.6695, 1.0947, 1.0551, 0.9807, 0.9002,\n",
       "                      1.0928, 1.0770, 0.9628, 1.1181, 1.0906, 0.9982, 1.1783, 1.0306, 1.0893,\n",
       "                      0.9713, 0.9058, 1.0028, 0.9591, 0.9461, 1.0238, 0.8795, 0.9425, 0.9674,\n",
       "                      1.1130, 0.9338, 1.0082, 1.0672, 0.8623, 1.0966, 0.8339, 1.1090, 1.0535,\n",
       "                      0.9285, 1.1663, 1.0503, 0.8377, 1.0346, 1.0166, 0.9262, 1.0436, 0.9427,\n",
       "                      1.0337, 1.0692, 0.9275, 1.0833, 1.0175, 1.0302, 0.9996, 0.9365, 0.9896,\n",
       "                      0.8994, 1.0442, 0.9474, 0.9502, 1.0942, 1.0632, 1.1562, 1.0967, 0.8708,\n",
       "                      0.9834, 1.1241, 0.9403, 1.1371], device='cuda:0')),\n",
       "             ('module.layers.6.norm1.bias',\n",
       "              tensor([-1.7010e-02, -2.9057e-03, -4.2191e-02,  4.2828e-02, -6.8187e-02,\n",
       "                       8.1617e-02, -9.8627e-02,  5.5085e-03, -1.4980e-01,  1.3705e-01,\n",
       "                       5.1912e-04, -1.3361e-01, -1.1579e-01,  3.8659e-02,  4.6622e-02,\n",
       "                       5.8516e-02,  3.6657e-02, -5.2099e-02, -1.1915e-01,  1.6410e-02,\n",
       "                       1.4323e-02, -4.6582e-02,  1.9149e-02, -7.4289e-02, -1.4415e-02,\n",
       "                      -1.4557e-01, -4.3244e-02,  1.6798e-01, -8.3235e-02,  1.1354e-01,\n",
       "                      -1.0202e-01, -1.4371e-01, -1.3192e-01,  5.0009e-02,  9.1040e-02,\n",
       "                       2.5391e-02,  2.5798e-02, -2.3406e-01, -2.3552e-03,  4.6051e-02,\n",
       "                      -1.2937e-01,  1.9228e-01,  1.3872e-01, -5.7742e-02,  1.2665e-01,\n",
       "                      -2.1552e-02, -7.0606e-04,  1.4371e-01, -1.1223e-01,  1.0026e-01,\n",
       "                      -2.5799e-01,  6.2251e-02,  2.5328e-02,  9.2905e-02, -6.2693e-02,\n",
       "                      -3.8692e-02,  6.8914e-02,  3.1598e-04, -9.2173e-02,  2.9292e-02,\n",
       "                      -2.8360e-01, -7.4927e-02,  3.4837e-02,  8.7344e-02, -8.5643e-03,\n",
       "                       9.1850e-02, -2.2825e-01, -6.0816e-02,  2.6872e-01, -6.4677e-02,\n",
       "                       4.4504e-02, -8.4496e-02, -7.7868e-02,  4.5201e-02,  1.0333e-01,\n",
       "                      -1.6762e-01,  2.8144e-03,  2.2344e-01,  1.0254e-01,  1.0717e-01,\n",
       "                      -3.8382e-03,  1.8245e-01, -1.2811e-01, -7.3495e-02, -6.9873e-04,\n",
       "                      -9.3156e-02, -7.0262e-02, -1.5391e-01, -1.2240e-02, -5.9397e-02,\n",
       "                      -5.9731e-02, -1.4494e-01,  3.4566e-01,  9.2621e-03,  3.0527e-02,\n",
       "                       1.5675e-01, -1.7657e-01, -2.4112e-01, -1.2010e-01,  5.6114e-02,\n",
       "                       4.8923e-02, -1.4271e-01,  1.4975e-01,  2.3399e-01, -9.2554e-02,\n",
       "                       2.3226e-02,  2.1748e-01, -9.4094e-02, -1.1126e-01,  1.7220e-01,\n",
       "                      -8.8892e-02,  1.8236e-02,  1.1719e-01, -9.2079e-02,  1.1083e-01,\n",
       "                      -2.5162e-01,  1.4813e-02, -7.7731e-03,  1.9649e-01,  6.9455e-02,\n",
       "                       1.2615e-01, -5.2954e-02, -1.3304e-01,  8.7635e-02,  5.9321e-02,\n",
       "                      -3.3565e-02, -3.5378e-02,  2.3293e-01,  2.5711e-01, -3.4568e-02,\n",
       "                       5.5988e-02,  7.4376e-02,  1.3709e-01,  9.9716e-03,  1.9157e-02,\n",
       "                      -8.5002e-03, -8.8356e-02,  3.4352e-02, -2.8186e-02,  5.9619e-02,\n",
       "                      -1.0283e-01,  8.4785e-03, -1.0261e-01,  4.9985e-02, -6.7115e-02,\n",
       "                       1.1994e-01,  1.5434e-01, -9.2981e-02,  1.8245e-01, -3.9747e-02,\n",
       "                      -3.8741e-02,  2.5089e-02,  2.5926e-02, -1.1525e-01,  7.4534e-02,\n",
       "                       2.8360e-02,  3.1896e-02,  6.9000e-02,  9.7943e-02,  8.1173e-02,\n",
       "                      -7.1603e-02,  8.7183e-02,  1.2724e-01, -3.9527e-02, -1.0069e-01,\n",
       "                       3.7866e-02, -1.3387e-01, -1.2824e-01, -2.1372e-02, -1.0466e-01,\n",
       "                      -9.5626e-02,  8.4996e-02, -1.4614e-01, -1.3269e-01,  1.1571e-01,\n",
       "                      -3.7782e-02, -2.7118e-01, -9.6244e-04, -3.7390e-02,  2.6228e-01,\n",
       "                       1.5293e-01,  1.7211e-01, -4.1449e-02, -8.8491e-02, -1.9316e-01,\n",
       "                       5.5550e-02, -4.3529e-02,  1.5812e-01,  9.6265e-03,  1.3253e-01,\n",
       "                      -6.4565e-02, -6.4092e-02, -1.3769e-01, -3.0061e-01,  4.9590e-02,\n",
       "                       4.0206e-02, -1.2544e-01,  6.8026e-02, -2.2703e-01, -1.4623e-01,\n",
       "                      -1.7152e-02,  5.7579e-02, -1.3567e-03,  6.3952e-02,  1.0823e-03,\n",
       "                       2.0622e-02,  1.2591e-01, -6.8596e-02, -1.8069e-01,  1.8788e-01,\n",
       "                       4.1393e-02, -7.3326e-02, -9.7496e-02,  1.1331e-01,  1.2860e-01,\n",
       "                      -3.0623e-02,  1.1616e-01, -2.1918e-01, -1.8986e-01, -1.4652e-02,\n",
       "                       1.2571e-01, -4.4201e-03,  1.3351e-01, -2.5027e-02, -3.0724e-02,\n",
       "                       1.8904e-01, -1.1290e-01, -5.1616e-02, -3.3058e-02, -2.9249e-02,\n",
       "                      -3.5029e-03, -1.5235e-01, -7.1030e-02, -4.0211e-02,  1.2427e-01,\n",
       "                      -5.0280e-02,  1.5362e-01,  1.0990e-01, -2.8696e-02,  4.5231e-02,\n",
       "                       1.0375e-01, -1.8246e-01, -1.4742e-01, -2.0999e-02,  2.8990e-01,\n",
       "                      -1.3169e-01, -8.8923e-02,  1.2137e-01,  2.6033e-01, -2.9534e-02,\n",
       "                       4.7608e-02, -8.1840e-03, -4.4930e-02,  8.6773e-02,  1.4147e-01,\n",
       "                       8.1018e-02], device='cuda:0')),\n",
       "             ('module.layers.6.norm2.weight',\n",
       "              tensor([0.8687, 0.7901, 0.8668, 0.9401, 0.8494, 0.7364, 0.7625, 0.8011, 0.8099,\n",
       "                      0.8406, 0.6377, 0.8916, 0.6119, 0.8182, 0.8360, 0.8196, 0.9070, 0.7790,\n",
       "                      0.8405, 0.7649, 0.8333, 0.7988, 0.8201, 0.9251, 0.8344, 0.8617, 0.7330,\n",
       "                      0.8849, 0.7636, 0.8586, 0.6003, 0.8743, 0.8096, 0.8545, 0.8405, 0.7415,\n",
       "                      0.8529, 1.0247, 0.8510, 0.8590, 0.7563, 0.9062, 0.8035, 0.8233, 0.7492,\n",
       "                      0.8132, 0.7857, 0.8624, 0.8570, 0.6966, 0.7505, 0.7598, 0.8957, 1.0815,\n",
       "                      0.7716, 0.8500, 0.7719, 0.8083, 0.8893, 0.8099, 0.9186, 0.7822, 0.8928,\n",
       "                      0.8804, 0.8967, 0.8976, 0.7835, 0.8086, 0.8733, 0.7684, 0.7983, 0.7963,\n",
       "                      0.7458, 0.7554, 0.9228, 0.8299, 0.8140, 0.9573, 0.8262, 0.6305, 0.8086,\n",
       "                      0.7059, 0.8384, 0.7770, 0.9051, 0.7786, 0.9245, 0.8523, 0.9780, 0.7944,\n",
       "                      0.7399, 0.6629, 0.8775, 0.9441, 0.6462, 0.9558, 0.8508, 0.7667, 0.7859,\n",
       "                      0.9093, 0.9142, 0.9322, 0.8422, 0.8119, 0.7858, 0.7589, 0.7203, 0.8149,\n",
       "                      0.8622, 0.8730, 0.7685, 0.8281, 0.9510, 0.7409, 0.7917, 0.6930, 0.7649,\n",
       "                      0.8288, 0.7944, 0.8656, 0.8254, 0.7762, 0.7704, 0.8317, 0.8200, 0.7750,\n",
       "                      0.8907, 0.7758, 0.7847, 0.8263, 0.7817, 0.7105, 0.8681, 0.8708, 0.7848,\n",
       "                      0.7854, 0.9637, 0.7777, 0.8649, 0.8997, 0.9329, 0.8291, 0.6868, 0.7756,\n",
       "                      0.8570, 0.8470, 0.8010, 0.8613, 0.6942, 0.8021, 0.8689, 0.9029, 0.7687,\n",
       "                      0.7367, 0.8481, 0.8794, 0.7900, 1.1025, 0.6880, 0.8104, 0.8198, 0.8752,\n",
       "                      0.8502, 0.8962, 0.8294, 0.8160, 0.7098, 0.7636, 0.8437, 0.8530, 0.7880,\n",
       "                      0.9421, 0.9957, 0.8654, 0.8004, 0.8038, 0.9763, 0.7662, 0.8159, 0.8589,\n",
       "                      0.8350, 0.8081, 0.8950, 0.4473, 0.8873, 0.8801, 1.0583, 0.9237, 0.7950,\n",
       "                      0.7447, 0.7887, 0.8645, 0.9204, 1.0101, 0.9027, 0.8448, 1.0199, 0.7380,\n",
       "                      1.0206, 0.7917, 0.8281, 0.7614, 0.9526, 0.8570, 0.7383, 0.7330, 0.8619,\n",
       "                      0.7947, 0.8042, 0.6936, 0.7202, 0.7899, 0.7658, 0.8284, 0.7592, 1.1237,\n",
       "                      0.7998, 0.8590, 0.8334, 0.7727, 0.9542, 0.7385, 0.7818, 0.8446, 0.9052,\n",
       "                      0.8392, 0.6869, 0.7979, 0.8212, 0.6989, 0.8275, 0.9392, 0.7231, 0.7718,\n",
       "                      0.7838, 0.7364, 0.7770, 0.7040, 1.0297, 0.8308, 0.8314, 0.7660, 1.0103,\n",
       "                      0.7750, 0.9391, 0.7865, 0.8222, 0.8618, 0.8296, 0.7137, 0.8014, 0.8825,\n",
       "                      0.7124, 0.7848, 0.7974, 0.8079], device='cuda:0')),\n",
       "             ('module.layers.6.norm2.bias',\n",
       "              tensor([ 7.4602e-03,  1.7533e-01,  8.5540e-02, -1.3256e-01, -4.1599e-02,\n",
       "                       7.1137e-02,  5.0181e-02, -9.3421e-02, -3.8948e-02, -2.1586e-01,\n",
       "                       8.2804e-02,  1.0163e-01,  3.0019e-01,  2.8996e-02, -8.0039e-02,\n",
       "                      -1.9770e-02, -1.0019e-01,  3.4676e-02, -2.4131e-02,  2.6361e-01,\n",
       "                      -3.6974e-02,  2.6108e-01, -1.4939e-01, -8.6197e-02, -4.5139e-02,\n",
       "                       8.6452e-02,  2.7124e-02,  2.6378e-02, -1.0715e-02, -7.7759e-02,\n",
       "                      -1.6555e-01,  2.2078e-01,  7.1041e-02,  2.1582e-01, -1.7682e-01,\n",
       "                      -6.6833e-02, -2.6672e-01, -1.5393e-01, -7.7741e-02,  1.8946e-01,\n",
       "                      -1.1671e-01,  1.4789e-01,  1.3697e-01, -6.4741e-03, -1.3129e-01,\n",
       "                       2.4688e-03,  5.5242e-02,  9.5273e-02, -7.6752e-02,  3.7661e-02,\n",
       "                       9.5691e-02, -8.2828e-03,  1.8847e-02,  5.6804e-01, -2.9836e-01,\n",
       "                      -8.3920e-02,  8.5640e-02,  4.4630e-02,  9.5414e-02,  6.8631e-02,\n",
       "                       3.1844e-02,  1.6103e-01, -7.6334e-02,  5.4941e-02, -3.2029e-02,\n",
       "                       6.6733e-02, -2.1586e-01, -1.2505e-01, -1.6734e-01, -9.9498e-02,\n",
       "                      -8.0882e-02, -1.2355e-02, -1.5167e-01,  8.2895e-02,  4.3428e-01,\n",
       "                       4.5436e-02, -2.4733e-01,  1.4713e-01, -5.4457e-02,  1.0583e-01,\n",
       "                       5.7340e-03, -1.4925e-01,  5.7016e-02, -8.9385e-02, -1.1298e-01,\n",
       "                       1.2546e-02,  8.9630e-02, -2.8061e-01,  1.4386e-01, -2.5341e-02,\n",
       "                      -1.6363e-01,  6.1629e-02,  9.0387e-02, -2.1194e-01,  5.9845e-02,\n",
       "                      -7.3429e-02,  2.8164e-01, -1.3557e-01, -5.4511e-02, -1.7270e-01,\n",
       "                       3.4706e-02,  2.0512e-01, -2.1173e-02, -3.1865e-02,  2.2027e-01,\n",
       "                       2.1792e-01, -1.0546e-01,  8.5733e-02,  4.9431e-02,  3.2791e-01,\n",
       "                       6.5595e-02,  1.4309e-01, -6.2919e-02, -5.5993e-02, -1.9485e-02,\n",
       "                       1.9063e-01,  5.2746e-03,  1.6742e-01,  2.6484e-01,  8.6146e-02,\n",
       "                      -1.7158e-01,  1.8205e-01, -6.1185e-02, -3.1375e-02, -4.3583e-02,\n",
       "                       1.8954e-02, -2.6560e-01,  6.0603e-02,  3.8927e-02, -7.0809e-02,\n",
       "                       2.3740e-01, -8.7671e-02,  1.1484e-01,  5.0015e-02, -1.6966e-01,\n",
       "                       4.2840e-02, -2.0379e-01,  1.0027e-01, -1.7307e-01, -1.4401e-01,\n",
       "                      -3.1349e-01, -3.0154e-01, -2.9999e-02,  9.8288e-02,  4.9798e-02,\n",
       "                       8.4481e-02,  3.4701e-02, -4.6627e-03, -1.5163e-01,  6.1498e-02,\n",
       "                       6.3265e-02,  8.8474e-02, -3.2491e-02, -1.2295e-01, -6.5077e-02,\n",
       "                      -3.5345e-02, -9.2678e-02,  2.2853e-02,  1.6472e-01, -1.2460e-01,\n",
       "                      -2.0158e-01,  1.7318e-02,  2.5217e-01,  1.5486e-01, -1.7428e-01,\n",
       "                       1.5919e-01, -1.3384e-01, -7.1786e-02, -1.4492e-02,  2.4458e-01,\n",
       "                      -6.3664e-02,  9.0830e-02,  9.7504e-02,  5.8187e-02, -2.1045e-01,\n",
       "                      -1.9334e-01, -1.1235e-01,  6.8083e-02, -1.1330e-02, -9.9946e-02,\n",
       "                      -4.6633e-02,  1.5320e-02,  6.7346e-02,  4.6423e-01, -2.0706e-01,\n",
       "                       2.7414e-01,  1.7533e-01, -3.6007e-01,  2.5834e-03, -6.8942e-02,\n",
       "                       4.8499e-03, -8.7943e-02,  3.9967e-02, -2.7483e-02,  8.6328e-03,\n",
       "                      -8.7463e-02,  6.2086e-02,  2.5348e-02,  2.0337e-01, -8.3077e-02,\n",
       "                       9.9961e-02, -2.2978e-02, -1.8426e-01,  1.2236e-01, -5.3849e-02,\n",
       "                       2.9027e-02, -1.7414e-01, -1.4231e-01, -2.0466e-02, -1.1122e-02,\n",
       "                      -1.3668e-01, -4.0412e-02, -2.3003e-01,  2.3676e-01,  2.5523e-01,\n",
       "                       3.1232e-01,  1.8960e-01, -1.2675e-02, -6.2869e-02, -4.3957e-04,\n",
       "                       1.6472e-01, -9.0046e-02,  1.3265e-02,  6.2275e-03, -3.6842e-02,\n",
       "                      -9.7431e-02,  2.8933e-01, -7.1279e-02, -2.7318e-02, -1.2228e-01,\n",
       "                      -7.4329e-02,  1.3451e-01,  7.4549e-02, -5.2339e-02, -1.8834e-02,\n",
       "                       4.5355e-02, -1.6319e-01,  6.2430e-02, -1.2658e-01, -1.8893e-01,\n",
       "                       1.6266e-01,  5.1506e-02, -5.8601e-02, -2.6357e-01, -3.9867e-02,\n",
       "                       2.0322e-01,  3.5288e-02, -3.0877e-02,  4.9842e-02,  1.2040e-01,\n",
       "                      -2.9879e-02,  8.1315e-02,  9.1014e-02, -6.2214e-02,  3.7328e-02,\n",
       "                      -9.8711e-03], device='cuda:0')),\n",
       "             ('module.layers.7.attn.attn.adaptive_span._mask.current_val',\n",
       "              tensor([[[0.3123]],\n",
       "              \n",
       "                      [[0.9687]],\n",
       "              \n",
       "                      [[0.9482]],\n",
       "              \n",
       "                      [[0.3218]]], device='cuda:0')),\n",
       "             ('module.layers.7.attn.attn.adaptive_span._mask.mask_template',\n",
       "              tensor([-1.0230e+03, -1.0220e+03, -1.0210e+03,  ..., -2.0000e+00,\n",
       "                      -1.0000e+00,  0.0000e+00], device='cuda:0')),\n",
       "             ('module.layers.7.attn.proj_query.weight',\n",
       "              tensor([[-0.0343, -0.0636, -0.0932,  ...,  0.1194,  0.0526,  0.0135],\n",
       "                      [-0.0621,  0.0434, -0.0838,  ...,  0.0622,  0.0157, -0.0712],\n",
       "                      [ 0.0408,  0.1426, -0.0590,  ..., -0.0302, -0.0177, -0.0126],\n",
       "                      ...,\n",
       "                      [-0.0627, -0.2106,  0.0386,  ...,  0.0332,  0.0188, -0.0460],\n",
       "                      [-0.0350, -0.0017,  0.1530,  ...,  0.1069, -0.1195, -0.0017],\n",
       "                      [ 0.0325, -0.0432,  0.0110,  ...,  0.0815,  0.0655, -0.0789]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.7.attn.proj_out.weight',\n",
       "              tensor([[-0.2216, -0.1553, -0.0787,  ..., -0.0022,  0.0958, -0.0417],\n",
       "                      [-0.0585, -0.0330,  0.0117,  ..., -0.1452,  0.0656, -0.0587],\n",
       "                      [-0.0346, -0.1373,  0.0016,  ...,  0.0222, -0.0175, -0.0154],\n",
       "                      ...,\n",
       "                      [-0.0478,  0.0008, -0.1043,  ...,  0.0492,  0.0879,  0.1373],\n",
       "                      [ 0.0423,  0.0776,  0.0123,  ...,  0.1339, -0.0368,  0.0127],\n",
       "                      [ 0.0937, -0.0130, -0.0260,  ...,  0.0178,  0.0738, -0.0096]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.7.attn.proj_val.weight',\n",
       "              tensor([[-0.0843,  0.0501,  0.0369,  ...,  0.0251, -0.0078,  0.0208],\n",
       "                      [-0.0453,  0.0993, -0.1250,  ..., -0.0020,  0.0813,  0.0558],\n",
       "                      [-0.1015,  0.0285, -0.0139,  ...,  0.0174, -0.1401, -0.0196],\n",
       "                      ...,\n",
       "                      [-0.0742, -0.0074, -0.0398,  ..., -0.1317, -0.0173,  0.0061],\n",
       "                      [ 0.0439,  0.0612, -0.0303,  ...,  0.0502,  0.0007, -0.0065],\n",
       "                      [-0.0148, -0.0705,  0.0196,  ..., -0.0402,  0.0438, -0.0031]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.7.attn.proj_key.weight',\n",
       "              tensor([[ 0.0007, -0.0237,  0.2304,  ..., -0.2232, -0.1183,  0.1259],\n",
       "                      [-0.0792,  0.1125,  0.0939,  ...,  0.1024,  0.0184, -0.2268],\n",
       "                      [-0.0305, -0.0720,  0.0354,  ...,  0.0227,  0.0766,  0.0119],\n",
       "                      ...,\n",
       "                      [ 0.1317, -0.0824,  0.0114,  ...,  0.0113,  0.0344, -0.1348],\n",
       "                      [ 0.0009,  0.0129,  0.0239,  ...,  0.1617, -0.0837, -0.1773],\n",
       "                      [-0.1373, -0.2066,  0.3107,  ...,  0.1091, -0.0028, -0.0939]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.7.ff.fc1.weight',\n",
       "              tensor([[ 3.4130e-02, -4.6606e-02,  3.1837e-02,  ..., -9.1301e-02,\n",
       "                        1.1738e-02,  1.2098e-01],\n",
       "                      [ 3.6394e-02, -7.1632e-02, -1.5275e-01,  ...,  1.5575e-02,\n",
       "                       -7.5913e-02,  1.5944e-02],\n",
       "                      [-4.5392e-02, -7.3081e-03,  2.4945e-02,  ...,  3.8869e-02,\n",
       "                        5.5335e-02, -4.4900e-02],\n",
       "                      ...,\n",
       "                      [ 2.6519e-02, -8.5652e-02,  1.4211e-02,  ...,  7.9177e-02,\n",
       "                        4.8038e-02, -1.4397e-01],\n",
       "                      [-1.7361e-01,  3.7381e-02, -1.9833e-02,  ..., -7.2228e-02,\n",
       "                        7.5400e-02,  2.0869e-02],\n",
       "                      [ 4.3492e-05, -2.2996e-02, -1.4908e-02,  ..., -7.6887e-02,\n",
       "                       -1.1810e-01,  1.1509e-01]], device='cuda:0')),\n",
       "             ('module.layers.7.ff.fc1.bias',\n",
       "              tensor([-0.3567, -0.1616, -0.0019,  ...,  0.0091, -0.2077, -0.1199],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.7.ff.fc2.weight',\n",
       "              tensor([[ 0.0122, -0.0058, -0.0010,  ...,  0.0233,  0.0026,  0.0081],\n",
       "                      [ 0.0390, -0.0347, -0.0193,  ...,  0.0340, -0.0040, -0.0085],\n",
       "                      [ 0.0024,  0.0018,  0.0417,  ..., -0.0119,  0.0198, -0.0053],\n",
       "                      ...,\n",
       "                      [-0.0115, -0.0337, -0.0293,  ...,  0.0347, -0.0126, -0.0008],\n",
       "                      [-0.0146, -0.0235,  0.0277,  ..., -0.0191,  0.0591, -0.0116],\n",
       "                      [-0.0407,  0.0538, -0.0024,  ..., -0.0046, -0.0073, -0.0466]],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.7.ff.fc2.bias',\n",
       "              tensor([ 1.1308e-01,  6.5668e-02, -2.6373e-02, -8.3591e-02,  1.7870e-01,\n",
       "                       8.7595e-02, -2.1582e-02,  9.7420e-02, -3.8471e-02, -5.2016e-02,\n",
       "                       1.9225e-01, -1.2427e-02,  1.1333e-01, -2.7265e-02, -4.1359e-02,\n",
       "                      -1.3633e-02, -7.8429e-02,  3.9531e-02,  5.1044e-02,  2.6075e-02,\n",
       "                       6.9686e-02,  8.2202e-03,  5.7463e-02, -1.1419e-01, -2.5180e-02,\n",
       "                      -7.6563e-02, -3.1012e-02, -2.0736e-02,  3.1963e-02,  5.5609e-03,\n",
       "                      -1.2372e-01,  5.1210e-02, -8.0796e-02, -5.6420e-02, -1.5712e-01,\n",
       "                      -4.6890e-02,  1.1121e-01,  6.0292e-02, -6.9969e-02,  1.0687e-01,\n",
       "                      -4.5796e-02,  1.8608e-02, -1.5968e-01, -5.3106e-02,  3.4326e-02,\n",
       "                      -4.3173e-02, -5.9340e-03,  8.0038e-02,  1.1722e-02, -3.5086e-02,\n",
       "                      -9.4232e-02, -5.5852e-02, -4.1254e-02, -7.3974e-02,  5.4932e-02,\n",
       "                      -1.4576e-02,  3.5602e-02, -3.5269e-02,  1.1535e-01, -2.0368e-03,\n",
       "                      -3.2473e-02,  1.0846e-01, -7.0975e-04, -3.1488e-02,  4.4202e-03,\n",
       "                      -5.5931e-02,  4.8595e-02,  2.3504e-02, -2.6453e-02,  1.2800e-02,\n",
       "                       9.2487e-02,  5.4806e-02, -1.3152e-02, -3.3042e-02, -5.4651e-02,\n",
       "                       1.6086e-02, -2.7489e-02, -5.3664e-02,  1.0246e-01, -9.9297e-02,\n",
       "                       5.5209e-02, -5.5912e-02,  5.5257e-02,  8.5034e-02, -1.7643e-02,\n",
       "                       7.4508e-02,  1.0626e-03, -7.3215e-02,  2.1480e-02, -2.0984e-02,\n",
       "                       1.9873e-02, -1.2695e-01, -3.0309e-02, -3.8143e-02, -5.2429e-02,\n",
       "                       1.6792e-01,  8.7954e-02, -6.8143e-02, -1.0393e-01,  3.9467e-02,\n",
       "                      -1.0230e-01,  1.5041e-02,  4.3530e-02,  2.2606e-02,  1.4751e-01,\n",
       "                      -5.4335e-02,  1.0872e-01,  8.4026e-02, -6.4041e-02, -1.2039e-02,\n",
       "                      -7.1333e-02,  1.1628e-01,  1.1571e-01,  9.8902e-02,  3.6349e-04,\n",
       "                       2.9400e-02, -5.3488e-02,  1.1935e-01,  1.6510e-02, -1.3350e-02,\n",
       "                      -4.2209e-02, -1.8449e-02,  8.4654e-02,  8.5987e-02,  7.2141e-05,\n",
       "                      -8.5886e-02,  5.9526e-02, -1.0468e-03,  8.4354e-03, -7.4720e-02,\n",
       "                      -9.9018e-02, -1.6853e-02,  1.1820e-01, -2.4571e-02,  6.4488e-04,\n",
       "                       3.2219e-02, -7.4695e-02, -5.8752e-02, -3.2041e-02, -4.2134e-02,\n",
       "                       2.9486e-02,  8.1506e-02, -9.1003e-02, -5.7877e-02, -6.5720e-02,\n",
       "                      -3.7365e-02, -6.0071e-02,  3.2204e-02,  4.9178e-02, -5.3725e-02,\n",
       "                      -2.3488e-02, -6.2145e-02, -1.9451e-02,  5.2497e-03, -1.3329e-02,\n",
       "                       4.8599e-02,  6.4361e-02,  4.3067e-02, -5.8431e-02, -6.4221e-02,\n",
       "                      -6.1481e-04,  2.7872e-02, -1.8592e-02, -5.7750e-02, -9.5698e-02,\n",
       "                      -4.2711e-02,  6.3998e-02,  1.7346e-01, -1.0453e-01,  1.4518e-02,\n",
       "                       4.7904e-02,  4.9371e-02,  7.0748e-02,  3.6245e-02,  1.2006e-01,\n",
       "                      -8.9460e-02,  6.2576e-02, -4.5892e-03,  1.3424e-01,  2.0557e-02,\n",
       "                      -5.7386e-02,  7.6643e-02, -2.9125e-02, -6.2838e-02,  3.1554e-03,\n",
       "                      -4.3571e-02,  7.6383e-02,  2.0241e-02,  1.4430e-02, -3.9223e-03,\n",
       "                      -1.7589e-01,  7.5727e-02,  1.4421e-01, -5.3138e-02, -1.6370e-01,\n",
       "                      -4.8153e-02, -2.6400e-02,  2.7247e-02, -8.0264e-02,  1.4463e-03,\n",
       "                       7.0865e-02,  3.5753e-02, -4.6233e-02,  2.5159e-02, -5.2296e-02,\n",
       "                      -2.1565e-02,  1.3753e-03, -7.7627e-02,  8.9456e-02, -5.4207e-02,\n",
       "                       1.6827e-02,  1.2955e-01, -5.9869e-02, -3.5355e-02,  6.0559e-02,\n",
       "                       2.1391e-03, -1.2180e-01, -1.7288e-01, -7.2038e-03, -1.5280e-01,\n",
       "                       3.3406e-03, -8.9430e-02,  1.5072e-02, -2.0621e-02,  9.4125e-03,\n",
       "                      -1.1380e-01, -1.9269e-01,  7.7862e-02,  1.1306e-01, -5.2526e-02,\n",
       "                      -8.6021e-02,  3.9505e-02,  2.5761e-02, -4.4253e-02, -3.1591e-02,\n",
       "                       7.1446e-02, -7.6206e-02,  2.6383e-02, -3.6564e-02, -5.0812e-02,\n",
       "                       6.6890e-02, -2.5041e-03,  5.1460e-02, -5.0994e-02,  9.1790e-02,\n",
       "                      -2.0919e-02, -6.3247e-02, -5.9211e-02,  5.6811e-02, -1.1317e-02,\n",
       "                      -1.3416e-03,  6.1839e-02,  5.9265e-02,  6.8097e-02, -8.4734e-02,\n",
       "                       8.3011e-03], device='cuda:0')),\n",
       "             ('module.layers.7.norm1.weight',\n",
       "              tensor([0.8881, 1.0765, 0.9236, 0.9979, 0.9762, 0.9763, 1.0974, 1.0865, 1.0632,\n",
       "                      0.8773, 1.0302, 0.8823, 0.9081, 1.0930, 0.9709, 1.1340, 1.0148, 1.1126,\n",
       "                      1.0288, 1.0241, 0.9731, 0.9859, 0.9684, 0.9603, 1.0783, 0.9258, 1.0613,\n",
       "                      0.8128, 0.9708, 0.9036, 1.0648, 1.0218, 0.9396, 1.0312, 0.9033, 1.0201,\n",
       "                      0.9309, 0.8556, 1.0191, 1.0484, 1.0126, 0.9579, 1.0736, 0.9944, 1.0880,\n",
       "                      1.0802, 1.1179, 1.1283, 0.9679, 1.0597, 0.9961, 1.0102, 0.9634, 0.9072,\n",
       "                      1.0707, 0.8915, 1.0412, 0.9169, 1.0811, 1.0368, 1.0399, 0.9646, 0.8531,\n",
       "                      1.1044, 1.1081, 0.9930, 1.0606, 1.0490, 1.1034, 1.0344, 0.9914, 1.0932,\n",
       "                      0.9954, 1.0506, 0.8921, 1.0087, 1.0752, 0.9931, 0.9771, 1.1239, 0.9359,\n",
       "                      1.1078, 1.0493, 0.9786, 1.0289, 1.1367, 1.0322, 1.0346, 0.9529, 0.8668,\n",
       "                      1.0815, 1.0924, 0.9905, 0.9534, 1.0376, 1.1948, 0.9655, 1.0353, 1.0112,\n",
       "                      0.8459, 1.0085, 0.8714, 1.0299, 1.0866, 1.0813, 0.8954, 1.0435, 1.0465,\n",
       "                      1.0085, 1.0107, 1.0156, 0.9504, 0.9659, 1.0186, 1.0485, 1.1510, 1.0796,\n",
       "                      0.9584, 1.0937, 0.9855, 1.0720, 1.1347, 0.9902, 1.0140, 1.0810, 0.9551,\n",
       "                      0.8794, 1.0465, 1.0353, 1.0723, 1.0392, 1.1010, 1.0896, 1.0097, 0.9770,\n",
       "                      1.0652, 0.9789, 1.0561, 1.0961, 0.8950, 0.9309, 1.0491, 1.0573, 1.1182,\n",
       "                      1.0967, 0.9571, 1.0367, 1.0359, 1.0745, 0.9911, 1.0231, 1.0215, 1.1342,\n",
       "                      1.0261, 0.9722, 0.9869, 0.9943, 0.7289, 1.0095, 0.9739, 1.1334, 0.8969,\n",
       "                      0.9433, 0.9925, 0.9848, 1.1010, 0.9196, 1.0793, 0.9477, 0.9396, 1.0919,\n",
       "                      1.0608, 0.9811, 1.0794, 0.9739, 1.0342, 0.8583, 1.0083, 0.9278, 0.9683,\n",
       "                      1.0110, 1.0708, 1.0617, 1.0193, 0.9791, 0.8213, 0.8701, 0.9486, 1.0221,\n",
       "                      1.0871, 0.9575, 0.9741, 0.9832, 0.9184, 0.9643, 0.9794, 0.9243, 0.9715,\n",
       "                      0.9390, 1.0702, 1.0250, 1.0387, 0.8519, 0.9159, 1.0626, 1.0626, 1.1441,\n",
       "                      1.1603, 1.0384, 1.1181, 0.9275, 1.0383, 1.0331, 1.0262, 1.1149, 0.8448,\n",
       "                      1.1233, 1.0376, 1.0177, 1.1064, 0.8500, 1.1169, 1.0119, 0.9219, 0.9181,\n",
       "                      1.1187, 1.1057, 1.0644, 0.9847, 1.0742, 0.9050, 0.9995, 1.0782, 1.0673,\n",
       "                      1.0327, 1.1247, 1.0837, 1.0037, 0.9610, 1.0593, 0.9264, 0.9859, 0.9783,\n",
       "                      1.0146, 0.8917, 1.1122, 1.0302, 1.0228, 1.0115, 0.8243, 1.1592, 1.0295,\n",
       "                      1.2350, 0.9969, 1.1475, 1.0428], device='cuda:0')),\n",
       "             ('module.layers.7.norm1.bias',\n",
       "              tensor([ 0.3243, -0.0409,  0.0218,  0.0489,  0.0816,  0.1449,  0.2018,  0.2774,\n",
       "                      -0.1506,  0.0184,  0.3261,  0.0545,  0.5377,  0.0122, -0.1152, -0.0249,\n",
       "                      -0.0471,  0.0847,  0.0115,  0.0522, -0.2026,  0.0650,  0.0050,  0.0012,\n",
       "                      -0.1709, -0.4096, -0.0080,  0.1463,  0.0396, -0.1001, -0.3355, -0.0196,\n",
       "                       0.2817, -0.1390, -0.1497, -0.0599,  0.0422,  0.1442, -0.1588, -0.0456,\n",
       "                      -0.1668,  0.1178, -0.2049,  0.3948,  0.0011,  0.0205, -0.1722,  0.2546,\n",
       "                       0.1709,  0.0603,  0.0270, -0.1502,  0.0493, -0.0890,  0.0378, -0.1646,\n",
       "                      -0.0461,  0.0527,  0.0444,  0.1533, -0.0973,  0.1371,  0.0720,  0.0633,\n",
       "                      -0.0581, -0.1240, -0.0702,  0.0813,  0.0868,  0.0380, -0.0986,  0.1377,\n",
       "                      -0.1319,  0.0125,  0.0649, -0.1044, -0.0019,  0.0915,  0.1667,  0.0476,\n",
       "                       0.0466,  0.2871,  0.0420,  0.0401, -0.1027, -0.0276,  0.0010, -0.0832,\n",
       "                      -0.0802, -0.0887, -0.1712,  0.1041,  0.2683, -0.1264,  0.1173,  0.0966,\n",
       "                      -0.0207, -0.0912, -0.1348, -0.0082, -0.0938,  0.0852,  0.0600,  0.1015,\n",
       "                       0.0747,  0.0103, -0.0859, -0.1533, -0.1508, -0.0226,  0.1505, -0.0511,\n",
       "                       0.3130,  0.1639,  0.0148, -0.0448,  0.1011, -0.1217,  0.1366,  0.0866,\n",
       "                      -0.1153,  0.1934,  0.0404,  0.1492,  0.0714, -0.2632, -0.0043,  0.2817,\n",
       "                       0.1131,  0.0376, -0.1889, -0.0028,  0.2410, -0.2220,  0.0819,  0.0375,\n",
       "                       0.0039, -0.0057, -0.0718,  0.0236,  0.0466,  0.0858, -0.0202,  0.0602,\n",
       "                      -0.0847, -0.1065, -0.1602, -0.0369, -0.3072,  0.0306,  0.0410,  0.2229,\n",
       "                       0.0657,  0.0602, -0.2429, -0.0403,  0.0527,  0.1416, -0.2009, -0.0359,\n",
       "                      -0.0181, -0.1026, -0.0428,  0.0010,  0.0974, -0.0820, -0.0937, -0.0395,\n",
       "                      -0.0512,  0.1404, -0.0214,  0.0394,  0.0689, -0.0202,  0.1340, -0.3026,\n",
       "                       0.0510, -0.0419, -0.0491,  0.0183, -0.0565,  0.2144, -0.1245,  0.3281,\n",
       "                       0.0627,  0.1217,  0.2522, -0.0196,  0.1384,  0.0292, -0.1407, -0.0787,\n",
       "                       0.2962, -0.1194, -0.1634,  0.1796, -0.1656, -0.0556, -0.0230, -0.1038,\n",
       "                      -0.0075, -0.0923, -0.1719,  0.1332, -0.2837,  0.0988,  0.2587, -0.0460,\n",
       "                      -0.1098, -0.1365, -0.1041,  0.0839,  0.0037, -0.0671,  0.0978,  0.1845,\n",
       "                       0.0119, -0.2688, -0.1277, -0.0755, -0.0440, -0.1560, -0.1214, -0.0505,\n",
       "                      -0.0205, -0.1462, -0.1671,  0.1164,  0.1227, -0.1628, -0.3777,  0.0186,\n",
       "                      -0.1021, -0.2485,  0.0324,  0.0105, -0.0144,  0.1351, -0.0878, -0.1589,\n",
       "                       0.0378,  0.1304,  0.3564, -0.2354,  0.0883,  0.0393, -0.3162, -0.1754,\n",
       "                       0.1283,  0.4361, -0.1528,  0.0388, -0.1183, -0.0660, -0.0488, -0.1797],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layers.7.norm2.weight',\n",
       "              tensor([2.4596, 2.0248, 4.7039, 3.4384, 2.4765, 2.2651, 2.4909, 2.2807, 2.1298,\n",
       "                      3.3015, 3.4040, 3.0502, 2.7242, 2.2679, 2.8809, 2.8749, 2.0406, 2.6012,\n",
       "                      2.4553, 2.5573, 2.9380, 3.0975, 3.0718, 2.9550, 2.7606, 2.7959, 2.5064,\n",
       "                      3.9281, 3.6891, 2.4729, 2.5599, 3.0240, 3.2408, 2.3416, 3.3092, 2.5331,\n",
       "                      2.8866, 2.8086, 2.6112, 2.4753, 2.6153, 3.1327, 2.9834, 2.0994, 2.2524,\n",
       "                      2.3804, 2.4094, 2.2607, 2.6763, 3.2004, 3.2199, 4.3194, 2.8128, 2.2213,\n",
       "                      3.2765, 2.4873, 3.6468, 2.9893, 2.2521, 2.7106, 2.7430, 3.8181, 2.4734,\n",
       "                      1.9309, 2.8658, 4.2220, 2.6750, 4.3862, 1.9410, 3.5045, 3.5809, 2.8260,\n",
       "                      2.8123, 3.0497, 2.2490, 3.0818, 2.0787, 2.6481, 3.0201, 2.3060, 2.8434,\n",
       "                      2.6572, 4.1418, 2.7504, 2.7073, 1.9649, 2.1720, 2.9113, 2.9205, 2.3004,\n",
       "                      3.2772, 2.6597, 3.6366, 3.2975, 2.7550, 1.6309, 3.1093, 2.7553, 2.9990,\n",
       "                      2.9957, 3.0016, 3.4332, 3.5188, 3.0766, 3.7499, 3.0070, 3.4015, 3.0195,\n",
       "                      2.8918, 2.0479, 3.1674, 3.4390, 3.0680, 3.0480, 3.4114, 2.5586, 4.0925,\n",
       "                      2.5389, 2.5257, 3.4299, 2.0993, 2.6751, 3.2346, 3.9450, 2.3733, 3.5055,\n",
       "                      2.9309, 2.3439, 3.3566, 3.3987, 2.5110, 3.7674, 2.5996, 2.6628, 3.0663,\n",
       "                      2.9148, 2.0756, 2.8527, 2.7641, 4.1591, 2.7921, 3.1840, 3.2215, 2.7317,\n",
       "                      1.8586, 2.9845, 2.5730, 3.9255, 3.1089, 2.5433, 2.7056, 3.2263, 2.3940,\n",
       "                      2.6172, 2.7701, 2.8336, 4.0536, 4.1824, 2.8651, 3.1984, 2.5421, 2.7572,\n",
       "                      2.6983, 4.3454, 4.7196, 3.2041, 2.7328, 3.4034, 3.4067, 2.2521, 3.2177,\n",
       "                      2.8979, 2.5548, 2.5426, 3.5506, 2.8633, 3.2646, 3.0776, 2.8999, 2.6737,\n",
       "                      2.8536, 2.7294, 2.1978, 2.5274, 2.4116, 2.8668, 2.8973, 2.8166, 2.8769,\n",
       "                      2.6474, 4.6936, 3.1421, 3.3032, 2.1359, 4.5067, 3.1075, 2.9372, 4.0997,\n",
       "                      2.8931, 2.3786, 3.3179, 3.0759, 3.2240, 4.0107, 2.9964, 2.6620, 2.3012,\n",
       "                      2.5337, 2.8885, 3.8068, 3.9196, 3.3231, 2.6579, 1.8362, 2.8040, 3.6205,\n",
       "                      2.7806, 2.5567, 2.7054, 3.1154, 3.1838, 2.8512, 2.7599, 4.4876, 1.7186,\n",
       "                      2.3355, 3.9065, 3.3958, 2.8247, 3.8797, 2.8310, 2.0756, 2.4655, 3.0785,\n",
       "                      3.0429, 3.4845, 3.7144, 2.6354, 2.6260, 2.0941, 3.8564, 3.5511, 2.4764,\n",
       "                      1.8903, 2.8813, 2.4614, 3.2159, 2.8779, 3.4884, 2.6631, 2.0360, 2.4639,\n",
       "                      2.8293, 2.7627, 2.9273, 4.2741], device='cuda:0')),\n",
       "             ('module.layers.7.norm2.bias',\n",
       "              tensor([ 0.4864, -0.4716, -0.7740, -0.6668,  0.5123,  0.4146,  0.7981,  0.4013,\n",
       "                      -0.5892,  0.6699,  0.4749, -0.5234,  0.6941, -0.4577,  0.6078,  0.4435,\n",
       "                       0.9540,  0.4803,  0.8013,  0.6159,  0.5592, -0.6769,  0.3320, -0.6931,\n",
       "                      -0.3418, -0.6028,  0.7573, -0.5471,  0.7099,  0.4436, -0.7236,  0.6688,\n",
       "                       0.6807, -0.7572, -0.7078, -0.8764,  0.3703,  0.9293, -0.4812,  0.6981,\n",
       "                      -0.4914, -1.1922, -0.9777,  0.4424,  0.3897, -0.8517, -0.4577,  0.4570,\n",
       "                      -1.1193, -1.0223, -0.5637,  0.5068, -0.6153, -0.9563,  0.2423, -0.5547,\n",
       "                       0.4326, -1.0856, -0.4422,  0.5298, -0.5090,  0.8080,  0.7389,  0.5874,\n",
       "                       0.6477, -0.0119,  0.5225, -0.6089,  0.4000, -0.6956,  0.8339,  0.6166,\n",
       "                      -0.6364, -0.6229, -0.4772,  0.6267,  0.4652,  0.3628,  0.7169,  0.5857,\n",
       "                       0.8040, -0.8370, -0.9590,  0.7850,  0.4936, -0.3849, -0.3923, -0.5722,\n",
       "                       0.8889, -0.4820, -0.6997, -0.6300, -0.9729, -0.2181,  1.0225,  0.1867,\n",
       "                      -0.3605,  0.8208, -0.7725,  0.6835, -0.6601, -1.0693, -0.7281,  0.7601,\n",
       "                      -0.5534,  0.3968, -0.8565,  0.5948, -0.3341,  0.3938, -0.6547, -0.1444,\n",
       "                       0.5797,  0.3606,  0.6188,  1.0478,  0.0502,  1.4195, -0.7564, -0.6198,\n",
       "                       0.7828, -0.4637,  0.8028,  0.7174, -0.4094, -0.5306,  0.4348,  0.4798,\n",
       "                      -1.0434, -0.6948, -0.8019,  0.7892,  0.4738, -0.9280,  0.6435, -0.5410,\n",
       "                       0.7273, -0.5162,  0.5317,  0.2515, -0.6156,  0.7254, -0.1576,  0.3963,\n",
       "                       0.4995,  0.5415,  0.4978, -0.5510,  1.0519,  0.8640, -0.1482, -0.9427,\n",
       "                      -0.2858, -0.5292, -0.5121,  0.2801,  0.4596,  0.1735, -0.7843, -0.9387,\n",
       "                       0.9661, -0.5570,  0.4263, -0.6596, -0.4723,  0.4232, -0.7811,  0.5856,\n",
       "                      -0.4783, -0.9543,  0.8737,  0.4838,  0.6440, -0.4420,  0.6075, -0.5068,\n",
       "                       0.9798, -0.9032,  0.7101, -0.6970,  0.7030,  0.6136, -0.6220, -0.5566,\n",
       "                       0.6334, -0.7491,  0.8840,  0.3897,  0.8561,  0.6708, -0.9134, -0.6143,\n",
       "                       0.6300, -0.4440, -0.7465, -0.7941, -0.5483,  0.7203,  0.5763,  0.4937,\n",
       "                       0.7518, -0.0186,  0.6356,  0.6114, -0.2800, -0.3725, -0.9803, -0.4700,\n",
       "                       1.1030, -0.6997,  0.7355,  0.9169, -0.7256, -0.5762,  0.5657, -0.6136,\n",
       "                      -1.1750, -0.3755, -0.4156, -1.1435, -0.5171, -0.8441, -0.3310,  1.1770,\n",
       "                      -0.2965, -0.6100, -0.6324,  0.6923,  0.5863, -0.8018, -0.6567, -0.3741,\n",
       "                       0.7890, -0.7773,  0.5988,  0.4305, -0.5386, -0.3713,  0.8996, -0.6043,\n",
       "                       0.8487, -0.6681,  0.6264, -0.4540, -0.5359, -0.6231, -0.8202, -0.4469,\n",
       "                       0.4630,  0.5117, -0.5281,  0.8051,  0.5663,  0.3867, -0.6904,  0.8508],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_state['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.load_state_dict(checkpoint_state['model'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets/code_search_net/tokenised/train.txt\n",
      "Tokenizing datasets/code_search_net/tokenised/valid.txt\n",
      "Tokenizing datasets/code_search_net/tokenised/test.txt\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(\"datasets/code_search_net/tokenised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128137090])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(\"datasets/code_search_net/code_bpe_hugging_32k-vocab.json\",\n",
    "                                  \"datasets/code_search_net/code_bpe_hugging_32k-merges.txt\",)\n",
    "\n",
    "sent = \"top_item = items[0\"\n",
    "# sent = \"    if (a == b): \"\n",
    "ids = tokenizer.encode(sent).ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_input = torch.tensor([[corpus._dictionary[str(i)] for i in ids]]).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_cache = [[\n",
    "        torch.zeros(\n",
    "            1,\n",
    "            layer.attn.attn.get_cache_size(),\n",
    "            params[\"model_params\"][\"hidden_size\"]).to(\"cuda\")\n",
    "        for layer in model.module.layers] for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.layers[0].attn.attn.get_cache_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 31886])\n",
      "torch.Size([7, 31886])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(src_input,hid_cache[0])\n",
    "v_out, h_cache = outputs\n",
    "print(v_out.shape)\n",
    "v_out = v_out[0]\n",
    "print(v_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_itos = [0]*len(corpus._dictionary)\n",
    "for k,v in corpus._dictionary.items():\n",
    "    try:\n",
    "        corpus_itos[v] = int(k)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "] or ][ or ]. or ], or ]]\n"
     ]
    }
   ],
   "source": [
    "max_ids_outputs = torch.argsort(v_out, dim=-1, descending=True).tolist()\n",
    "BPE_ids = [[corpus_itos[j] for j in i] for i in max_ids_outputs][-1][:5]\n",
    "print(\" or \".join([tokenizer.decode([i]) for i in BPE_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
      "    \"\"\"\n",
      "    Trains a k-nearest neighbors classifier for face recognition.\n",
      "\n",
      "    :param train_dir: directory that contains a sub-directory for each known person, with its name.\n",
      "\n",
      "     (View in source code to see train_dir example tree structure)\n",
      "\n",
      "     Structure:\n",
      "        <train_dir>/\n",
      "        ├── <person1>/\n",
      "        │   ├── <somename1>.jpeg\n",
      "        │   ├── <somename2>.jpeg\n",
      "        │   ├── ...\n",
      "        ├── <person2>/\n",
      "        │   ├── <somename1>.jpeg\n",
      "        │   └── <somename2>.jpeg\n",
      "        └── ...\n",
      "\n",
      "    :param model_save_path: (optional) path to save model on disk\n",
      "    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\n",
      "    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\n",
      "    :param verbose: verbosity of training\n",
      "    :return: returns knn classifier that was trained on the given data.\n",
      "    \"\"\"\n",
      "    X = []\n",
      "    y = []\n",
      "\n",
      "    # Loop through each person in the training set\n",
      "    for class_dir in os.listdir(train_dir):\n",
      "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
      "            continue\n",
      "\n",
      "        # Loop through each training image for the current person\n",
      "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
      "            image = face_recognition.load_image_file(img_path)\n",
      "            face_bounding_boxes = face_recognition.face_locations(image)\n",
      "\n",
      "            if len(face_bounding_boxes) != 1:\n",
      "                # If there are no people (or too many people) in a training image, skip the image.\n",
      "                if verbose:\n",
      "                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
      "            else:\n",
      "                # Add face encoding for current image to the training set\n",
      "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
      "                y.append(class_dir)\n",
      "\n",
      "    # Determine how many neighbors to use for weighting in the KNN classifier\n",
      "    if n_neighbors is None:\n",
      "        n_neighbors = int(round(math.sqrt(len(X))))\n"
     ]
    }
   ],
   "source": [
    "!head -50 datasets/code_search_net/code_corpus_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
