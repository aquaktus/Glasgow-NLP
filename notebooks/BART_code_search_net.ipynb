{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can Language Models produce correct structured output?\n",
    "The goaal of this notebook is to explorer the nature of the mistakes a Language Modell can make when producing structured output like code. The idea is that it is prone to making syntactic errors that could be avoided when scaling up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.RawDataLoaders import CodeSearchNet_RawDataLoader, CoNaLa_RawDataLoader\n",
    "from src.models_and_transforms.text_transforms import Numericalise_Transform, Rename_Transform\n",
    "from src.models_and_transforms.complex_transforms import *\n",
    "from src.models_and_transforms.BART_models import BART_Simple\n",
    "from src.Experiments import Sequence_BLEU_Experiment\n",
    "from src.models_and_transforms.SOTA_transforms import CoNaLa_SOTA_Transform, Django_SOTA_Transform\n",
    "from src.pipe_datasets import BART_Pipe_Dataset\n",
    "from src.useful_utils import chunks, download_from_url, Validate_and_Save_Callback\n",
    "\n",
    "from pytorch_lightning import Trainer, Callback, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateLogger\n",
    "from pytorch_lightning.callbacks.base import Callback\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from tokenizers import processors, Tokenizer\n",
    "from transformers import BartConfig\n",
    "import torch\n",
    "import ray\n",
    "# ray.init(ignore_reinit_error=True)\n",
    "import random\n",
    "import itertools\n",
    "import cloudpickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c736662f3a9543ee95fb13307ccc4c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='loading: sonl/train', max=14.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8b7c25daa24817b4321a946d2ac793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='loading: sonl/valid', max=1.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9aba74ca43d4c8f8e3b380e3e5b66d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='loading: jsonl/test', max=1.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "code_search_net_RawDataLoader = CodeSearchNet_RawDataLoader(\"./datasets/code_search_net\", language=\"python\", max_chars=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conala_RawDataLoader = CoNaLa_RawDataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running SOTA model on CoNaLa and Django"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load parser from [src/external_repos/external-knowledge-codegen/best_pretrained_models/finetune.mined.retapi.distsmpl.dr0.3.lr0.001.lr_de0.5.lr_da15.beam15.seed0.mined_100000.intent_count100k_topk1_temp5.bin]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading reranker...\n"
     ]
    }
   ],
   "source": [
    "conala_test_samples = conala_RawDataLoader.get_samples('test')\n",
    "conala_transform = CoNaLa_SOTA_Transform(cuda=False, fields={'input_field':'description', 'output_field':'pred_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baeb8fb653214bafa275e7bed99ee4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Tranx:', max=10.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.system('str_0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print(str_0.decode('str_0', 'ignore'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i for i in var_0 if i == i]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\" \"\"\".join(str(x) for x in str(var_0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicodedata.normalize('NFKD', string).encode('utf8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(var_0.values())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(var_0.values())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subprocess.call('str_0', **subprocess.check_output('str_0'), shell=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\"\"\".join([str_0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.concat([var_0] * 5, ignore_index=True)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "# takes around 5 mins for inference\n",
    "samples = conala_transform(conala_test_samples[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f023e66ebf704947bab088e0119632e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Tranx:', max=1.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_0 = [(i * j) for i, j in zip(var_0, var_0)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing rerank features for hypotheses...\n",
      "initializing features...\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'foo = [(x * y) for x in foo]'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples = [{'description':'multiply each element of list `foo` by 2'}]\n",
    "test_samples = conala_transform(test_samples)\n",
    "test_samples[0]['pred_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'send a signal `signal.SIGUSR1` to the current process',\n",
       "  'code': 'os.kill(os.getpid(), signal.SIGUSR1)',\n",
       "  'pred_code': \"os.system('<unk> <unk> <unk>')\",\n",
       "  'BLEU': 0.0},\n",
       " {'description': \"decode a hex string '4a4b4c' to UTF-8.\",\n",
       "  'code': \"bytes.fromhex('4a4b4c').decode('utf-8')\",\n",
       "  'pred_code': \"print(4a4b4c.decode('4a4b4c'))\",\n",
       "  'BLEU': 0.0},\n",
       " {'description': 'check if all elements in list `myList` are identical',\n",
       "  'code': 'all(x == myList[0] for x in myList)',\n",
       "  'pred_code': '[i for i in myList if i == 2]',\n",
       "  'BLEU': 0.0},\n",
       " {'description': 'format number of spaces between strings `Python`, `:` and `Very Good` to be `20`',\n",
       "  'code': \"print('%*s : %*s' % (20, 'Python', 20, 'Very Good'))\",\n",
       "  'pred_code': '\"\"\" \"\"\".join(str(x) for x in str(Python))',\n",
       "  'BLEU': 0.0},\n",
       " {'description': 'How to convert a string from CP-1251 to UTF-8?',\n",
       "  'code': \"d.decode('cp1251').encode('utf8')\",\n",
       "  'pred_code': \"unicodedata.normalize('NFKD', string).encode('utf8')\",\n",
       "  'BLEU': 0.27901593935858265},\n",
       " {'description': 'get rid of None values in dictionary `kwargs`',\n",
       "  'code': 'res = {k: v for k, v in list(kwargs.items()) if v is not None}',\n",
       "  'pred_code': 'list(kwargs.values())',\n",
       "  'BLEU': 1.0},\n",
       " {'description': 'get rid of None values in dictionary `kwargs`',\n",
       "  'code': 'res = dict((k, v) for k, v in kwargs.items() if v is not None)',\n",
       "  'pred_code': 'list(kwargs.values())',\n",
       "  'BLEU': 0.0},\n",
       " {'description': 'capture final output of a chain of system commands `ps -ef | grep something | wc -l`',\n",
       "  'code': \"subprocess.check_output('ps -ef | grep something | wc -l', shell=True)\",\n",
       "  'pred_code': 'sys.stdout.flush()',\n",
       "  'BLEU': 0.0},\n",
       " {'description': \"concatenate a list of strings `['a', 'b', 'c']`\",\n",
       "  'code': '\"\"\"\"\"\".join([\\'a\\', \\'b\\', \\'c\\'])',\n",
       "  'pred_code': '\"\"\"\"\"\".join([[\\'a\\', \\'b\\', \\'c\\']])',\n",
       "  'BLEU': 0.0},\n",
       " {'description': 'find intersection data between series `s1` and series `s2`',\n",
       "  'code': 'pd.Series(list(set(s1).intersection(set(s2))))',\n",
       "  'pred_code': 'pd.concat([s1] * 5, ignore_index=True)',\n",
       "  'BLEU': 0.0}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi_expr = Sequence_BLEU_Experiment(fields={'target_seq':'code', 'predicted_seq':'pred_code'})\n",
    "simi_expr.__transform__(samples)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsmoothed_official_BLEU: 0.22539098849201342\n",
      "nltk_BLEU: 0.2529552430370321\n"
     ]
    }
   ],
   "source": [
    "samples = simi_expr(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(samples, open(\"CoNaLa_TranX_predictions.json\", 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training BART on CoNaLa\n",
    "### Using the BPE tokens trained from code search net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training BART codeBPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'sort a list of lists `the_list` by the second item in each list',\n",
       " 'code': \"sorted(the_list, key=lambda x: int(x.split('_')[1]))\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conala_RawDataLoader = CoNaLa_RawDataLoader()\n",
    "conala_samples = conala_RawDataLoader.get_samples('mined_GPT3', max_char_len=200)[:20000]\n",
    "print('Dataset size:',len(conala_samples))\n",
    "conala_samples[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericaliser. Ex: 'This is a test' -> [0, 3863, 343, 276, 1772, 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d921f1a08b40fc82b2bdc6d6f43f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f69dad64f60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_numericalise_transform = Numericalise_Transform(numericaliser='Code32k', fields=[('description','input_ids'),('code','target_ids')])\n",
    "\n",
    "conala_dataset = BART_Pipe_Dataset(conala_samples, \n",
    "#                                          sort_key_fn=lambda sample_obj: len(sample_obj['target_ids']),\n",
    "#                                          valid_sample_fn=lambda sample_obj: len(sample_obj['target_ids'])<80 and len(sample_obj['input_ids'])<80,\n",
    "#                                          shuffle=True,\n",
    "#                                          batch_bucket_size=16, \n",
    "                                         slow_pipe=[], real_time_pipe=[code_numericalise_transform])\n",
    "conala_mined_dataloader = conala_dataset.to_dataloader(16)\n",
    "lengths = [len(s['target_ids']) for s in conala_dataset]\n",
    "plt.scatter(range(len(lengths)), lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BartConfig(vocab_size=32000)\n",
    "model = BART_Simple(from_pretrained=False, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import EvalResult\n",
    "import wandb\n",
    "def CoNaLa_valid_fn(model):\n",
    "    conala_RawDataLoader = CoNaLa_RawDataLoader()\n",
    "    test_samples = conala_RawDataLoader.get_samples('test')[:50]\n",
    "    test_samples = Rename_Transform(fields=[('description', 'input_text')])(test_samples)\n",
    "    \n",
    "    BART_cond_gen_transform = BART_Conditional_Generator_Transform(model, \n",
    "                                                                    numericaliser='Code32k', \n",
    "                                                                    denumericaliser='Code32k',\n",
    "                                                                    device='cuda',\n",
    "                                                                    max_length=40)\n",
    "    test_samples = BART_cond_gen_transform(test_samples)\n",
    "    test_samples = Sequence_BLEU_Experiment(fields = {'predicted_seq':'pred_text', 'target_seq':'code'}, debug=False)(test_samples)\n",
    "    nltk_BLEU = np.average([s[\"nltk_BLEU\"] for s in test_samples])\n",
    "    \n",
    "    table = wandb.Table(columns=[\"Desc\", \"True\", \"Pred\"])\n",
    "    for sample_obj in test_samples:\n",
    "        table.add_data(sample_obj['input_text'], sample_obj['code'], sample_obj['pred_text'])\n",
    "    \n",
    "    return {'nltk_BLEU':nltk_BLEU, 'valid_samples':table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lr = 0.000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 24905<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.01MB of 0.01MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201006_230855-19tfm72s/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201006_230855-19tfm72s/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>global_step</td><td>0</td></tr><tr><td>nltk_BLEU</td><td>0.0</td></tr><tr><td>_step</td><td>0</td></tr><tr><td>_runtime</td><td>15</td></tr><tr><td>_timestamp</td><td>1602025753</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>global_step</td><td>▁</td></tr><tr><td>nltk_BLEU</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">BART_codeBPE_mined20k_set_lowLR</strong>: <a href=\"https://wandb.ai/aquaktus/pytorchlightning/runs/19tfm72s\" target=\"_blank\">https://wandb.ai/aquaktus/pytorchlightning/runs/19tfm72s</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.4<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">BART_codeBPE_mined20k_set_lowLR</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/aquaktus/pytorchlightning\" target=\"_blank\">https://wandb.ai/aquaktus/pytorchlightning</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/aquaktus/pytorchlightning/runs/4j2t0m29\" target=\"_blank\">https://wandb.ai/aquaktus/pytorchlightning/runs/4j2t0m29</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201006_230932-4j2t0m29</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type                         | Params\n",
      "------------------------------------------------------\n",
      "0 | BART | BartForConditionalGeneration | 387 M \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662bc5b6837041638e5250f1b07c3d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericaliser. Ex: 'This is a test' -> [0, 3863, 343, 276, 1772, 2]\n",
      "Denumericaliser. Ex: [0,1,2,3,4,5,6,7,8,9] -> !\"#$%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f649700190436e9da5ccd7edd53420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BART is thinking:', max=50.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numericaliser. Ex: 'This is a test' -> [0, 3863, 343, 276, 1772, 2]\n",
      "Denumericaliser. Ex: [0,1,2,3,4,5,6,7,8,9] -> !\"#$%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcaa765f33d4082ae9737d30c2a5d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BART is thinking:', max=50.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numericaliser. Ex: 'This is a test' -> [0, 3863, 343, 276, 1772, 2]\n",
      "Denumericaliser. Ex: [0,1,2,3,4,5,6,7,8,9] -> !\"#$%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aed9bc2b7d6498bb6b7324014899813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BART is thinking:', max=50.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Numericaliser. Ex: 'This is a test' -> [0, 3863, 343, 276, 1772, 2]\n",
      "Denumericaliser. Ex: [0,1,2,3,4,5,6,7,8,9] -> !\"#$%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900c7fe8e1804669834b395024d21121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BART is thinking:', max=50.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numericaliser. Ex: 'This is a test' -> [0, 3863, 343, 276, 1772, 2]\n",
      "Denumericaliser. Ex: [0,1,2,3,4,5,6,7,8,9] -> !\"#$%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173ed926788948299753dc92709fd4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BART is thinking:', max=50.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "saving_cb = Validate_and_Save_Callback(filepath='saved_models/BART_CoNaLa/',\n",
    "                                       prefix='BART_codeBPE_mined20k_set_lowLR',\n",
    "                                       validate_fn=CoNaLa_valid_fn,\n",
    "                                       monitor='nltk_BLEU',\n",
    "                                       interval=0.3)\n",
    "wandb_logger = WandbLogger(name='BART_codeBPE_mined20k_set_lowLR',project='pytorchlightning')\n",
    "lr_logger_cb = LearningRateLogger(logging_interval='step')\n",
    "\n",
    "trainer = Trainer(gpus=[0], gradient_clip_val=0.5, amp_level='O1', max_epochs=200, callbacks=[saving_cb, lr_logger_cb], logger=wandb_logger)\n",
    "trainer.fit(model, conala_mined_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BART_Simple. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BartForConditionalGeneration. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BartModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BartEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LearnedPositionalEmbedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type EncoderLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BartDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DecoderLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save({'model':model, 'train_dataset':train_dataset}, 'BART_6k_chars.pickle', pickle_module=cloudpickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericaliser. Ex: 'This is a test' -> [0, 3863, 343, 276, 1772, 2]\n",
      "Denumericaliser. Ex: [0,1,2,3,4,5,6,7,8,9] -> !\"#$%\n"
     ]
    }
   ],
   "source": [
    "config = BartConfig(vocab_size=32000)\n",
    "BART_cond_gen_transform = BART_Conditional_Generator_Transform(\"saved_models/BART_CoNaLa/BART_codeBPE_mined20k_set_lowLR_{'nltk_BLEU': 0.2149831961314364, 'valid_samples': <wandb.data_types.Table object at 0x7f669336c1d0>}_step_64875.ckpt\", \n",
    "                                                                numericaliser='Code32k', \n",
    "                                                                denumericaliser='Code32k',\n",
    "                                                                device='cuda',\n",
    "                                                                from_pretrained=False,\n",
    "                                                                config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1542ad2c4084fcc8e2bd4ab7408c024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BART is thinking:', max=1.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'input_text': 'split a string `foo` by comma',\n",
       "  'input_ids': [0, 961, 276, 711, 613, 3797, 68, 626, 6155, 2],\n",
       "  'pred_ids': [0, 3797, 277, 6773, 18, 961, 401, 3797, 4022, 438],\n",
       "  'pred_text': \"foo = foo.split('foo bar')\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conala_RawDataLoader = CoNaLa_RawDataLoader()\n",
    "# test_samples = conala_RawDataLoader.get_samples('train')[:10]\n",
    "# test_samples = conala_samples[:10]\n",
    "test_samples = [{'description':'split a string `foo` by comma'}]\n",
    "test_samples = Rename_Transform(fields=[('description', 'input_text')])(test_samples)\n",
    "\n",
    "test_samples = BART_cond_gen_transform(test_samples)\n",
    "test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training BART on Code Search Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fecbd04b88a4c5a9ce120416293ce15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Filtering max chars: 600', max=412178.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b487ec0d4ece4a6d809b9278359fbdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='deleting bload fields', max=184916.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pretrain_samples = code_search_net_RawDataLoader.get_samples(\"train\", fields=['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conala_train_samples = conala_RawDataLoader.get_samples('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'swap values in a tuple/list inside a list `mylist`',\n",
       " 'code': 'map(lambda t: (t[1], t[0]), mylist)'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conala_samples[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7d4fb64cc746bba243b6b763bbd4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conala_train_dataset = BART_Pipe_Dataset(conala_train_samples, slow_pipe=[], real_time_pipe=[\n",
    "    BART_Numericalise_Transform(fields=[('description','input_ids'),('code','target_ids')])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conala_train_dataloader = conala_train_dataset.to_dataloader(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BART_Simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type                         | Params\n",
      "------------------------------------------------------\n",
      "0 | BART | BartForConditionalGeneration | 406 M \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b8e7e7c0554c4ca7a101a32005165d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(gpus=[1], gradient_clip_val=0.5, amp_level='O1', max_epochs=100, \n",
    "                  callbacks=[saving_cb])\n",
    "trainer.fit(model, conala_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint('saved_models/BART_CoNaLa/BART_CodeBPE_CoNaLa_100_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model on cuda\n"
     ]
    }
   ],
   "source": [
    "BART_cond_gen_transform = BART_Conditional_Generator_Transform(\"saved_models/BART_CoNaLa/BART_CoNaLa_100_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7029d2a8d71047caaa2a7ef656167538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BART is thinking:', max=1.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'l = list(itertools.chain.from_iterable(iterable([0, 1], repeat=False]))([0] for i in range(0, len(l)) for a item in l])\\nelse:\\n    l   pass'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples = [{'input_text':\"l is an empty list\"}]\n",
    "BART_cond_gen_transform(test_samples)[0]['pred_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46b5cbf84e54e4d831df389925ba37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BART_Span_Prediction_dataset(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = train_dataset.to_dataloader(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  9232, 18134, 41087,  1215,   560,  1215, 48408,  1640, 41087,\n",
      "          3256, 50118,  1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,\n",
      "         32988,    10,   385, 34748,   128, 41087,   108,  7626,     7,    10,\n",
      "         10798, 49683,    11,    36,  8766,     6,   235,     6,  2576,     6,\n",
      "           314,    43,   645, 50140,  1437,  1437,  1437,  4832, 46669, 20705,\n",
      "            35,    10,   385, 34748,   128, 41087,   108,  7626, 50118,  1437,\n",
      "          1437,  1437,  4832, 30921,    35,    10, 10798, 49683,  8985,     9,\n",
      "             5, 20705,    11,    36,  8766,     6,   235,     6,  2576,     6,\n",
      "           314,    43,   645, 50118,  1437,  1437,  1437, 49434, 50118,  1437,\n",
      "          1437,  1437,   671, 20705,     4,  8766, 49196, 20705,     4,  4070,\n",
      "         49196, 20705,     4, 23724, 49196, 20705,     4,  6960, 43048,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,  9232, 18134,  4328,   757,  1215, 48408,  1215,   560,  1215,\n",
      "           428, 12363,  1640, 48408,     6,  2274,  1215, 43882,  3256, 50118,\n",
      "          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,  5293,   686,\n",
      "            10, 49683,    11,    36,  8766,     6,   235,     6,  2576,     6,\n",
      "           314,    43,   645,    16,   624,     5, 22772,     9,     5,  2274,\n",
      "             4, 50140,  1437,  1437,  1437,  4832, 46669,   740,  7485,    35,\n",
      "          1437, 10798, 49683,  8985,     9,     5, 20705,    11,    36,  8766,\n",
      "             6,   235,     6,  2576,     6,   314,    43,   645, 50118,  1437,\n",
      "          1437,  1437,  4832, 46669,  2274,  1215, 43882,    35,   295, 35187,\n",
      "          3989,     9,     5,  2274,  8932, 50118,  1437,  1437,  1437,  4832,\n",
      "         30921,    35,    10, 20856, 10798, 49683,  8985,     9,     5, 20705,\n",
      "            11,    36,  8766,     6,   235,     6,  2576,     6,   314,    43,\n",
      "           645, 50118,  1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,\n",
      "           671, 19220,  1640, 48408, 10975,   288,  7479,   321,   238,  5251,\n",
      "          1640, 48408, 10975,   134,  7479,  2274,  1215, 43882, 10975,   134,\n",
      "         48677,  5251,  1640, 48408, 10975,   176,  7479,  2274,  1215, 43882,\n",
      "         10975,   288, 48677, 19220,  1640, 48408, 10975,   246,  7479,   321,\n",
      "            43]])\n",
      "tensor([[ 9232, 18134, 41087,  1215,   560,  1215, 48408,  1640, 41087,  3256,\n",
      "         50118,  1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437, 32988,\n",
      "            10,   385, 34748,   128, 41087,   108,  7626,     7,    10, 10798,\n",
      "         49683,    11,    36,  8766,     6,   235,     6,  2576,     6,   314,\n",
      "            43,   645, 50140,  1437,  1437,  1437,  4832, 46669, 20705,    35,\n",
      "            10,   385, 34748,   128, 41087,   108,  7626, 50118,  1437,  1437,\n",
      "          1437,  4832, 30921,    35,    10, 10798, 49683,  8985,     9,     5,\n",
      "         20705,    11,    36,  8766,     6,   235,     6,  2576,     6,   314,\n",
      "            43,   645, 50118,  1437,  1437,  1437, 49434, 50118,  1437,  1437,\n",
      "          1437,   671, 20705,     4,  8766, 49196, 20705,     4,  4070, 49196,\n",
      "         20705,     4, 23724, 49196, 20705,     4,  6960, 43048,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [ 9232, 18134,  4328,   757,  1215, 48408,  1215,   560,  1215,   428,\n",
      "         12363,  1640, 48408,     6,  2274,  1215, 43882,  3256, 50118,  1437,\n",
      "          1437,  1437, 49434, 50118,  1437,  1437,  1437,  5293,   686,    10,\n",
      "         49683,    11,    36,  8766,     6,   235,     6,  2576,     6,   314,\n",
      "            43,   645,    16,   624,     5, 22772,     9,     5,  2274,     4,\n",
      "         50140,  1437,  1437,  1437,  4832, 46669,   740,  7485,    35,  1437,\n",
      "         10798, 49683,  8985,     9,     5, 20705,    11,    36,  8766,     6,\n",
      "           235,     6,  2576,     6,   314,    43,   645, 50118,  1437,  1437,\n",
      "          1437,  4832, 46669,  2274,  1215, 43882,    35,   295, 35187,  3989,\n",
      "             9,     5,  2274,  8932, 50118,  1437,  1437,  1437,  4832, 30921,\n",
      "            35,    10, 20856, 10798, 49683,  8985,     9,     5, 20705,    11,\n",
      "            36,  8766,     6,   235,     6,  2576,     6,   314,    43,   645,\n",
      "         50118,  1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,\n",
      "         19220,  1640, 48408, 10975,   288,  7479,   321,   238,  5251,  1640,\n",
      "         48408, 10975,   134,  7479,  2274,  1215, 43882, 10975,   134, 48677,\n",
      "          5251,  1640, 48408, 10975,   176,  7479,  2274,  1215, 43882, 10975,\n",
      "           288, 48677, 19220,  1640, 48408, 10975,   246,  7479,   321,    43,\n",
      "             2]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([ 9232, 18134, 41087,  1215,   560,  1215, 48408,  1640, 41087,  3256,\n",
      "        50118,  1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437, 32988,\n",
      "           10,   385, 34748,   128, 41087,   108,  7626,     7,    10, 10798,\n",
      "        49683,    11,    36,  8766,     6,   235,     6,  2576,     6,   314,\n",
      "           43,   645, 50140,  1437,  1437,  1437,  4832, 46669, 20705,    35,\n",
      "           10,   385, 34748,   128, 41087,   108,  7626, 50118,  1437,  1437,\n",
      "         1437,  4832, 30921,    35,    10, 10798, 49683,  8985,     9,     5,\n",
      "        20705,    11,    36,  8766,     6,   235,     6,  2576,     6,   314,\n",
      "           43,   645, 50118,  1437,  1437,  1437, 49434, 50118,  1437,  1437,\n",
      "         1437,   671, 20705,     4,  8766, 49196, 20705,     4,  4070, 49196,\n",
      "        20705,     4, 23724, 49196, 20705,     4,  6960, 43048,     2,  9232,\n",
      "        18134,  4328,   757,  1215, 48408,  1215,   560,  1215,   428, 12363,\n",
      "         1640, 48408,     6,  2274,  1215, 43882,  3256, 50118,  1437,  1437,\n",
      "         1437, 49434, 50118,  1437,  1437,  1437,  5293,   686,    10, 49683,\n",
      "           11,    36,  8766,     6,   235,     6,  2576,     6,   314,    43,\n",
      "          645,    16,   624,     5, 22772,     9,     5,  2274,     4, 50140,\n",
      "         1437,  1437,  1437,  4832, 46669,   740,  7485,    35,  1437, 10798,\n",
      "        49683,  8985,     9,     5, 20705,    11,    36,  8766,     6,   235,\n",
      "            6,  2576,     6,   314,    43,   645, 50118,  1437,  1437,  1437,\n",
      "         4832, 46669,  2274,  1215, 43882,    35,   295, 35187,  3989,     9,\n",
      "            5,  2274,  8932, 50118,  1437,  1437,  1437,  4832, 30921,    35,\n",
      "           10, 20856, 10798, 49683,  8985,     9,     5, 20705,    11,    36,\n",
      "         8766,     6,   235,     6,  2576,     6,   314,    43,   645, 50118,\n",
      "         1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671, 19220,\n",
      "         1640, 48408, 10975,   288,  7479,   321,   238,  5251,  1640, 48408,\n",
      "        10975,   134,  7479,  2274,  1215, 43882, 10975,   134, 48677,  5251,\n",
      "         1640, 48408, 10975,   176,  7479,  2274,  1215, 43882, 10975,   288,\n",
      "        48677, 19220,  1640, 48408, 10975,   246,  7479,   321,    43,     2])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['decoder_input_ids'])\n",
    "    print(batch['decoder_target_ids'])\n",
    "    print(batch['target_attention_mask'])\n",
    "    print(torch.masked_select(batch['decoder_target_ids'], batch['target_attention_mask'].type(torch.bool)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3031936809b7430d82272d54053f3466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(train_dataset[i]['input_ids']) for i in tqdm(range(10000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type                         | Params\n",
      "------------------------------------------------------\n",
      "0 | BART | BartForConditionalGeneration | 406 M \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e347e177964a4f1281d32aea76fecbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(gpus=[1], gradient_clip_val=0.5, amp_level='O1', limit_train_batches=0.001, max_epochs=1, checkpoint_callback=checkpoint_callback, \n",
    "                  callbacks=[saving_cb])\n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model on cuda\n",
      "Numericaliser. Ex: 'This is a test' -> [0, 713, 16, 10, 1296, 2]\n",
      "Denumericaliser. Ex: [0,1,2,3,4,5,6,7,8,9] -> <s><pad></s><unk>. the, to and of\n"
     ]
    }
   ],
   "source": [
    "BART_cond_gen_transform = BART_Conditional_Generator_Transform(\"./saved_models/BART_CodeSearchNet/BART_600_step_21960.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4113ebf62a9e47b39ff6e3ec8ae89612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='BART is thinking:', max=1.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "</s><s>def contains_number(x):\n",
      "    \"\"\"A function to check if x is an integer\"\"\"\n",
      "  # # #  #   return x\n",
      "  %   >>> x.is_int(x)\n",
      "\n",
      "  # return x.size()\n"
     ]
    }
   ],
   "source": [
    "# Complete the string bellow\n",
    "test_samples = [{'input_text':\n",
    "                 '''def contains_number(x):\n",
    "    \"\"\"A function to check if x is an integer\"\"\"\n",
    "'''}]\n",
    "returned_samples = BART_cond_gen_transform(test_samples)\n",
    "print(returned_samples[0]['pred_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38b7ae26a804b54b23ffb9b4ceac4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "numer_samples = BART_Numericalise_Transform(fields=[('code', 'input_ids')], use_ray=False)(samples[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(s['input_ids']) for s in numer_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a('foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 15:44:44,635\tERROR worker.py:666 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6765d68cbae49ce89564c48a9860d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Augmenting code with Ray cores', max=184916.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "augmented_samples = Code_Sample_Augmentation_Transform()(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lengths = [len(sample['code']) for sample in augmented_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6261e6dcf2504cc18d9b3094fe9f21dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "large_samples = list([{'code':'foo '*40}]*4000)\n",
    "large_samples += list([{'code':'foo '*40}]*20)\n",
    "dataset = BART_Span_Prediction_dataset(large_samples)\n",
    "max_batch_dataloader = dataset.to_dataloader(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(s['input_ids']) for s in dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_size = 1\n",
    "model.train_dataloader = lambda: dataset.to_dataloader(model.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type                         | Params\n",
      "------------------------------------------------------\n",
      "0 | BART | BartForConditionalGeneration | 406 M \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7672afd229b40cc9b5f3efbe0fccf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(gpus=1, gradient_clip_val=0.5, amp_level='O1', max_epochs=100)# , auto_scale_batch_size='binsearch')\n",
    "trainer.fit(model, max_batch_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
